{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS Lab - Cryptocurrency Arbitrage Trading.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8fKJesQ9CtA"
      },
      "source": [
        "# **Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvHdNuQBk--J"
      },
      "source": [
        "import numpy as np\n",
        "binance_arr = np.load('/content/binance_order_array.npy', allow_pickle=True)\n",
        "bitfinex_arr = np.load('/content/bitfinex_order_array.npy', allow_pickle=True)\n",
        "coinbase_arr = np.load('/content/coinbase_order_array.npy', allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuhp9WCJcTr7"
      },
      "source": [
        "# **Getting max bids and min asks for exchanges**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92fa-CBhb3jS"
      },
      "source": [
        "**Binance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qNs-nPGl0Wd"
      },
      "source": [
        "binance_max_bids = []\n",
        "binance_max_bids_quantity = []\n",
        "\n",
        "binance_min_asks = []\n",
        "binance_min_asks_quantity = []\n",
        "\n",
        "order_time = []\n",
        "\n",
        "\n",
        "for i in range(binance_arr.shape[0]):\n",
        "\n",
        "  binance_bids_list = []\n",
        "  binance_bids_quantity = []\n",
        "\n",
        "  binance_asks_list = []\n",
        "  binance_asks_quantity = []\n",
        "\n",
        "  \n",
        "\n",
        "  for j in range(100):\n",
        "\n",
        "    binance_bids_list.append(binance_arr[i]['bids'][j][0])\n",
        "    binance_bids_quantity.append(binance_arr[i]['bids'][j][1])\n",
        "\n",
        "    binance_asks_list.append(binance_arr[i]['asks'][j][0])\n",
        "    binance_asks_quantity.append(binance_arr[i]['asks'][j][1])\n",
        "\n",
        "\n",
        "  order_time.append(binance_arr[i]['time'])\n",
        "\n",
        "  a = max(binance_bids_list)\n",
        "  index = binance_bids_list.index(a)\n",
        "  binance_max_bids.append(a)\n",
        "  binance_max_bids_quantity.append(binance_bids_quantity[index])\n",
        "\n",
        "  b = min(binance_asks_list)\n",
        "  index2 = binance_asks_list.index(b)\n",
        "  binance_min_asks.append(b)\n",
        "  binance_min_asks_quantity.append(binance_asks_quantity[index2])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOPI-E93b0wG"
      },
      "source": [
        "**Bitfinex**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kxlelnjnbzre"
      },
      "source": [
        "bitfinex_max_bids = []\n",
        "bitfinex_max_bids_quantity = []\n",
        "\n",
        "bitfinex_min_asks = []\n",
        "bitfinex_min_asks_quantity = []\n",
        "\n",
        "order_time_bitf = []\n",
        "\n",
        "for i in range(bitfinex_arr.shape[0]):\n",
        "\n",
        "  bitfinex_bids_list = []\n",
        "  bitfinex_bids_quantity = []\n",
        "\n",
        "  bitfinex_asks_list = []\n",
        "  bitfinex_asks_quantity = []\n",
        "\n",
        "\n",
        "  for j in range(25):\n",
        "\n",
        "    bitfinex_bids_list.append(bitfinex_arr[i]['orders'][j][0])\n",
        "    bitfinex_bids_quantity.append(bitfinex_arr[i]['orders'][j][2])\n",
        "\n",
        "    bitfinex_asks_list.append(bitfinex_arr[i]['orders'][j+25][0])\n",
        "    bitfinex_asks_quantity.append(bitfinex_arr[i]['orders'][j+25][2])\n",
        "\n",
        "\n",
        "  order_time_bitf.append(bitfinex_arr[i]['time'])\n",
        "\n",
        "  a = max(bitfinex_bids_list)\n",
        "  index = bitfinex_bids_list.index(a)\n",
        "  bitfinex_max_bids.append(a)\n",
        "  bitfinex_max_bids_quantity.append(bitfinex_bids_quantity[index])\n",
        "\n",
        "\n",
        "\n",
        "  b = min(bitfinex_asks_list)\n",
        "  index2 = bitfinex_asks_list.index(b)\n",
        "  bitfinex_min_asks.append(b)\n",
        "  bitfinex_min_asks_quantity.append(bitfinex_asks_quantity[index2]*(-1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7XwodogcH8d"
      },
      "source": [
        "**Coinbase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt8lLE80cGz3"
      },
      "source": [
        "coinbase_max_bids = []\n",
        "coinbase_max_bids_quantity = []\n",
        "\n",
        "coinbase_min_asks = []\n",
        "coinbase_min_asks_quantity = []\n",
        "\n",
        "order_time_cb = []\n",
        "\n",
        "for i in range(coinbase_arr.shape[0]):\n",
        "  \n",
        "  coinbase_max_bids.append(coinbase_arr[i]['bids'][0][0])\n",
        "  coinbase_max_bids_quantity.append(coinbase_arr[i]['bids'][0][1])\n",
        "\n",
        "  coinbase_min_asks.append(coinbase_arr[i]['asks'][0][0])\n",
        "  coinbase_min_asks_quantity.append(coinbase_arr[i]['asks'][0][1])\n",
        "\n",
        "  order_time_cb.append(coinbase_arr[i]['time'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hia1HH3oeYZm"
      },
      "source": [
        "# **Merging all data according to timestamp**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjqgz9FtZTvq"
      },
      "source": [
        "# **Preparing Order book data to merge**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UX-OuKCk4Z3"
      },
      "source": [
        "**Bitfinex**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txqzfia322-j"
      },
      "source": [
        "order_time = np.array(order_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETg_4GVXZXqv"
      },
      "source": [
        "bitf_book_time = []\n",
        "bitf_book_ind = []\n",
        "\n",
        "for i in range(order_time.shape[0]):\n",
        "  for j in range(np.array(order_time_bitf).shape[0]):\n",
        "    if str(order_time[i])[:-3] == str(order_time_bitf[j])[:-3]:\n",
        "      bitf_book_time.append(j)\n",
        "\n",
        "  bitf_book_ind.append(bitf_book_time) \n",
        "  bitf_book_time = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0uS8J99fwOY"
      },
      "source": [
        "all_bid_bitf = []\n",
        "all_ask_bitf = []\n",
        "\n",
        "for i in range (np.array(order_time_bitf).shape[0]):\n",
        "  all_bid_bitf.append(bitfinex_max_bids[i])\n",
        "  all_ask_bitf.append(bitfinex_min_asks[i])\n",
        "\n",
        "bitf_bid_ave = average(all_bid_bitf)\n",
        "bitf_ask_ave = average(all_ask_bitf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngaYxa07gmfc",
        "outputId": "6348fed2-d6c7-49fb-a681-aafc8c8684b0"
      },
      "source": [
        "for i in range (np.array(bitf_book_ind).shape[0]):\n",
        "  for j in range (np.array(bitf_book_ind).shape[0]):\n",
        "      if not bitf_book_ind[i]:\n",
        "        if i-j >= 0:\n",
        "          if bitf_book_ind[i-j]:\n",
        "            bitf_book_ind[i] = bitf_book_ind[i-j]\n",
        "          else:\n",
        "            bitf_book_ind[i] = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g4xrg8aj0rd"
      },
      "source": [
        "bitfinex_max_bids = np.array(bitfinex_max_bids)\n",
        "bitfinex_min_asks = np.array(bitfinex_min_asks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fkZ_BLrhS_1",
        "outputId": "8f434da6-1855-4e66-bfc5-6e22c5b75d6b"
      },
      "source": [
        "bitfinex_bid_prices = []\n",
        "bitfinex_ask_prices = []\n",
        "\n",
        "for i in range (np.array(bitf_book_ind).shape[0]):\n",
        "\n",
        "  if bitf_book_ind[i] == 0:\n",
        "    bitfinex_bid_prices.append(bitf_bid_ave)\n",
        "    bitfinex_ask_prices.append(bitf_ask_ave)\n",
        "  else:\n",
        "    bitfinex_bid_prices.extend(bitfinex_max_bids[bitf_book_ind[i]])\n",
        "    bitfinex_ask_prices.extend(bitfinex_min_asks[bitf_book_ind[i]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDj3eYCBk7J-"
      },
      "source": [
        "**Coinbase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7RvAjPglEPd"
      },
      "source": [
        "cb_book_time = []\n",
        "cb_book_ind = []\n",
        "\n",
        "for i in range(order_time.shape[0]):\n",
        "  for j in range(np.array(order_time_cb).shape[0]):\n",
        "    if str(order_time[i])[:-3] == str(order_time_cb[j])[:-3]:\n",
        "      cb_book_time.append(j)\n",
        "\n",
        "  cb_book_ind.append(cb_book_time) \n",
        "  cb_book_time = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoOYFw5RlmEF"
      },
      "source": [
        "all_bid_cb = []\n",
        "all_ask_cb = []\n",
        "\n",
        "for i in range (np.array(order_time_cb).shape[0]):\n",
        "  all_bid_cb.append(coinbase_max_bids[i])\n",
        "  all_ask_cb.append(coinbase_min_asks[i])\n",
        "\n",
        "cb_bid_ave = average(all_bid_cb)\n",
        "cb_ask_ave = average(all_ask_cb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0Q_FeFfnCm_",
        "outputId": "b13df9d4-a2b7-4ed7-a883-292247d60b95"
      },
      "source": [
        "for i in range (np.array(cb_book_ind).shape[0]):\n",
        "  for j in range (np.array(cb_book_ind).shape[0]):\n",
        "      if not cb_book_ind[i]:\n",
        "        if i-j >= 0:\n",
        "          if cb_book_ind[i-j]:\n",
        "            cb_book_ind[i] = cb_book_ind[i-j]\n",
        "          else:\n",
        "            cb_book_ind[i] = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W5GkTrMnM-5"
      },
      "source": [
        "coinbase_max_bids = np.array(coinbase_max_bids)\n",
        "coinbase_min_asks = np.array(coinbase_min_asks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDw0XfqQnRfn",
        "outputId": "89df254c-445c-4349-b740-7ac192f22554"
      },
      "source": [
        "coinbase_bid_prices = []\n",
        "coinbase_ask_prices = []\n",
        "\n",
        "for i in range (np.array(cb_book_ind).shape[0]):\n",
        "\n",
        "  if cb_book_ind[i] == 0:\n",
        "    coinbase_bid_prices.append(cb_bid_ave)\n",
        "    coinbase_ask_prices.append(cb_ask_ave)\n",
        "  else:\n",
        "    coinbase_bid_prices.extend(coinbase_max_bids[cb_book_ind[i]].astype(float))\n",
        "    coinbase_ask_prices.extend(coinbase_min_asks[cb_book_ind[i]].astype(float))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLKHNh5qZDV-"
      },
      "source": [
        "# **Preparing Trade data to merge**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCdCQA8Fcjtb"
      },
      "source": [
        "binance_tr_arr = np.load('/content/binance_trade_array.npy', allow_pickle=True)\n",
        "bitfinex_tr_arr = np.load('/content/bitfinex_trade_array.npy', allow_pickle=True)\n",
        "coinbase_tr_arr = np.load('/content/coinbase_trade_array.npy', allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGrZdkMKODQ9"
      },
      "source": [
        "**Binance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ7WVqtTEfMo"
      },
      "source": [
        "order_time = np.array(order_time)\n",
        "binance_tr = np.array(bitfinex_tr_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xmgOmf4GeEt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb64e1d-03c1-48c5-fcff-6cb2279d380d"
      },
      "source": [
        "times = []\n",
        "time_ind_bin = []\n",
        "for i in range(1, order_time.shape[0]):\n",
        "  for j in range(binance_tr_arr.shape[0]):\n",
        "    if str(order_time[i-1])[:-3]==str(binance_tr_arr[j]['T'])[:-3]:\n",
        "      times.append(j)\n",
        "\n",
        "  time_ind_bin.append(times) \n",
        "  times = []"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-f3252cf0b34a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinance_tr_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinance_tr_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'T'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m       \u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNsW4hXINhkP",
        "outputId": "c296b173-63fb-46e7-a86d-c2293b07f3c0"
      },
      "source": [
        "bin_tr_array = np.array(time_ind_bin)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoYMIG3XNj-_"
      },
      "source": [
        "for i in range (bin_tr_array.shape[0]):\n",
        "  if len(time_ind_bin[i]) != 0:\n",
        "    time_ind_bin[i] = time_ind_bin[i][len(time_ind_bin[i])-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OD-5GLZNlEb"
      },
      "source": [
        "def average(lst): \n",
        "  c=0\n",
        "  sumx = 0\n",
        "  for i in range(len(lst)):\n",
        "    if lst[i]:\n",
        "      sumx += float(lst[i])\n",
        "      c+=1\n",
        "    \n",
        "  return sumx / c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5Ryr_ZHNrN3"
      },
      "source": [
        "all_bin = []\n",
        "for i in range (binance_tr_arr.shape[0]):\n",
        "  all_bin.append(binance_tr_arr[i]['p'])\n",
        "\n",
        "bin_ave = average(all_bin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9RRvs0xNyyI"
      },
      "source": [
        "for i in range (bin_tr_array.shape[0]):\n",
        "  for j in range (bin_tr_array.shape[0]):\n",
        "    if not time_ind_bin[i]:\n",
        "      if i-j >= 0:\n",
        "        if time_ind_bin[i-j]:\n",
        "          time_ind_bin[i] = time_ind_bin[i-j]\n",
        "        else:\n",
        "          time_ind_bin[i] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a1OYL-SN56p"
      },
      "source": [
        "binance_tr_prices = []\n",
        "for i in range (bin_tr_array.shape[0]):\n",
        "  if time_ind_bin[i] == 0:\n",
        "    binance_tr_prices.append(bin_ave)\n",
        "  else:\n",
        "    binance_tr_prices.append(binance_tr_arr[time_ind_bin[i]]['p'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhyBEfOkOAi5",
        "outputId": "ccbf8034-02bc-4699-c192-8fc1109cb439"
      },
      "source": [
        "np.array(binance_tr_prices).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10052,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf79xXMpOGTn"
      },
      "source": [
        "**Bitfinex**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KtVYbmLRZB5"
      },
      "source": [
        "bitfinex_tr_arr = np.array(bitfinex_tr_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKQ05xBtOHfo"
      },
      "source": [
        "times = []\n",
        "time_ind_bitf = []\n",
        "\n",
        "for i in range(order_time.shape[0]):\n",
        "  for j in range(bitfinex_tr_arr.shape[0]):\n",
        "    if str(order_time[i])[:-3]==str(bitfinex_tr_arr[j][1])[:-5]:\n",
        "      times.append(j)\n",
        "\n",
        "  time_ind_bitf.append(times) \n",
        "  times = []\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MehGoEv3PxCU",
        "outputId": "ed1e8783-aee8-4cca-9768-6ff0a3f9e613"
      },
      "source": [
        "bitfinex_tr_ar = np.array(time_ind_bitf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFB135pGP2_1"
      },
      "source": [
        "for i in range (bitfinex_tr_ar.shape[0]):\n",
        "  if len(time_ind_bitf[i]) != 0:\n",
        "    time_ind_bitf[i] = time_ind_bitf[i][len(time_ind_bitf[i])-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Snfe-1EEP4Ec"
      },
      "source": [
        "all_bitf = []\n",
        "for i in range (bitfinex_tr_arr.shape[0]):\n",
        "  all_bitf.append(bitfinex_tr_arr[i][3])\n",
        "\n",
        "bitf_ave = average(all_bitf)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG9ht-pcQE-u"
      },
      "source": [
        "for i in range (bitfinex_tr_ar.shape[0]):\n",
        "  for j in range (bitfinex_tr_ar.shape[0]):\n",
        "      if not time_ind_bitf[i]:\n",
        "        if i-j >= 0:\n",
        "          if time_ind_bitf[i-j]:\n",
        "            time_ind_bitf[i] = time_ind_bitf[i-j]\n",
        "          else:\n",
        "            time_ind_bitf[i] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhxbW7iEQE4N"
      },
      "source": [
        "bitfinex_tr_prices = []\n",
        "for i in range (bitfinex_tr_ar.shape[0]):\n",
        "  if time_ind_bitf[i] == 0:\n",
        "    bitfinex_tr_prices.append(bitf_ave)\n",
        "  else:\n",
        "    bitfinex_tr_prices.append(bitfinex_tr_arr[time_ind_bitf[i]][3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huMnS49eQgCK",
        "outputId": "aa19fc0e-e794-47d0-d30b-40705e2a9109"
      },
      "source": [
        "np.array(bitfinex_tr_prices).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10052,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e-fj3DIRMAf"
      },
      "source": [
        "**Coinbase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af9B1_q_Qieo"
      },
      "source": [
        "times = []\n",
        "time_ind_coinbase = []\n",
        "\n",
        "for i in range(order_time.shape[0]):\n",
        "  for j in range(coinbase_tr_arr.shape[0]):\n",
        "    if str(order_time[i])[:-3]==str(coinbase_tr_arr[j][0])[:-2]:\n",
        "      times.append(j)\n",
        "\n",
        "  time_ind_coinbase.append(times) \n",
        "  times = []\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6xfDKqSYjlf",
        "outputId": "12979897-0730-428a-c785-9eaebff85957"
      },
      "source": [
        "coinbase_tr_a = np.array(time_ind_coinbase)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Gk0WLxjYlYx"
      },
      "source": [
        "for i in range (coinbase_tr_a.shape[0]):\n",
        "  if len(time_ind_coinbase[i]) != 0:\n",
        "    time_ind_coinbase[i] = time_ind_coinbase[i][len(time_ind_coinbase[i])-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5TMApKIYnvJ"
      },
      "source": [
        "all_coinbase = []\n",
        "for i in range (coinbase_tr_arr.shape[0]):\n",
        "  all_coinbase.append(coinbase_tr_arr[i][4])\n",
        "\n",
        "cb_ave = average(all_coinbase)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgZyuRS9Y0Wv"
      },
      "source": [
        "for i in range (coinbase_tr_a.shape[0]):\n",
        "  for j in range (coinbase_tr_a.shape[0]):\n",
        "      if not time_ind_coinbase[i]:\n",
        "        if i-j >= 0:\n",
        "          if time_ind_coinbase[i-j]:\n",
        "            time_ind_coinbase[i] = time_ind_coinbase[i-j]\n",
        "          else:\n",
        "            time_ind_coinbase[i] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDi2aKJaY4pA"
      },
      "source": [
        "coinbase_tr_prices = []\n",
        "for i in range (coinbase_tr_a.shape[0]):\n",
        "  if time_ind_coinbase[i] == 0:\n",
        "    coinbase_tr_prices.append(cb_ave)\n",
        "  else:\n",
        "    coinbase_tr_prices.append(coinbase_tr_arr[time_ind_coinbase[i]][4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGo2MhnHY-yr",
        "outputId": "70407e74-fcab-4004-abb4-a2afc2db3777"
      },
      "source": [
        "np.array(coinbase_tr_prices).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10052,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag-WZXDxn5f5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiHl95fvn8UG"
      },
      "source": [
        "# **Merging all in one dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS6hvj31n_Zz"
      },
      "source": [
        "crypto_data = zip(order_time, \n",
        "                  binance_max_bids, bitfinex_bid_prices, coinbase_bid_prices,\n",
        "                  binance_min_asks, bitfinex_ask_prices, coinbase_ask_prices,\n",
        "                  binance_tr_prices, bitfinex_tr_prices, coinbase_tr_prices\n",
        "                  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCeNp_4-o1-a"
      },
      "source": [
        "import pandas as pd\n",
        "crypto_df = pd.DataFrame(crypto_data, columns = ['Timestamp', \n",
        "                                     'Binance_max_bid', 'Bitfinex_max_bid', 'Coinbase_max_bid', \n",
        "                                     'Binance_min_ask','Bitfinex_min_ask','Coinbase_min_ask', \n",
        "                                     'Binance_trade_prices', 'Bitfinex_trade_prices', 'Coinbase_trade_prices'\n",
        "                                     ]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICGgTgwP8RVI"
      },
      "source": [
        "# **Data Preprocessing and LSTM Modeling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR12KszxtKZu"
      },
      "source": [
        "import pandas as pd\n",
        "df1 = pd.read_csv('/content/crypto_data.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e9JmJ1292Iu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "d3d00042-8e85-492d-eb31-945938b0c537"
      },
      "source": [
        "df1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Binance_max_bid</th>\n",
              "      <th>Bitfinex_max_bid</th>\n",
              "      <th>Coinbase_max_bid</th>\n",
              "      <th>Binance_min_ask</th>\n",
              "      <th>Bitfinex_min_ask</th>\n",
              "      <th>Coinbase_min_ask</th>\n",
              "      <th>Binance_trade_prices</th>\n",
              "      <th>Bitfinex_trade_prices</th>\n",
              "      <th>Coinbase_trade_prices</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1609195948717</td>\n",
              "      <td>0.027032</td>\n",
              "      <td>0.026843</td>\n",
              "      <td>0.026852</td>\n",
              "      <td>0.027033</td>\n",
              "      <td>0.026866</td>\n",
              "      <td>0.026865</td>\n",
              "      <td>0.027033</td>\n",
              "      <td>0.026805</td>\n",
              "      <td>0.026864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1609195950271</td>\n",
              "      <td>0.027032</td>\n",
              "      <td>0.026843</td>\n",
              "      <td>0.026852</td>\n",
              "      <td>0.027033</td>\n",
              "      <td>0.026866</td>\n",
              "      <td>0.026865</td>\n",
              "      <td>0.027035</td>\n",
              "      <td>0.026805</td>\n",
              "      <td>0.026864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1609195951836</td>\n",
              "      <td>0.027035</td>\n",
              "      <td>0.026843</td>\n",
              "      <td>0.026852</td>\n",
              "      <td>0.027046</td>\n",
              "      <td>0.026866</td>\n",
              "      <td>0.026865</td>\n",
              "      <td>0.027046</td>\n",
              "      <td>0.026805</td>\n",
              "      <td>0.026864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1609195953400</td>\n",
              "      <td>0.027045</td>\n",
              "      <td>0.027010</td>\n",
              "      <td>0.026852</td>\n",
              "      <td>0.027046</td>\n",
              "      <td>0.027040</td>\n",
              "      <td>0.026865</td>\n",
              "      <td>0.027042</td>\n",
              "      <td>0.026805</td>\n",
              "      <td>0.026864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1609195954952</td>\n",
              "      <td>0.027045</td>\n",
              "      <td>0.027010</td>\n",
              "      <td>0.026852</td>\n",
              "      <td>0.027046</td>\n",
              "      <td>0.027040</td>\n",
              "      <td>0.026865</td>\n",
              "      <td>0.027045</td>\n",
              "      <td>0.026805</td>\n",
              "      <td>0.026864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10047</th>\n",
              "      <td>1609239317624</td>\n",
              "      <td>0.027310</td>\n",
              "      <td>0.027300</td>\n",
              "      <td>0.027310</td>\n",
              "      <td>0.027315</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0.027304</td>\n",
              "      <td>0.027305</td>\n",
              "      <td>0.027320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10048</th>\n",
              "      <td>1609239325355</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0.027300</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0.027323</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0.027340</td>\n",
              "      <td>0.027324</td>\n",
              "      <td>0.027305</td>\n",
              "      <td>0.027320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10049</th>\n",
              "      <td>1609239333121</td>\n",
              "      <td>0.027317</td>\n",
              "      <td>0.027300</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0.027330</td>\n",
              "      <td>0.027324</td>\n",
              "      <td>0.027305</td>\n",
              "      <td>0.027320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10050</th>\n",
              "      <td>1609239340850</td>\n",
              "      <td>0.027315</td>\n",
              "      <td>0.027300</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0.027316</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0.027330</td>\n",
              "      <td>0.027316</td>\n",
              "      <td>0.027305</td>\n",
              "      <td>0.027320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10051</th>\n",
              "      <td>1609239349321</td>\n",
              "      <td>0.027309</td>\n",
              "      <td>0.027300</td>\n",
              "      <td>0.027310</td>\n",
              "      <td>0.027318</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0.027319</td>\n",
              "      <td>0.027305</td>\n",
              "      <td>0.027320</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10052 rows Ã— 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Timestamp  ...  Coinbase_trade_prices\n",
              "0      1609195948717  ...               0.026864\n",
              "1      1609195950271  ...               0.026864\n",
              "2      1609195951836  ...               0.026864\n",
              "3      1609195953400  ...               0.026864\n",
              "4      1609195954952  ...               0.026864\n",
              "...              ...  ...                    ...\n",
              "10047  1609239317624  ...               0.027320\n",
              "10048  1609239325355  ...               0.027320\n",
              "10049  1609239333121  ...               0.027320\n",
              "10050  1609239340850  ...               0.027320\n",
              "10051  1609239349321  ...               0.027320\n",
              "\n",
              "[10052 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKDkn2D9SHc5"
      },
      "source": [
        "trades = df1.iloc[:, 7:10]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHEBGb_sS4TR"
      },
      "source": [
        "import numpy as np\n",
        "trades = np.array(trades)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_DyBL5wSkUc"
      },
      "source": [
        "for i in range (trades.shape[0]-1):\n",
        "  trades[i,:] = trades [i+1, :] "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1ax14l0T1AO",
        "outputId": "ba5d6f4d-aab9-4420-b4de-b3f0d99ab58b"
      },
      "source": [
        "trades"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.027035  , 0.02680532, 0.02686412],\n",
              "       [0.027046  , 0.02680532, 0.02686412],\n",
              "       [0.027042  , 0.02680532, 0.02686412],\n",
              "       ...,\n",
              "       [0.027316  , 0.027305  , 0.02732   ],\n",
              "       [0.027319  , 0.027305  , 0.02732   ],\n",
              "       [0.027319  , 0.027305  , 0.02732   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYX86MbMeOYi"
      },
      "source": [
        "bids = df1.iloc[:,1:4]\n",
        "asks = df1.iloc[:, 4:7]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvYEhA8XfgIb"
      },
      "source": [
        "bids = np.array(bids)\n",
        "asks = np.array(asks)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acmLSgbodcf-"
      },
      "source": [
        "bids_list = []\n",
        "asks_list = []\n",
        "\n",
        "max_bids = []\n",
        "min_asks = []\n",
        "\n",
        "for i in range(df1.shape[0]):\n",
        "  bids_list.append(bids[i,:])\n",
        "  asks_list.append(asks[i,:])\n",
        "\n",
        "  max_bids.append(max(bids_list[i]))\n",
        "  min_asks.append(min(asks_list[i]))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXrYY22T74s8"
      },
      "source": [
        "**Labeling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCZMUoPfgODb"
      },
      "source": [
        "labels = []\n",
        "ones = 0\n",
        "zero = 0\n",
        "for i in range(np.array(max_bids).shape[0]):\n",
        "\n",
        "  if max_bids[i] - min_asks[i] > min_asks[i]*0.001:  \n",
        "    labels.append(1)\n",
        "    ones += 1\n",
        "  else:\n",
        "    labels.append(0)\n",
        "    zero += 1"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "KBaXxN9ehkox",
        "outputId": "e807fcad-8547-4169-8a8e-7a115955a699"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "Labels = ['Label 1', 'Label 0']\n",
        "Values = [ones, zero]\n",
        "ax.bar(Labels, Values)\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK1wB_YLktJn"
      },
      "source": [
        "crypto_data = df1.iloc[:, 4:7]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ4tXv4vUm-w"
      },
      "source": [
        "crypto_data['Binance_tr'] = trades[:,0]\n",
        "crypto_data['Bitfinex_tr'] = trades[:,1]\n",
        "crypto_data['Coinbase_tr'] = trades[:,2]\n",
        "crypto_data['Labels'] = labels"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "i4qtA1wEU4-c",
        "outputId": "a08d5b98-b6c8-481b-c72c-1f4f73eb9281"
      },
      "source": [
        "crypto_data"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Binance_min_ask</th>\n",
              "      <th>Bitfinex_min_ask</th>\n",
              "      <th>Coinbase_min_ask</th>\n",
              "      <th>Binance_tr</th>\n",
              "      <th>Bitfinex_tr</th>\n",
              "      <th>Coinbase_tr</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.027033</td>\n",
              "      <td>0.026866</td>\n",
              "      <td>0.026865</td>\n",
              "      <td>0.027035</td>\n",
              "      <td>0.026805</td>\n",
              "      <td>0.026864</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.027033</td>\n",
              "      <td>0.026866</td>\n",
              "      <td>0.026865</td>\n",
              "      <td>0.027046</td>\n",
              "      <td>0.026805</td>\n",
              "      <td>0.026864</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.027046</td>\n",
              "      <td>0.026866</td>\n",
              "      <td>0.026865</td>\n",
              "      <td>0.027042</td>\n",
              "      <td>0.026805</td>\n",
              "      <td>0.026864</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.027046</td>\n",
              "      <td>0.027040</td>\n",
              "      <td>0.026865</td>\n",
              "      <td>0.027045</td>\n",
              "      <td>0.026805</td>\n",
              "      <td>0.026864</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.027046</td>\n",
              "      <td>0.027040</td>\n",
              "      <td>0.026865</td>\n",
              "      <td>0.027049</td>\n",
              "      <td>0.026805</td>\n",
              "      <td>0.026864</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10047</th>\n",
              "      <td>0.027315</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0.027324</td>\n",
              "      <td>0.027305</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10048</th>\n",
              "      <td>0.027323</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0.027340</td>\n",
              "      <td>0.027324</td>\n",
              "      <td>0.027305</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10049</th>\n",
              "      <td>0.027320</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0.027330</td>\n",
              "      <td>0.027316</td>\n",
              "      <td>0.027305</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10050</th>\n",
              "      <td>0.027316</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0.027330</td>\n",
              "      <td>0.027319</td>\n",
              "      <td>0.027305</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10051</th>\n",
              "      <td>0.027318</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0.027319</td>\n",
              "      <td>0.027305</td>\n",
              "      <td>0.027320</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10052 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Binance_min_ask  Bitfinex_min_ask  ...  Coinbase_tr  Labels\n",
              "0             0.027033          0.026866  ...     0.026864       1\n",
              "1             0.027033          0.026866  ...     0.026864       1\n",
              "2             0.027046          0.026866  ...     0.026864       1\n",
              "3             0.027046          0.027040  ...     0.026864       1\n",
              "4             0.027046          0.027040  ...     0.026864       1\n",
              "...                ...               ...  ...          ...     ...\n",
              "10047         0.027315          0.027320  ...     0.027320       0\n",
              "10048         0.027323          0.027320  ...     0.027320       0\n",
              "10049         0.027320          0.027320  ...     0.027320       0\n",
              "10050         0.027316          0.027320  ...     0.027320       1\n",
              "10051         0.027318          0.027320  ...     0.027320       0\n",
              "\n",
              "[10052 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhBSLeTN8Fqv"
      },
      "source": [
        "**Data plotting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "zDR6tw5qoE4Z",
        "outputId": "bdf6947e-f48d-41c3-9a12-bbaf2e2b01a4"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "plt.plot(crypto_data[:,0], color = 'blue', label = 'Binance', linewidth=0.5)\n",
        "plt.plot(crypto_data[:,1], color = 'red', label = 'Bitfinex', linewidth=0.5)\n",
        "plt.plot(crypto_data[:,2], color = 'green', label = 'Coinbase', linewidth=0.5)\n",
        "\n",
        "plt.title('Minimum ask rates over the time in exhanges')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "QK7SVba-phyQ",
        "outputId": "e1cce928-eba0-4a39-e4c1-82523d3b2f6f"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "plt.plot(crypto_data[:,3], color = 'blue', label = 'Binance', linewidth=0.5)\n",
        "plt.plot(crypto_data[:,4], color = 'red', label = 'Bitfinex', linewidth=0.5)\n",
        "plt.plot(crypto_data[:,5], color = 'green', label = 'Coinbase', linewidth=0.5)\n",
        "\n",
        "plt.title('Minimum latest trade rates over the time in exhanges')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEICAYAAAC0+DhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydZ5hURdaA39NpMkMYco6Sk0gQFTAgYMCAiIqYxVV0xRVlV1dGwDWurjl9ugYUXRFdFFwTooACAgISJOcwMMwwOXT3re9H3WF6cg/0JKbe5+mn+96qW3Xqdt176lQ4JUopDAaDwWAIxFHVAhgMBoOh+mGUg8FgMBiKYJSDwWAwGIpglIPBYDAYimCUg8FgMBiKYJSDwWAwGIpQ65WDiLwmIn8PddzKRESGisi+qpajshCRRSJya1XLcSohIrtE5PwKSvtsEdlcEWkXk9cGERlaGXkF5HlK1sdTVjnYlT1XROIKnf9NRJSItAFQSt2hlJoRTJrliVtdEZEbRWRJiNIq9YVyKigtEXlHRGZWtRyhpKLLZD9fHfKOlVKLlVKnVVR+gSiluimlFlVGXqc6p6xysNkJXJN3ICI9gMiqE8dQGBFx1ca8K4vaUEZDBaGUOiU/wC7gYeDXgHPPAA8BCmhjn3sHmGn/HgrsA/4CHAYOAjcFXF9c3AcC4l4GjAK2AEnA34q7NvD6QvJOAdYBGcBbQGPgKyAN+A6oV0JZC6c1FdhuX7cRuNw+3wXIBvxAOnDMPh9m35s9QALwGhBhh8UBXwLH7DItRjcq3gcsIMtO64FCMkXZYZYdng40A+KBOcAsIBW4FegP/GLncRB4CfAEpHUB8AeQYof9CNwaEH4zsAlIBr4GWpdwn9rY//0tdll/ss9/Ahyy0/8J6Gafvx3wArm2/F/Y55sBnwJH0A2QewLy6A+stMuWADxbSh29Ddhm39d5QDP7/KvAM4Xi/he4L4j8i9zfQumUVKZdwP3o+pcCfAyEB1x3MbDG/o9+BnqWUKaf7HucYad/NSdZ14GBdp7HgLXA0DKe+/MD7sV/gPfsdDcA/Uq5tjPwrf1/bAbG2ufb2+f6Btz/I3lyAIuAGcBSO59vgLiAdIutXwHvhZeB+fa1y4H2AeHDbVlSgFcIsu4DAjyHfjelAr8D3cv1Dq2ol3NVf/IqiX1juwBO9Mu8NaUrBx8wHXCjX/SZeRW1hLiP2HFvsyvMh0AM0A39cmxb+NqA6ws/MMvQD0lz+09dDfQBwoGFwLQSylo4ravsCuxAP5wZQFM77EZgSaHrn0O/nOrbsn8BPG6HPY5WFm77czYghR/EYOQKeGC9aEXqACKA09EvABf6Bb4JuNeOH4d+aMbY+U+27/utdvho9Au2i339w8DPJcjTxv7v30MrrzwFeLNd7jDgX8CaQg9v4P/mAFbZ/7sHaAfsAC60w38Brrd/RwMDS5DlXCAR6Gvn+yL5yuocYG/Afa6HrkvNgsi/yP0tJu8CZQr4L1fYedS3/4M77LA+6Po4AP0c3WDHDyuhbAroEIq6bocfRT+LDnRD4SjQsLTnPuBeZNvXOtF1eVkJ10XZ9/wmux71sf+frnb4beiGViT6JfxMwLWL0I2xTuj6vAh4IiC8rPp1FN2ocAEfAB8F1P1U4Ao77M/2f1tm3QcutOtJXbSi6IL9Dgj2c6p3K4Fu4U5AV6pNwP4y4nuB6Uopr1JqAbr1U1J/qRd4TCnlBT5C/5nPK6XSlFIb0JWpVzlkfVEplaCU2o9uoS9XSv2mlMoGPkNX2DJRSn2ilDqglLKUUh8DW9GVrwgiIujW5GSlVJJSKg34BzAuoIxN0S0Sr9L9xyfrkOsXpdTntnxZSqlVSqllSimfUmoX8DowxI47CtiglJpj3+d/oVthedyBVmSblFI+W/beItK6lPzjlVIZSqksAKXU2/Z/loN+ofQSkdgSrj0D/WKarpTKVUrtAN6k4P3qICJxSql0pdSyEtK5DnhbKbXazvevwCB7LGwx+gV7th13jH3PDgSRPxS6v6Xch8K8YNebJHQDobd9/nbgdaXUcqWUXyn1LpCDVugnSrB1fTywQCm1wC7Pt2jLbFSQ+Syxr/Wj3wUlPY8XA7uUUv+26+FvaOvsKgCl1JvoF/Fy9PPwUKHr/62U2mLf7/+Qf++CqV+fKaVW2PX3g4Br8+r+XDvsBYKv+160QuqMbmRsUkodDPKeAaf+mAPoCnEtusX8XhDxj9o3Oo9MdAuwpLh++3feQ5gQEJ5VyrXFUfjaE0pLRCaIyBoROSYix4DuaMVVHA3RraFVAfH/Z58HeBr9UHwjIjtEZGrwxSmRvYXk7SQiX4rIIRFJRVfyPHmbBca3FVPg9a2B5wNkT0K3lJoHk7+IOEXkCRHZbue9yw4q6X61Bprl5Wfn+Td0Kxh0l1Un4A8R+VVELi4hnWbA7oBypaNbkM3tMn5E/njZteiXRjD5FyhfOQl88QTW+9bAXwrl2dIuw4kSbF1vDVxVKO+z0C/oYChcpvASxmFaAwMK5XMd0CQgzpvoZ+lF+0VfWj7REHT9Kum+F1f3Ayd4lFj3lVIL0V2wLwOHReQNEalTTLlL5JRXDkqp3eh+2VHA3CoUJYOCg+FNSop4MtithjeBSUADpVRdYD260oBukQaSiH4Yuyml6tqfWKVUNIDd4vmLUqodcClwn4icV0JahSkpvPD5V9FjCh2VUnXQL7s8eQ+iX0R55ZPAY/TDMzFA9rpKqQil1M9BynUt2jw/H4hFdz1ByfdrL7CzUH4xSqlRAEqprUqpa4BGwJPAHBGJKkaGA+iHO69cUUAD8i3b2cAY+/8cgG7Flpl/CTKXVv5g2Iu2kAPzjFRKzS5nOifCXuD9QnlHKaWeqIB8fiyUT7RS6k8AIhKNtlrfAuJFpH6Q6ZZVv0rjINAi78Cu+y0Cwkut+0qpF5RSpwNd0Q2WKUHKDNQC5WBzC3CuUiqjCmVYA4wSkfoi0gS4t4LyiUI//EcAROQmdGsnjwSghYh4AJRSFlqZPCcijexrmovIhfbvi0Wkg10xU9CD2VZAWu1KkSUBaFBKF00eMei+1XQR6Qz8KSBsPtBNRK6wW3z3UFCxvgb8VUS62fLGishVZeRXOO8cdKs9Em21FC5DYBlXAGki8qCIRNgtw+4icoad/3gRaWjf12P2NRZFmQ3cJCK9RSTMzne53a2G3a2RCPwf8LVSKi+tUvMPkrL+t8K8CdwhIgNEEyUiF4lITIjSL41ZwCUicqFd1nB7inSLMq8sH18CnUTkehFx258zRKSLHf48sFIpdSu6Tr4WZLpl1a/SmA/0EJHL7Lp/F0HWfVv2ASLiRjdMsym+HpZIrVAOSqntSqmVVSzG++iZFrvQsxk+rohMlFIbgX+iB0YTgB7oWRR5LETP2jgkIon2uQfRXUfLbNP3O/LHWTrax+l2mq8opX6wwx4HHrbN2vuLkeUP9Etwhx2npG6I+9EtrDT0i+j4vVFKJaL7fZ9AP2AdA8ujlPoM3UL/yJZ9PTCytHtUiPfQ3Tv70WNEhccI3gK62vJ/bncjXozuF95J/gs8TwGOADaISDr6hTKuuH5/pdR3wN/RFsFB9IyYcYWifYhucX4YcF1Z+QdDgTKVFdl+dm5Dd1Mko+vKjaVcEg+8a6c/thxyFZf3XnTL+2/oBs9edAs4pO8upcfahqP/gwPorp4ngTARGY3+X/MaLfcBfUXkuiCSLqt+lSZTXt1/Cl33u6LHW3Ls8NLqfh30s5Rs538U3UUcNHmzIQwGg8FQjRERB3rM4bqABlqFUSssB4PBYKiJ2N1pde2ux7yxuKCtj5PBKAeDwWCovgxCr6FIBC4BLivn9OQTxnQrGQwGg6EIxnIwGAwGQxFOCadccXFxqk2bNlUthsFgMNQoVq1alaiUalhcWFDKQURGoKflOYH/K7wAxR4seQ/tI+cocLVSapeIXICeguhBO/qaopRaaM+PXhyQRAtgllLq3oA0r0Q7EDujrGmobdq0YeXKqp6pajAYDDULEdldUliZykFEnOgl2Begp1H9KiLz7Pn0edwCJCulOojIOPTc26uxB1GUUgdEpDvaYVVze05x74A8VhGwetlWHn9G+zExGAwGQyUTzJhDf2CbUmqHUioX7fNldKE4o4F37d9zgPNERGxHWgfs8xuACNvKOI6IdEK7Ggi0JGagFUx2uUpjMBgMhpAQjHJoTkFHXvso6tTseBzbaV0K2k9MIFcCeR4oAxkHfGw7lUJE+gItlVLzgyqBwWAwGEJOpQxI274/nkQvTy/MOOB6O54DeJbSl+bnpXk72pUwrVq1CpWoBoPBYCA4y2E/Bb1gtqDongjH49gOomLRA9PYDrI+AyYopbYHXiQivQCXUmqVfSoG7SRukYjsQvuLnyci/QoLpZR6QynVTynVr2HDYgfbDQaDwXCCBKMcfgU6ikhb25PnOPSuYYHMQ+8OBXpjkoVKKSUiddGeBacqpZZSlGvQjtkAUEqlKKXilFJtlFJt0MvEL60GTvMMBoOhVlGmcrDHECahZxptAv6jlNogItNF5FI72lto18zb0B4L8zaEmQR0AB4RvfnMmjy30DZjCVAOBoPBYKgenBLuM/r166fMOgeDwVCbyHt3661WTgwRWaWUKtJtD8Z9Rq1lwoSqlsBgMJwM87fOZ/xn4yssfaMcaimzZoHfX3Y8g8FQPcnyZpHjK7wyIHQY5VBLUQpSU2HJkqqWxGAwnAgvvKjIzDzxLqWyMMqhFvPVVzBqVNnxDAZD9WPnToXlN8rBEGLq1IGsLDjrrKqWxGAwFMfGjaWH+5WFQyruFW6UQy3k9Os+5/wOF5K87QgNCjs5MRgM1YJu3UoPV0rhOImZSmVhlEMtJCnhI5o1XMt7z2ynbt2CYf2KndRmMBgqmxhSWbEgscRwhbEcDCHmBv/HxPgiGTQojagosCx9/sABWLWq9GsNBkPlEE88DZ/8S4nhhw8rdu82loMhxFjeSH5bk86TT4LTCUlJMNteqz52bNXKZjAYII0YvtnSFoDnny8mgijWra045XBKbBNqKB9ZhJN79DQSBn4E3rUA3DMXPvgSGAqfpKYAz1WliAZDrebll+G7875HlIP2O87i3nvPp39/GDQoP06duhap3sgKk8FYDrWQ5QzA3+Zp7vu2Cc8sSuPNRfuYebgTvZLjYVE85NThVHCrYjDUVCZNAqffyaCfB7H+8HoArriiYJx+pyti1v21wmQwlkMtI8deUNn90nZMnK9t1TiOkPzQU6xnLFdc4eLzZCeWsnCKswolNRgM5w9xsM7SrgwOHSoYFhltkZZiBqQNISI1VX/ffLP+PuMMuHVqQw7QjGjSmTMHhpztJiPLV3VCGgwGAHw5DnyWfhYjI2Hfvvyw07b8l9vUGxWWt1EOtYzMTDjtNHC54MMPYcUKePxxSCeaaNIRgR++czHyIqMcDIaqIiJCfy9dLLz5lp8ne8/m0awHmDw5P8627YqBb91RYTIY5VDLyMgAh0OPJ1xzTf75NGKIIU0fWC5+XmaUg8FQVfTsCfXqgcuChJ3JDI5YjaduJHlr3vx+aNdeMeJC061kCBGz3vGRkVH0fHhcvnKYdJeLEaOMcjAYqorwcFAWfKquopNs4kDzMxDR084BvF5wOEEw6xwMIUIlHkWiik5/c8TGMDL2F1i8mC7OXaSnfUBaTloVSGgwGCIjwW/BenqxmtNZe9pYjibB9u063OsFHMqskDaEjkE9M2jQ1FPkfFLHAYyY0h1yc7m63mDaJc7lyy1fVoGEBoMhIoLjHlcjIuGxx/T5rCz97fWCy599UrvAlYWZylqL+HTjp/yYuglHeNEpqo6IMA52OQ/OgwZAnfELsZRV+UIaDAYiIyEzU48NZkVvhN7vsIY1JLtW0bLl6fy6QqGcjgrtVjLKoRaxeM9iumUP4cJWXYqEud2Qm5t/HBsXiT87sxKlMxgMeUSF+2mdvYT/AZ22v8CWXTnEuXfTrsdkzl15LuFPWGTVbWi6lQyhITYslkZpsdStF1ckzOMpqBy2JtQjJ9mMORgMVcHpCQv4xnURAFPuaArH2vBB2jQWt3TyaP846r0wnaSOAyq0W8koh1qEiCCZGbhio4qEXXQRdO2af3xMNSA7KbUSpTMYDHm0TV5Nctu+gH4uBw4Enw9ouwgijwAgTuOy2xAilIJ5s4tXDuPGFdzLIbxxHLn7DlSidAaDIQ+nE667Vv+OjobmzfXaBjaMgbRmMDSeff5VeJxFJ5eECqMcahFz54JkZeCuW1Q5FGb0w73wHz5cCVIZDIbCCPmOL3v2hE8+0Y07PvmEv4+aCIviWThpFpFu45XVEALWr4f+rMDZsH6ZcaPrReHN8ZLnnPVIxhEa3TKRO+ffyc7kXRUrqMFQy1GoAjORROCjj/TvceN0N3AFDjcARjnUKrp1VxykqbZTyyAszMmKVRadOunj5OxkElcN4fyWl9L7rEOlX2wwGE4KhR4jTEjIP3f11fDUU3oM4stKWIJklEMtIrIcFmiTxk7w57Jtmz72WT7C3S72/6GYnPlAwalNBoPhpFm3Lv+3Er36uVGjgnGmTKk8eYxyqCUopfh1RfB26GmdHLgkl05sBrRyyMpw8dIMH82jtkN2dkWJajDUSnr1yv+96CdVoQvcgsEoh1qCpSwaqKMMGxLcDm9OcfKtDONPvArAtEd9YLnI3dqSL7tk2/PqDAbDyfLFF/DWWwXPKVEVuoYhGIJSDiIyQkQ2i8g2EZlaTHiYiHxshy8XkTb2+QtEZJWI/G5/n2ufjxGRNQGfRBH5lx12n4hsFJF1IvK9iLQOXXFrL5ayGNFpL0Nm3RZUfIc4SItNYX+0oHx+/jsvG7GEmBwHdRNjbM9fBoPhZNm6FTb+7seBHyzbZY1QoWsYgqFM9xki4gReBi4A9gG/isg8pdTGgGi3AMlKqQ4iMg54ErgaSAQuUUodEJHuwNdAc6VUGtA7II9VwFz78Degn1IqU0T+BDxlp2U4CRQKl9+Xv4tIGUS6I2HbCD49803atvwHE9y7qVvfSwwdWEJLoxwMhhARnbyXCQsmE0kvmLgH6/U3i8xWqgqC8a3UH9imlNoBICIfAaOBQOUwGoi3f88BXhIRUUr9FhBnAxAhImFKqZy8kyLSCWgELAZQSv0QcM0yYHy5SmQoFktZOP3+oJWDiBB9aCQy4kvu2n8aNPTj2DMEi2Fc1WmlUQ4GQwjIzoaE3dms73g5M7deS79m15Dx+3/gyo045MwqlS0Yu6U5sDfgeJ99rtg4SikfkIJ27hnIlcDqQMVgMw74WClVXGf4LcBXxQklIreLyEoRWXnkyJEgilG7sZSFy/LpXUSC5MgRyP7mYTjcnRnjxpLy+9kA/LHFQe5R43fJYDhZli6FD97388UCJzh8fKt20qVBdzpnNOOOfhW3BWgwVEqnloh0Q3c1TSwmeBwwu5hrxgP9gKeLS1Mp9YZSqp9Sql/Dhg1DKe4piaUsHJYFjuD/8vBwWLu0KRm7uvLwxK5ER2pDs3mvRnhXrSvjaoPBUBL33AMJCXrVsxM/u7stB3cWm36IplO9rrTLbkhMWEyVyhjMm2I/0DLguIV9rtg4IuICYoGj9nEL4DNgglJqe+BFItILcCmlVhU6fz7wEHBpMZaG4QSwlIVQdB+HsoiLK7g+IjUVwhpE4U8z7rwNhhPlq6/0s+RIT+V1JrLmwvcgKgGHEvx+iE4/WNUiBqUcfgU6ikhbEfGgW/rzCsWZB9xg/x4DLFRKKRGpC8wHpiqllhaT9jUUshpEpA/wOloxGOc+IeK/f/yXWO/J+2GJiQE8Yaj9ximfwXCiiOiJSc7MNM5iKaIc4MxFbOXgi6hT1SKWrRzsMYRJ6JlGm4D/KKU2iMh0EbnUjvYW0EBEtgH3AXnTXScBHYBHAqatBq75G0vRLqWngWjgEzt+YUVkOAG2J+9gxMEeIUlLwsPw5/pDkpbBUBtRyvaNlDd11bKVg+XAl2vhi6jaLiUIcic4pdQCYEGhc48E/M4GrirmupnAzFLSbVfMufODkclQPg4eVCQcDs3UuJyENtyQ8xIf5EyhTljVt3AMhpqICDhFKwexnODMpX1rB5vXe1Gq6jfpNCukawl/bIYt20Lzd9/e/0Y6ZTQlLcfMWDIYToS8uZlOh/4RG+0EVw5up3Dn7T72HnRXoXQaoxxqCS2aw003hSatAQPA4xT8ynQtGQwnigg40JZDRLiDJ57OxaEE8ftQTmM5GCoJrxdcIapvTZqA8jmwlBWaBA2GWkbemEOecgh3u+jZ24vldSA+r1EOhsrD5wNPbnpI0hJBz6qwjOVgMJwMYjewXA4nOf4cdm4XnP7ccq1HqiiqXgJDpeDzgTO27E1+gsWB6VYyGE4Uh8OeqGQPPjgdTnYm7+SAasncw4M5Gtu2agXEKIdag88HLmdw7rqD4Viiw1gOBsMJsm2bdtVt+bTlMLBOd5rGNGXj/odJtuqSFtWkiiUMciqroeaTmxu6MQeApCPGcjAYToa9e0HV1cqhflgs47qPIykenHf5wIw5GCqL779XuNyhcwHc+TQz5mAwnCgXXwzDhoHfp615cepnc/167WupOgxIV70EhgpHKRAUDk/o5k47lZmtZDCcKGFhsDZ5CUfTvmDlAPCL//h5N14cnqp/NRvLoRaQk4PeZSqE/UpOv0XOil9Dlp7BUJvonrKU3xY8xIZH+mGtG8+0kU8A0K8fuPAx+YGqXwRX9eqpivn3v0O3OKy6kpkJzRpbIVUOz6y+lnX+8WzdtIitAzrQMLIhdw+4O2TpGwynMr2PfMvbvnZcnbmLHxjDvQ20y7nrroO9431E1qn6V3OttxxuvrmqJah4MjNhSKsd0KJFyNJ07RnEPUvDeS5zEZMHTiYpKylkaRsMpzpOJ/hxEU42VqHX8PecB1FRVSRZPrVeOQAcrkGOwefMKf81mZlQ59g+uOiikMlh4SDCp9iVkk24K/jd5QwGA2SGZZEbkU442XzxRcGJIjfxDtSvXzWCBVDrlUMMqWR+ubCqxQiasWPzvfwGS8JBC5fy2psxhAYLB1Fei5zwbH5dJPmexAwGQ5ms3J6N+0BPwsmuFquhi6N6SlWJ9OB3Gr0yrarFCJqICL0pebAcyTjCuc9NoE5U4W2/Tw4LB3VyFRM2ZLF0+KOwdk1I0zcYTmVyvAq/ctORrfbGDtWPWq8cWjXI5EBSBACzi+xkXf2IioKMjODjp+akEr5zEOOt0G6TYeGggT+dV+fD8/xZL8E2GAzBITDqhoY8xkN6wUM1pNYrh96ejazbqX0OXXttFQsTBEeOwOefBx/fZ/nwWApfiMcFFEIWEfRgHe07OFCmW8lgCBqFIjrGyQoGQHjBZ7N5aI38E6bWKwfvwSOsozt7U/ZBnb1kejOrWqRS6dABepRjt89srw+PZWF5QqscLBw4sFhPD1LSnajyDoQYDLUZAZer+O6kPXsqWZYSqPXKwYeLpHrHuG9ePLT/hsd/eqqqRSqV9HTtJylY7pzk5ZLGa+h2ToOQynHRxVo5PPssjBnrQPmN5WAwBItCcXrf4pVDdRmfriZiVB2dOoI4fJwe1p+6v12BL7f6+gt67jk4dAhSU4O/Jj3LR7QvG8eoESGV5alntHKYPBkaNHJiGeVgMJQLp6N6DkTnUeuVQ7NmsJwBLJq5hNt4E8eqFVUtUrH4/XDffXoXtksugaVLy75m7lxY97sPKzf0f7OFA0ErBE+4wygHg6E8CEg1naWUR9Wv0a5ilILlMgCUh2VhlzMu4esKyyczs+yFj//b9j+eeGU/Z54Jn3wCUx/U51etBvpAXA+IWhjGuLOGsFe1LDWtK+/6Dbp/Tq8WztAUIoC8MQeA5SudRDczYw4GQ7AoFIKwdm1VS1Iytd5yCJxk07WHkw3rLZIqwBPE559DmzZlx1u4cyE/vjWcLu7hbPvfcOomDWd4++GkrBoO24fTTg2nXafneYCnyl7a3WUubVaM5PpGTUNShkCU5CuH/33j4HCCsRwMhqCxLYeePatakJKp9crB4YDvvlNERAj/928nDhRpaTosJyd0+dStC507FxNgWdpEsPFIJKS2pGVsS0htydqfWpKVoD+ktmTyzS1JjlD8c7AP3n239EyVk96pSTjHjQtdQfLEVoLD7lZq3dZBTpZRDgZDsISFa8uhOlPrlYPHrYitq/D5hNh6DgTIytJh4eGwalVo8rn8ckhIKMbLhNcLY8dy4AD89a8F8wY91nDaafmroocOhYvmX8xudyMOL/0Dli2jdb3UEo2I3qxB2rYJTSECaBCXX7Fbt3OSbZSDwRA0PXpU/zGHWq8czjwTXG6tHOrW1ecC3VP06xeafFLqL2Rri7/T6954pnwzhe1J23WAZZEaBpO+mMATz2SRlQX3DltLw39OZRrx1P3HFNqxnZwcmP/gT7BgAc04AH4PK/rdDnv3MuXY3/hiavEj1C58HC9YCGnQAOjTB4C27cQoB4OhHCiq//NS65UDIjidirathchIfSqv9R5SmqyBn+/n9xfiGd15NDuSdzBlCnz4vp/ESNiXtB6iE0hLg+YpGxk15yaS7o7nMy6nM39weOHvnJ84G+LiqDvjfvCFc8nMLjy6YQxvcQuL/70VHnoI3n77eJYNSSCWlAoojI1tVrVrL0RQvRcPGgzVBcsCBdW+W6nWz1bSKJ58UhCBXj28fLD1n7Rp8xc48xnwpDPlm0yeHn5yi+OGnefnh5X6dj/1uIexN6byzDNw8xU+9rguos7CgzgGPsOsWXGMapBNNuGceSb89GIk1zCbBBrj/OuD0L4NY/vDoT69+POzTxH/owuGwhrg9wxh6JYPyfhyBbFhsfTy/0E8nzDp5G9Q8dhmcdu2kEv+zlU//gi7dsENN1RUxgZDzcXvB3GoU6NbSURGiMhmEdkmIlOLCQ8TkY/t8OUi0sY+f4GIrBKR3+3vc+3zMSKyJuCTKCL/Ki2tyuLPMTdz5H/zad0a8KTDonhee1GbFEqduH85v+UH5cSBn58/P8aW7XqZc2y0nzWuLqi9g+mbvZNO/EG97APkEEbdurBmRyx3dPmR/zAWZ/s2x9O7qu/5sHAmLIon7Jd4WC/AuscAACAASURBVBRP5IpHuefIOYzqOIpNiZs4b/EAOg2KO7kbEgRt2oAP9/HFeUOHlj1WbjDUVvx+9Gylam45lKkcRMQJvAyMBLoC14hI10LRbgGSlVIdgOeAJ+3zicAlSqkewA3A+wBKqTSlVO+8D7AbmFtGWhWDUsfnHAP80vUWEg5aeL35zhLT0/X3iy+C260bzMuWlSsLflri5aKRDjqwjTf8k1j8s1YOs97zs/Ks71mccCd7aUEWkbRKWkMqdWjSBGjbFveGtWylU4E0mwbMTu3dW397LScOLNwON16/Fx8ufvjhRG5K+ciTJdBbrNdb8fkaDDURywKPL/2UsBz6A9uUUjuUUrnAR8DoQnFGA3ltxTnAeSIiSqnflFIH7PMbgAgRCQu8UEQ6AY2AxaWlVZ5ClRel8k28IUPA7/RDxFFyvF4GD9Zx+vSBZ/+8i2EsZBgLefaShfDHH0Glv3Ah9JDfmNdxKvc0+JCtVje27U+CiKNI5GHqHm6G91hnEqQxe2nJtn98QoMWkfmbQYmwbVtxcuvptnNttbp8uVZcbqebbF8uFg7CwopeF2ryFvalp8Ozz0Ijx15u2X97uTclMhhqAwkJsG9HTs23HIDmwN6A4332uWLjKKV8QApQ2NPblcBqpVTh1QPjgI9Vvs/nYNJCRG4XkZUisvLIkSNBFKMERApYDmFh0HJPS+jxIY2yzjnejRQWBhN5HR8ufLg4lOiCN94IKguXC87snY5jWjyXrH6UtJQu7Dvggx4fktP9M94e0w/LgtmPXgzbRnL22bB3L7RqlZ9G+/bFp+3xaBcgeThSkvFkZJOWkkXjxpVX+RTg27qTKVNADXyBub0/xtmwGI1mMNRydu2CHan1TgnL4aQRkW7o7qGJxQSPA8q9zY5S6g2lVD+lVL+GDRuelHyBloPHA522doIVd9NBLsTKyKIZ++ncYhPbmyeyuHk4TSaHs7hhA5ZtrBNU+qmpEOnMhehowsPB7XPDiknU23o3sSsm0DOyFSIw7uz+3D9uIPXqlb8Mf/oTdOsGu9qdi/vd9/n992x6X9qq7AtDxAa641+1GKvpChp128U5W2LBGcJVhAbDSVCdthsJD+fUGHMA9gOBTnxa2OeKjSMiLiAWOGoftwA+AyYopbYHXiQivQCXUmpVMGlVBh6P/r72WnjiCbgs/H/0b76fXMftZEZmQGQig85NhMFP87+v4auvyk4zLQ3C0hLB4cDthnbufQxhEX16K/7S4F2996fN00+fmNx+v3bKN/ip0SR81YSRCy5Costw5BRCcvCw7ODXnNPiCaZ++yvid3LRJT4SEipNBIOhRLp109/btsG//lU1Mvhth89xcTBs6KmxCO5XoKOItBURD7qlP69QnHnoAWeAMcBCpZQSkbrAfGCqUqq4VVrXUNRqKDatIOQ8YQK7lTweaMtOGiZtxumEWHcmYV3ak5Lp0BbF1lFc1GkUHGsDwKjrt/DCD7OZ/ftsdh3bVSDd73Z8x+zfZ/PdoQ/Z2kin73bDzf43OY/v+e6seO6efSZcffVJlyE9Xa/CBvjzxvtIODiKpMGXnHS6wXLm8Gi86Ul03dWYNhl9iItRRMX4OKvJ1kqTwWAoiU0pv3LuxUfo2BEmT64aGVq31oPRPp89lbWmWw52v/8k4GtgE/AfpdQGEZkuIpfa0d4CGojINuA+IG+66ySgA/BIwLTVRgHJj6WocigprQojsFvJ6YSHeIzB29+FjAyuu+gY7Tu7sZSDLCIYOVK30AGc+Inq8RrddkG73VlMf+ZZ+Pln/cnKYv6W+fRt2pfoY7142n0hoJWDz3Iw9o8ZyPRHkQvOD8nuHvXq5Y897KE1yxiEu27lWQ7t2jlIdUXh9DvJtdw0ivbj8Hj5g+IcShkMlYfXC5z5T37Y/d3xc1XRzZSToy0XrxdwVH/LIahFcEqpBcCCQuceCfidDVxVzHUzgZmlpNuumHPFplWRBFoOAPtpQWbzTvDKK9SNcOKpG82SJnE8u/FBunTR3UQuNyxmMD3Vczx983AuuDSKJUcz4Zx02LIFkpJITY4lJvc03pyRxQuP6/UGHg98+632lxRKXnjh+Jq047jdxcetCFwuyMj14/A7WBE9lH45i5GlC3FipiwZKp7X527E12IRd/W/s0iYxwOMioNun0B93bN949vQsWPRdPo06cNFnS6qEBmbNdNu+y0LRKrRIEgJmBXSFLQcACZNggkv3Eievvi7snh2jKLOdH0cGQm33+zmlYXnAsuBEXw9PxfOXA/Dh7M5pQmr3tnK20fh7QkQje/4m1oEzj8/9GXIMz4sS/dpJiXl93FWBg4HrNnop73fyfsxdzLwvdMIP/+dyhPAcEqxbh3lcmf98Js/MfSaNdzVH1asgDPOyG8sRZHOOZnLGbp4JOkZen3RdS0V7WO6wZgxBdKZ+dPMClMOLpfuUrIscDhPjQHpWseLLxZshTvEQeoxJ3H2YmOnE87o3JzbP5zOxdcc5PrrAcsFDi+LFsHvW8P48tP8mTqTJvp0zagERPRWolC5yiEuqgG72u6iQ2MPGRnQILoRG3qsI34oPPDtAxzJOInpxoZaR69e5YvfrLnFgf16U6sBAwouwmzEYdqc2Zyfz53ODGs6bf9vOtvGTce18Q9cDleBT0UiAkePwuzZkJlV/d1nGMuBot1KJRG4oOzG3jdyo70ymYkwfLiD699SDBsGrQljGPnK4b57fPBD5d1qtxuSkyEmptKyZOqwu2l92QZ6Dcjm0Q3Qo3EPrvziQu51bmF+i0EcTD9Iw6iTm3JsqF1YVnDDcV4vNGuuSMzJj5yayvHGXCSZKLcbrxfee09bFaNHCxddU0GCl8CqVTBiBLRtbdGln7EcagSFu5WKoyxfQePH51sbydTjTH5mGN/zJA8Q+fpzxXdwViB162oLp7Jwu2F35wupl7KbvDWJLnxYDjcOcWjfUgZDOQh2s60ZM+CP5UlEZRwhbxvHzz/PD2/JXsTlZsECbU3HxOhhweLIza34weo/TbTo1NVR7S0HoxwIznKYMCGIdOxKlUosk3mOrmzi+uV3E/HcP2D48BBIWr3J8TqICFfccYc+dmChnC4c4sBSZmDaUD4C91UpjRkz4Gz/94R5M1H/eh4o2KV6EfPJbNj6eJqlWdRvvw2bNp2oxCWTmKg96gP4ci1wibEcqj1KBWU5BMN9k4W7PomHkXeTQRTRpNG0U0woZqrWCNaud+B0WLz6qj5+kgdZ13O8UQ6GcvGPf+jvvHU7ZdGiBfQaGEZK3Q74/XA+3zJg938Y98CNvDjvRxKJI9d26RYeDnXqQKNGxSuBTMch3O7Qmw4NG0K7fT8xjXgGfz8dR1SEsRxqAsGOOZTFPy+dxktj4vn7lHrgyuEV7qyQXdiqK268eNKTjh//84OmbDhYn0MHjXIwBM/q1YArmx+XZgfVHXnzzXpR2fJlgtcnTOn8Ba8u7s62bcu5J347PpcPn9/i2mvz54UcPgzHjhVNy5XWjgx/6DfIcruh1baFvNM6nq8Gz4QxVxrLodpTAdr7vLbncf+cf1Hfe/Irn2sSv9ODpD9PP3587bWwZy9s2WyUgyF4Pl20Geflt3Hl0//iiSVPlBlfBCwBlIO5nyn8MfV4Y0lXIlLjIPogywYu47zOZ+D15rvHufvu/N+BRB+4iD4PhX57rLAw3dXVt6/u2gpVb0VFYpQDof+jhrQZwlOXTuX3rwaGLM2awDY6os49r8C5XDw4fblGORiCJ3YP/lUTGB45lSxfFhsOb+Bg2sFSL1EosFyk71uPz7UCUDj9Tlj8N6aqs5g47BLats33bjBlCjj9uQXSSEyEvau7QVKHkBfJFX2MHeEJ7EjbwKufbmDnsZ3GcqgJhKpbKRCRyp1KWl0IDy94vJq+xOzfZpSDIXhaL+acjv3IyYFFO5bw6aZPeWzxY6VeYqHAcnPf4KZ80exnqLvbDpHjayaefBLOOUf/joqCXH/B6XwPPpj/+6WXQlQWm4yez/HD4UTSIzaSE7ORKHcUpzc7PbSZhBijHKgZJl5NobCpfpCmHNqUelw5LNu3jHmb5zFv8zzmb5lvprgaiuJ388lrQss5z7Hit0yWfzCC+uElb3fbedNnWJkZTPmLi8yYFOKGvginzSO5XjJQ/FqJyEjI8WnlMN3uCW3cGEBxBZ+y6+5nQlokb67QbWNX+oZfBRuv4qpuV1EnLDiX/1WFUQ5UjOVQG3n//fxd4fI4Rl2Ord6F5ddLVmf/PpsWdVrQok4Lftr9E0ezKs0bu6GmIBYxzhwuXPIwXpXNgnnhrF1bcvQmCWtRF1/M/UPuJG7DNG699Gqm3XQWI7aM4v328UTFFl2AGhYGfp+elTRtmj73+OPgIZcEGhFNOjNmhK5I3XvAX6fChx/CO++ELt2KxCgHQ8gYP76o5fDkrBZYyo1/w3oA6obXo0+TvvRt2pfWdVtTwd7YDTWQZrIPz9uvkWZFgcNLs9wUrJ9/gddeKxLXsvT6IgtFvfB6JG7pQExEGPET+/KF9Th9/htP+MyHi1wnUnCx26ZN0Jvf6MVafLbjiI8+eJzVB1eHpEyxseAJE1wuuOGGsuNXB4xywHQrVSRdezj5VfXHSk8FYPp0dXweu6C3aDUY8lAKzmu5Bee99zKnwUR4fTUXJm9leWJ72L27SPyW9jZklrJwiIMHHsh3m5GZqbuPSswroLfgnXf0NsD38SzK4aIxCVzW/G/M21x465oTw1kD37Q1UOTQY7qVKo6ePWHE5XXwp+TPHc/bl1tEjOVgKMCiRZC0NwNiY8nKcfKs72+cziqSqKd3TLTyJzZ89hkcOKBdXuQphyefzJ+d3qiRXvBWEg5HvvXg8UACjXmeP6Na9uXBoRH8Yg1GHU0qOYFyUBPbnkY5YCyHiublT5vyy7xDxx/E+Hj9bSwHQ2GSkiCdaADS0xW33heL+/WX8ePO93ltk5ycf11xz/DSpdCgQen55Q1Wv/5CDn6cLGMQP7w8g+mjn0UtmsHXc1JDUq6GRzbA1pq1K6JRDhjLoaK5e2JzFjnXcufNA4hN03b+sWOnvuUQrOM4Qz5JSeAOGD92u/NnEeUph6NH9Z7Qt9wCU3iKmD7Fr0sIdrOrLl3Al5pBCrHExOhJFffeCxlEcfRQbtkJBEFU+iHtuKkGYZSDocI5u3s7Fs9fz/n8nY6rzuW++2DOnFPfcogNz2bPQ6/Bq68WdBNqKJGcHOhrT/93OgWnU++8CKCcLl541kdcHGzcqM9FkknCBeNPKC9RFhFksmtTJg04SgZRxz0KAyQSRwzpTArBgmkljoI+/2sARjlgupUqmlGj9PeB5Ahu5B3u3z+ZnvsWnLKWw+UjsgDoxBY2bvXAFVfAsmVVLFXN4O678wdvfX7tdj5L304mPaiY8tstMDQeLr4DRt7NoqGL+Cw5nmxfkC5cA9jbYhCTeIlJvMTlfMYihhZ4f/93TRvasZ2XX4bt27X7i1OwupZIrd/s5zF+4vDmZO7qf1dVi3LKkvfAbdoVwUTXMhInfk30W28gND7lVk5/9BG8/XUzIJnx8iGJPe/Q/SI1rNVYlTgCFi47HNC5M0REQrbHj3t/b3KXPwRD42nbFp5NHErfm+NPKJ9tHUfyNCNLDA+PdJBIQ0DRoYNwzz16gsUtt5xQdjWOWm85PMQ5PD/yeTo16FTVopzyvLO2N8/HzcTZqAHuxAPacjjFupU+/lhPkZzhjGdg11T+/FybSt106VQg737VJwlEOPts6N1LyHVZhPvyLfyISOjb58Trz6OP6u9WrfR34QWcDgfkpLei9QjtOzwhQY+HJyUVmDRVhO3b4bFC3j6Uqnk9E7VeORgqh3fegSwiuf7DkXjChMyIOBziOOW6lT7/HF7kbh6x4vnmsleOv0gO7PHB119XtXjVmryqkPcaTSf6uKY4fDSXTfXd1PdlAuDES9ucTfkbpp8gvXvrwWeABQsKhrVtC0eS36NNtp4W9fHH2gN/167w228lp5maCg8HrLt7d84Rsl2hGdiuTIxyMFQKesaJdnzm8WjXBeUekP7mG0hPrxgBQ8SQIfm/Ay2Gnu9M1hPzDSVSeOc3a8JNMHYsADPHX8Zp4xTX7zjAJF6kIUeIzE2Bv/3tpPJcs0ZvFgTQqVDngcMBR4+Ci3z/X9eMszicYJGZnm86ZGQUktsOylN2N856kD7H2pyUnFVBrR9zMFQOeV3uTqf+/cWX0HZm+QakU+9+iDqzXtE7xJcDy9KLkCpjzsGQTgcZ39wi/sv9fLnxD5qdBQf2w1HgQNNomvn9lbu5dw1izJiCxw+/m7/v+riz+5OxpT8/Xgbt3o/HiZ/MyDho3fqk873qKu3eorhhoXXr4N5b9/GntlcQ3TialIQs4lpFseMfu8ltqc2DkSNh8ffRDGgxANDTtM89Vy/OCwsDUloxuAZ2nxrLwVApuN1w5pn6t8cDQvkth9+3eFj4v/Kb5716Fe+ZsyIYuvl12j9zJ+3GvMHqFR6efdoDfv153fEbeL2VI0gNZMECaMyhEqcEeTz5rXInVsGR6xMkWq+3K9HVRsuWcOuvbr7yj+bbxrfxhv8e5kXdQmpEazxODx6nB2+2h7d+e+v4NRkZet+IwHUuB/bVPO/DxnIwVApud/7iVpfLVg7lmMq6bLnFD6el8v0juZz79/LlvX59vgwV/W7+8ScY1rQpO3YI7DmbIW0gJlnP1Vfi1AIU3vTCcJxnPA+xrXv3YsOUyrf+XBaok3RY5PPp9Tagx8SK2xkO4LRkP47ks0hxtoc90KIr9Ej+jrNbn60j7IG4sO+Px1+2DOrX191kaewHh4/0rJr3qjWWg6FS8HjyH+zISPDjLJflsG5jNo9duQkPwVsOK1fCwoX5xwGeF47jD3GDTuzyTJigj6OjdbcFwJJlDmM5lEHnoU2gYcNiw3y+/D2gO/w8mvdG33RSeTmdcLW9k++115bc7RhJJllE4PdrdxzFrXw/fDj/9+OPa59OOTlw/0s/IevH6EVwNYyaJ7GhRtK7N3z7rf7tdEJ0VPncZ/gtHxE5LpKGPs93f3wT1DU//lh0DDgxMf/3t98WHYQMFW3b6lkr0dHwlt3jsC/8SP6KLkMBNm2CMLLJcUWVGGfgQLjJ1gd/ug4aNKiczXLOi17BQZpy2WV6P4ZA5ZC3e1xet2Xe39uwng9vYgr//cJHhyYu2neteetcglIOIjJCRDaLyDYRmVpMeJiIfGyHLxeRNvb5C0RklYj8bn+fG3CNR0TeEJEtIvKHiFxpn28lIj+IyG8isk5ERoWmqIaqpPC2qaefrt1nBLsITrxZ9F86hPMWncN3375TalyloH9//aAeOgS/DJ/GNOKZRjwre9wEK1YAWlH07n2iJSqeYWfnmyKFt4n1Hu2mp8cYipCcDO3ZrgeZS6BrVz3bLZxsLuNzPa+0EvjtaCtmzhRuvhnq1SuoHJ56Sn+/+ab+bt8errkGeiR8R8aYCcTEernf/Srn3tuzUmQNJWV2hImIE3gZuADYB/wqIvOUUhsDot0CJCulOojIOOBJ4GogEbhEKXVARLoDXwPN7WseAg4rpTqJiAOob59/GPiPUupVEekKLADanGxBDdUPhziC7lYKd2bjc0ayvN5I+uWUMsmc/FZcv366T3nalcKjZzSE+tt5teOlx6fDHjwITZueVBGKUoIldPgwtBoXx+Sfp8GvM/gnF+Jo1BjuvDPEAlRfAruFAvnuOx3WrdkxUuq3BQ6Ums5feYKp71SIiMXi8cBDD+nfW7fC/v1AIYtzCIvw/X0atx8U6i4AV6cMftzRkvBePnJzw/WUphpGMJZDf2CbUmqHUioX+AgYXSjOaOBd+/cc4DwREaXUb0qpvH96AxAhInn21c3A4wBKKUsplWfwKyDPXoylrJpyspTl09dQIeippcF3K9XdsYJzz/cw5W9u/N6yBwpe4i6iX9XNushI+NtjR7io67n8siPp+ODDrJdTaPLyw3qfyF9+OfHCBGA5im9vNWyo3T98tu16mpx/OTkPTSV7z+Hi9q85ZWnVquiQyxdfwAUXwL590L5lLl6CdKVaRbRtqxW9KuTF2WEJGVMe4VHimZwST4vZT3OMulj7duLLrpm998FI3RzYG3C8j/zWf5E4SikfkAIUfuteCaxWSuWISJ49OENEVovIJyJiL5MiHhgvIvvQVsPdxQklIreLyEoRWXkk0JViebm72OQNFYxS5fPKeuaLY3F5PLijPFjeMrqi2nzPrOG/sWLofBgaz0sNF9GqXlNuvdlNVAN1XDlkJf/ED3f/SvxZPp5b+FiRZI4dK91NQmH8fsjOKWUxhTuL3dvDCXeFk+XLYvPmgitpT2WSk+HIsKuKrGHcs0d/r14NY0Z7GTzUXa1Xzbtc8OWXRQevRTlY8rOf++7TY2pt2sDXXEiEI40enWue6wyopAFpEemG7mqaaJ9yAS2An5VSfYFfgGfssGuAd5RSLYBRwPt2t1MBlFJvKKX6KaX6NSxhdoOhelMey8ESCGsShyvSg+Ur3XJwx+yhx6pBDF00DBbFM8MxlIn9JhIb5SEiNl85jLnoD3p7zyN+aDwp/swi6QwcCJs3B1+eNWv0oqmSaN/RD5aLCHcE2b5sXK6CG9acqsydq6d2+jrN4fDhgv93nvJ99VXo3C6XVh1KmE9ajRg5smjvocMSLr7Uh9sN33+vFUQ24Tgd2ZzRp2ZaDsFMvt0PtAw4bmGfKy7OPhFxobuDjgKISAvgM2CCUmq7Hf8okAnMtY8/QY9bYH+PAFBK/SIi4UAcEDBZzFDTESmf5fCUTKZT9y44Euri+qX0nkaXI4e4xhGsO9qTacQT1Ukbum6nm7kLLJ44y4cbqJOzn0PNz9bNwWJMhJwc3d/8+I/PkOVPx+GA9YfX8+Ylb1Ivol6R+F4vXH55yXLdc95V/HlWcxbNUuy95DX2x/zEmvp38e32y7ig/QVB3YeayJVX6m+xBGvJT3Bavo+RjAwQLBrHWYSTHfwOPVWMSP7MpOhoaL27NQx+kg/2C+EKflgEu4cm0JBjRBLqga3KIRiV9ivQUUTaiogHGAcU3nV7HnCD/XsMsFAppezuo/nAVKXU0rzISjcXvwCG2qfOA/IGuPfYx4hIFyAcOIl+I0N1JDkZxowRvvgiOOWgROF2OXDWq4MvrJRd44FxZ+7EcoTxGVfwKPFw220AeJwemndLITtdd3yHZR/h/z6uz/oNxSspp+WFw4f58vME2q28k/iud3Jhk7PI9Ba1MkB3Q5W2vu3C9iPgcA9m/6sni6ZNp9W/h9Jk7538/Nsxnn46qNtQ4/jgg/zfDkClpRQI/+gjeIKp3JL4BM6tf+hO/RpC3hqZ99+HlvtawKJH2Tcrnvih+pO16Cnu2NQH15BhVSrniVKmcrDHECahZxptQs8k2iAi00XkUjvaW0ADEdkG3AfkTXedBHQAHhGRNfankR32IBAvIuuA64G/2Of/AtwmImuB2cCNqjp3QhpOiCNHACU8/Pey/1rL0srBIQ7CwkB5ffmd1cXQ7NCvvHv0MkT0CzuPznGdiei3mjVpO5kwAXKdDrDc9OhRfDrj0t+Ed98ld81GVjw4B+bMwf3u++RmF+/8b+RIeyZLCQRObV2yRH9npnmY8Y9cHnig5OtqIjk5+jM+YJM2UeArZKBNnAj9zo7kMR7WAzCxsZUr6Ani8mVj7dkH6M2sCg9QAzz3Zgz+qQ9pR0s1kKDWdCulFqAHhwPPPRLwOxu4qpjrZgIzS0hzN3BOMec3AoODkctQczmu7qXsEd+sLIhrpHA6nISFQUrTLvDXvxZsltrk5EBueBR1mtfjm68LvmvqhNXh9DqjOfrzXN7/BP4x2gJLPwI5hRZe33MPuJOy6PXeWDLO3clK7uSVO+HXS5Yy7ZwMFs7Xc9oLU9qePnl+fAI5tN+NP1Znvm2bdvl9//1l3pJqT3g43M/TPF5vOe9FjWSzoys+p8JXqPsuJ8f2ubU4+LSrgyLdfNql9Ny4EWhRoCcscH7LrbdWulghpWaOlBhqPD5x4VBAEGMO0dHgCdeWQ2wsvL+wBcfiit9UPiUFnB5Fm9aOYn3lhNWLY1+ubsLn+C1mTtdPdtaBlAK+Nl58ETzkkt13Fvx+DaAVxs4dHpKTs4qdghrLMTwRJTuDq1Mn32LIY3riZHDqbq6ko4r1ry8t5sqaSRQZPD9QCA9LwHKncsHqFvgL+TDJytJDPl275p8ra8veJ5+sCGnLh+Vw4c/RZRGB8ddp530zZlSxYCHEKAdDlWDhxGEJdFxAak5qifF+2PkD9JzFwpgNOMVJo0YAipwcPQBceN78sWPgdCve/beT004rml5Olodtu/3QYhlrG+7kklFu5s6FD3cPYsuMjws4W/KQS3QDL+zVhuyLL4Lyh2F1/oLP1uY7WktPh5074Qrm0vme4aWWe3CATezGyxj/PGi5FHrOYsqb/8fgyPOYtW4Wn2z4pFpP6QwWyapH8+09YPuFND8Si1XoD9uc9h2zfb8y9cNZzFqnP9uStlWRtMHjQyuHZ5/Vxx06QEREjekVCwqjHAxVQo7fiWv7MDzZrVh7aG2J8b7a9hXsG8jl0pUrulxxfMB37z7hxhth0KCC8VNSwOG2cJbgo3vfHjc70yIZ3Pl+Lk88mx6NehAVBYk04veMtgW0Tc/uikaN4dM5+WmdbfUmev1FvLv0q+Pnvv1W7yZ2zhnZONu3ASj1xZ7nfiGHMA5m9oRF8bBvIOs+60WvfREMbD6AJXuW1NgtVAN7jnw4CUMXWCkHPl/B/ruj6S8zqOsFDGo5kIEt9OepC56qTHFPiLAoF7ff4uO776pakoqj5vmRNZwSHDzsxIWDy0e2KPISDHSzsHl9FH9K+oYrz2xJmMvu0K+3E7e7FQsWwHXXFUz32DFwuvT4RHG0ahTD471SGdi7D2n1n0YEuncHog/xvGsXEeKxcAAAIABJREFU639MJd0bBkNgWb9FJOXUJTYW/u//tFvnEadHsuv5Tcw5mr9t2bHsY2xt8gqpWyKD2sjH49Gb2g0f/ghO/HCsLdOmQXjSAdr/uw4NYloTFxmHpSwcNdCbZ27A+z+XMK7mY67utoEt0YeLWA4RPicdzrgQ6hffTVhd8US6cOHDdwrv21Tzap7hlMCPkwuG+Zn336IL4QL9HW3cCI1JIO7JKfkn957J4g2ZHDsGL79cMN2UFHB4KPGl+uhdPWDuLH5++AXuukufa9bs/9s77/iqirTxf59zbklIQkgghJK4AaVISRCCgBQpIuhrWUFFfrouurquu7Lq7sLqytJ9LYtrXxXFRV0LFuC1LlYsKAoIUpWO9BJKQsrNvffM749zbnLTSAgJN2W+n8/95JyZOXNnztyc5zzPzDwP8O7TjDt8CZN73snz4ybT5/PhPLizJWcuW0B0NPzmN/Zk85Gho1lGby47o3i32+7c7WzI+4Kth7OrHOVt+HD7DTsuzrGvK0XTqEL2H4+BQKBex9f2+eAf/4Dz+sExmvHb+NfJeGsy2aNvJhgI8Pe/2x5rlQKxAieexa+j7Njtwo2f1NAOsNMRZvA0o4WDJiIEMenaOUj7oyvLaA6HDhUHcA8GFSkpJWN8DuwXzabd5e+SvuoqEDNYoXCwV5ZIOZOewtLvvYjfz+EsYSiLkRdfoiBfiI62S0yeDD0HxtDuinMgrP4jRy3I6sCX53zC1O8eZOriqRzMq3xrjghk59jHl75zM603fUF0YhPw+zHEqLLH2rrG44/bbsovvBAuuAB+c5PQsZNguFwE/X5mzoTp022PuKYVqJfBjy64yE0zjvLHa7PsQNPlBQup52izkiYixCeajLkyyLAP/oJSn5bJD600CgYsjFKuPK8dE8Xq1wLYK51KOUAjiGFamHLy+n4hHigs5IYb4Faxt0fn5lIkHAY5C6/nz4dx44qva97Cgs0juf8XqQwf8AeIqTgmQWlc0R6m5E+l18o5vL+yNe27n13vhcM33xSPn8tVvOnZ5XKzc4dtVnroITsto1d+vZzFbdPLVm87rXgFVgCDB0e0PbWB1hw0EcETZWKoIIYCFfYQ/OtHf4UWG5g3zz5v6d+D0axkUJeOLc7ip46baHdGOQ/PkbezMzoXj1mxj541a8qm/ec/cOkoD6rAxxlnQGrsURBhyBB7CWppQtpOfj7cM8kCZXDBkGCVzUohZnn+xjSm8uqYhbjxs/mskfDYY8iSr+qNcMjOtnc6hzh8GJIdN5q9e9taAoDpcnP4cMk5B8MKlh+8uY6T2iGKf/EHe2PD+PEwbFikm1TjaOGgiQhZ3jY0f/FhRIFlFZuI1h5YC4lbipahdmx+iCvmlvQQP6RTL/yeAH+6w2LyZFi0qDjv/Mw4nvKOwm1W7KOnvBDF114LlieKQK6PadMomlV99llnTqICcnOxN/IpA7GC5QcsOAGh+VnD42JAr3x2tz0Xpk3DKPDVG+Gwd6/t9TzE0qW2SQns2BohzcF0mXhcAfryDReyiAtZxNGfj9Vbe/3VV0e6BbWLNitpIsKSxEv5+bZLWXksi85hax/VwTTOTf0nn3/3BBuS+5J2vC1N4sq+jUdnN+UTaxp7zaNMv+Vq1PZB+P1giDrpB3QIiY7i2L58JkwAmiSfuKzzt6CAIuFA8OQ1h7w8eOwxMFe7MP0FWKYbRDBU1Z0S1iVmzIB+fM2fD74NAT9KFW8L75rQg/utB2g5eAGryKBZPBzbdN0JaqvbhLTbhorWHDQRYcAA29RsuaII5hbHVVa7Fd0+uZbf7+jLvcOn0jcrA5e37APXteImZnwl3PiJcH3iJHILczl6zCLKbZ30AzqEREfxhxvzq+gEzxYPeXmABOnf02drG9V4Cx4/HpTpwsotYPN2F7t3g3ESIVQjjVIKy/Bx+GiAyVMDdGQjcuvviicWHNJb9+W2z5Lpt3gEW/47hzZ5c9i1/s8V1KqJNFo4aCLCI49Ax45gmR6ChcUrPZSlyKZp8eIPq/yH/Xtcwk/XzeD1qFnsjYriga/u584X/s3RI1a1NYdgfCKXZO5j2bKqX5OXBx3kR2a0/Fe1Yo527Wr/XfSJi91b8nnz/1ykpEBerrBgYf0QDt/t+4pdQ4bT4op7YdAMe9NbOb5Lgt4mJHCEtXTD64Vf/cp+SdDUTbRw0ESUr752s2d3sXDwuKFFS7PIi8XmjcHioNCl6NAB+vb20uebgdzW61Y2bvXh96lqaw5GQjwfv++jR4+qX5OVBXfcWoAxdBjcdttJf2docjwQE88FfMzm7W7at4fcHOGt+fVDOFiGj4Jcj2MGE1rEFZYrHPLyIJbjnPdL22Q3eHDD8kXU0NDCQRNRLhhuEhNVLBx+WGlx+51GkeYQ8JVvx58/H9LT7YfLwCFuzKBFl65Beveq/pxDk8Qooig4qcsvuADcph/jBBPgJyJkhdrXqgeD+ILY1AS2boVDB+qPWSkYVKCKzWmxHl/Rxrbw/STt2sFaunHJTa0ASE1tkCtAGwx6QloTUUyPm2CYS4XCQkV0rEkgYLvEjneXLxxCEddEAJcLI2iRlx8gSY5CVPU0B2+8LRyqggD79oXa7MdwndpGrthYWEe3ote1w4eED1YXsGDDghLlOrXoRJekLuXUEDkCQWdCHpC4neS3XcOCHWlgmuQW5haVa9YMZiQ9zpjekWmn5uTQmoMmoojLVWLOwUDhiTaxLGjVCqxA5RPMQcONEbBocmATnh2bbN8U1WDpD9H0Z4m9vbeSieVt24unGFo0D2CYp/ae1bNn8fGIEeAxBZLWs/HAdtontC/6/Gf1f07pe2oDS4U2IyrivhzPkcJBtG/RgfYJ7fnLeSWDUxQU1MsN0Y0SLRw0EcVwmQT9xcJBsDDctnBo0gS2bq54zqHoGo8b5VO4crJQ6emQklKttqR2iOJ2HrUX6U+YcOLCjuxISoKmcQEM16nFPv7b34r3PDzwACQ0A9y53HVTZzJaZRR9TrS5LxJYVrHm8D+8y7tHxzOwTYei9ibHllwSnJ+vhUN9QZuVNJHF2wSVV2x6MLBIaG6wZg3EDMH2WlqJ5mB4XATzLSx/AWZs9Xfbtm0LXYa2htTKy4bw+cAKBKo95xBOaK7DsuDnHQLuPMhvfsr11iZTpsDKXHvO4TixnMkm+v254jjQgQAlIqdp6i5ac9BEFImKLqU5KNxRJkeP2S6KDCo3Kxluk2B2AX7Lj8tT/fedQKDqC53cfjcMnsrVf7+FN3e8T1xUOT42qkmzZmDlJ9G/410YeSX9DkXKU2tFX5ubC7J/N30L17I9zsufeQjXxRUHPHrllXq7IbrRoYWDJqIYHjdWoW1P2b8feqQrxGU/oWOjg3RL3FvpE9sX25yli/LIL/RjnoLtPzMTZpYb8bwsw7/vT/Tiidz7RZB/976Xzpkjq/29pUlLg/d+nMM5b97Fi7/4osbqPRV69HB2g5fCssAVzCd6yXh2vPMhrzH2hPWMPXG2pg6hhYMmoojbg+X4MRo0CAqO5BcJgzOC2xh7+MlKXzULAi6mTYFde4OnNDHcvDmce27VyiapAzzCHSTdeiWMHFnuuv7qEuruxE2/JT3/WztIRVFeZF67d+6093SEs26ds0NcBbCUPWbPPHP626apHbRw0EQU02USdHa8xVnHaJ39E/TowTkZimbRTjzNSh6IQWXgwkIkiFkDtv+qEFd4iE8ZilxUcxpDOD4fpJ7lZWdKvxKxAiJlVhqT+zwvp0zE/7/FvkW6dbMdEwYKg1jKhdcLv/1tRJqnqQX0hLQmorjcJla+/cAbfnwBXyX2hthYDkal0sa/g983mcu/KqnDb5kYWBhY9GqbWfuNBrAsgtRejMiQIqIMk6Lt4hEgEICCQAFfXvI4s62ujDpsEQro+f94mQSO4CvYwhGVUR8DumlOgNYcNBHFMAx8PnsncBQF5LntCdiDwUS6bl7InsIWldbhDxoYWAz/eBgXnFXxZGhNYhKsVeEQ4uulRgnhcLrNSm3aQHZBLr13CdbWEWQV+oryOrKRfxp/IeXnLxh0vkvvdm5gaM1BE1F27TZ4621F0AtRhg+/Y7te0vwy+lzdkxtvq3zPQq/eBv9+5fSGafSYQS67tPaFw4HDJTWH021WyjmYT/aOnewPnAGWi9zC4u9XCB7LR47EEeN1YTa8SJmNGq05aCLK4cMGgsWePRAtPgqD9gM3r9CFr3Ual42q/P2le8v9fM7gWm5pSUyCjBlb+/8+QUxU0Nas7rqr5uvfk7OHYwXHKsx/kIl8/uDLrAr0A8tFga+sv6coySP7uKuyvYqaeoYeTk1EEdMEsTAMOLC7kI1bbWHw2WfwxhtVrMTZPXZF5x9rqZVl8Vg+TE/taw69zzUI+IIcPGjvnK5pJnw4gfu/ur/C/MMkcm98Dnu3Xs+sf5jkh2kObRPyKRQPSeynXXsXs2bVfPs0kUMLB01EMQ2DYKu1xGd9hh37zLapn302/PKXVa3EZD5XsPCa1yovW0MElXFahENqmknAFyx6K6/pOYcP552F11X+TLJSEDQsdm5tAsdbEx9n4gsWaw5+VzQAORJDWnuTtLQabZomwug5B01EGdU/jaYfbWXt0WmM6DwEw3n4rVt38jtpA6fR5u0yLQxX7b9bGW6TQKHFihX2eU3PORw6aE9pBAJlPZ1nZcGx+KNwpBNRURDlceEPcyNuGM4OdlGc3aX2BaXm9FKlX7eIjBSRn0Rks4iUsXyKiFdE5jn534pImpM+XERWiMga5+/QsGs8IjJbRDaKyI8iMjos72oRWS8i60TklVPvpqauktjcRcZek6PBWPLzFJbz7DspweAUPp3C4fwhJmLV/hJTMQ0sf5C1a09c7pZbTr7u/fsBhIULYerUsvkqFKahIJ7mzcHrMQlYCsuCtAvf58vuy3gmM8D2Fr4a8S2lqVtUKhxExASeBC4CugBjRaS0Q/nfAEeUUmcBDwMh6+gh4FKlVHfg18BLYdfcAxxQSnV06v3c+b4OwN1Af6VUV+COavZNUw8QQ/DgJyjiPNyrbzY5ndsBDPdp2n9gmqhAkE6dYMgQyM8v//7Mnl2x/6OKaNUKQLF2Ldx7b9n8YBAUgDJ4803wuk0KLQvLgh3Wl/Ta1oXLf4IPu2Qj2tVqg6MqmsO5wGal1FalVCHwGnB5qTKXAy84x28Cw0RElFIrlVJ7nPR1QLSIhAycNwL3ASilLKXUISf9ZuBJpdQRJ+9AdTqmqScYBuI81OLjoXt6NcwmStGt62l2Bd2tGzStOWd7FWKaWAGL2I8WYH3xFe++V/H9yc2tMKsMeXlhJ7H7YMhkfAFfiTJ+P2T0sGM1ZGRA89h4Pmr6Bf9Y+BcIemhaEENKNuxUaUSfnX5y/dLUeaoiHNoCO8POdzlp5ZZRSgWAY0BpX8Ojge+VUj4RaeakzRCR70XkDREJOX7vCHQUkSUislREyvVPICK/FZHlIrL84MGDVeiGpi4ihtBCjtCho6JlS7iiqpPQ4XTrxpmTr2XKlBpvXsU8+CAMHFj732PYZqVvH/2GocEPUQW+CovGxVW92mKlR+Ddp+nePpmcwpwSZXw+aJEEPc8RoqPhvF+cy3mJX3Lg62VAmKby5Hpax7Wu+pdr6gWnZbWSiHTFNjWFLKMuIAX4WinVE/gGmBWW1wEYDIwFng0TJkUopWYrpTKVUplJSUm13ANNbXE8z0Asi9BzplqrcTp1wrx6dJXdbdcnxGWbldbRlfbGdvrufwfKeRl6n4tw4a+ypSsQAMRi4AD7EZCaYpSJWf3II7DhR8XECU4IUIGJD7cmenciFCTg+EvUNFCqIhx2UzL8SYqTVm4ZEXEB8UCWc54CLACuV0ptccpnAXnAfOf8DSAUKHEX8LZSyq+U2gZsxBYWmgZIXFMhh3ggMg7l6jo+y83/u/go8Qkmb7WbwM+eM+1X+lJcxH85g5/ZsKFq9QaDgBFgxHCTIUPACpYVDs2aQfMkVUJgKwXXqXRYekdRM+bOrWbnNHWaqgiHZUAHEWknIh7gGuDtUmXexp5wBrgS+FQppZw3/veAu5RSS0KFlb0e7x0o2tY6DFjvHC8MpYtIC2wz09aT65amvtAk1sBE2atiNGV46cNkYjhO/pF8PK0SyToixfFES9GLFfxYxX2AH2x5F4ZO4pzW5/Dpp+AyygqHjAzo1BkMKfmYCAbtwcrOgUyW8+tfo2mAVCocnDmE24BFwAbgdaXUOhGZLiKXOcXmAM1FZDPwJyC03PU24Cxgsoiscj4tnby/AlNFZDXwK+DPTvoiIEtE1gOfAROUUqU8yWsaCoYpGMo2KykVOZfUdZXJ02yPs278WIYLC6PCNbt5NOG//61avUvW7IRv7uTiDhcDIGIQLLU0t7AQDFMhpVaQhX/9J0d7Vb0zmnpFlTbBKaXeB94vlTY57LgAuKqc62YC5cbWUkrtAAaVk66wBcyfqtI2Tf3GdBv2zmjRQqE8osTHNbzGVwwgaLhtT7ClhENODqyjD4dowXtz4LnnStaRuy+HqNfmYt4xnsLC0P6FIAMHFE/StN+2GOvHFOhTbEH25wcQf34Js9KUKbD0KXj4YUh+yl5hpmmYaPcZmohimILpmDNEIhfprK4SHcjhat7AjZ8ALgKuIHtz9pb4HM7NwRvjwk355qZ//GU/ByY9CsBTT8E990DTeIvf3VIsHMwtm9n9yboS1617eRVWu/ZlzEr7D0BiYg13VFPn0O4zNBEl5IJCoVizJsKNqYO4TVtwuvFzy21uZt6dzsKdn2AYm4rKfLN5Pb8tdJHWNsBXpZeKAK+/XMjVeGiNLYCfew4yXEH6DSoWDrk5Blu2BDkv7LqvF/u49IYWJcxKIvbSgeho0B66GzZaOGgiiumyNQeFIutwpFtT9zBb2cu0vWaA/7ncxd7PRzFu44e4Rhf7y3jrw6nk+t20TgqUXUcIeCikEDu03F2353ED/2bVl1/QLj8IW+2dg5nJe2ieWPJx78WH8rpKaA6hKSGXC4LaFNig0cJBE1FMt4GBImhBk2h7fbOmGLNnBo8xnrtHbwSXiyMp3QlmLyz6x73sMlicU8gj7KYNe2jFXjZvbs1ZZxXXES4czmQLeTRhlXQn54KroV8TALK8BbRcZ2+xDjnh8+KjSbybnDBT39y5MA4wc7NxW3qjQ0NGzzloIoqYBk2bWCgFAwZEujV1D68Xbucx/M+9CCK4vQZWQJGfb+e/8w7EkcNj/JGmMUEe5XYWvFpQoo6BfElcagIA0eRzgJbkSTRmy5bQogW0aIHRNJ5goa05uN3w9NPQl6WoFoklzEpNbFmCO/co+2LPQtNwabCag9/vZ9euXRQUFFReWFMuUVFRpKSk4HbXosdNEaJdFpZStj1bL2UtQUyMbecPDYHHY29gS24BaWmQSBYX8T7HOI/vuo0lakk2qYUFQLGjqThy2N++H2djx+kuIAqMIK6wLeVuj4ttm4s1gVtvhfnpgmrVCiO/2N4X2vhm+vLwmU1qseeaSNNghcOuXbuIi4sjLS1Nr4CpBkopsrKy2LVrF+3atau9L3Ic7yn7UFMOShULB7cbLMveg7B+PfRmC2ewk9juwn4vFBCF6S/5QjRoIIiyUJ9/wa94iRn8HeQrrECxcHB5PKz7IbvEdU2b2gsFwv9/tm61hc25P8ymyVVX1l6nNRGnwQqHgoICLRhOARGhefPm1LpTQxHEsrCULRz0eJVP6CU/pDm8FhjNGrrjIsBWWtE+qPB4oCU7OWPrYmxHBjYigFIE9+znUW5nJ2eAKJJbFktjIyqKJNlfwu33l1/BhcoqYVa64Qb4y78f4s9zQFsBGzYN+l1NP2hOjdNy/2JjkVdfw0JpzaEC3nmn+NjrtSeM19CdaUzl78wkm6YEArbL8s85n5zs4id8yBGfJSaB/EL+cIcHOr5DfLvNtG9fXG98dCJrWll07Aid2UAsOfQ519Ygw1cr/fGPtd1bTV1B/ztqIovLBQMHotTJhwVtLFxySfGx1wvBQPHDv39/UAjnD1LccgscoCX7jhbPN9x/PyxbZt/bn37wcTjXC21WcPT5/5T4jnNa9GV/rOLazVO5l3sYwme0b1/WrNSjR+31U1O30MKhFjFNkx49epCRkUHPnj35+uuvAdizZw9XXqnttSFEBEspDENPRldGVBS8t9CPH3sS4oEH7Pma5gkWKSkQxMTyF/tI2rbNNkn5xcOcx47z+VIvv/992Xpjorx84+rJNKYyiZlEk8+xY2Apq8wOaU3jQI96LRIdHc2qVav44YcfuO+++7j77rsBaNOmDW+++WaEW1d3EASxAiTsWV954UZObi4kHPgRP27atLHnIKKjih2eJ7c2iWtSLBwCAfAYAbb4z+By/o+/zYimvPAnvzjDIBSSL59oosknOdk2K5V2vDd2bG31TlOX0MLhNJGdnU1Cgr3WfPv27XTr1g2AuXPnMmrUKEaOHEmHDh2YOHFi0TW33normZmZdO3alSlhYc7S0tKYMmUKPXv2pHv37vzo+Gk+fvw4N9xwA927dyc9PZ233noLgA8//JB+/frRs2dPrrrqKo4fP366ul0lRIRVrS5k6e2v6qWslRATAzv4BX7c7NkDx46ByyUoy75vLm9JzcHvB2W6eHj5QNLYzuCLK15+KsoFg6eya/Bz5A++n6eTPmbRlkWcmXhmiXKvvFI7fdPULRrsaqXSzJ0L27fXXH1paTBu3InL5Ofn06NHDwoKCti7dy+ffvppueVWrVrFypUr8Xq9dOrUifHjx5Oamsq9995LYmIiwWCQYcOGsXr1atLT7Vi9LVq04Pvvv+df//oXs2bN4rnnnmPGjBnEx8ezxnFSdOTIEQ4dOsTMmTP5+OOPiYmJ4YEHHuCf//wnkydPLrctkUAQflgjZHVzQZtIt6ZuM3QozKUvh7E93/n92LEwHOEgLjM8Bij5/gJ8Xh9H8gqxvDlkB/MoDJa/s7n1pkns2QOX/BL8C3sxqdV7xAz731rvk6Zu0miEQ2UP8togZFYC+Oabb7j++utZu3ZtmXLDhg0j3vF93KVLF3bs2EFqaiqvv/46s2fPJhAIsHfvXtavX18kHEaNGgVAr169mD/fDqj38ccf89prrxXVm5CQwLvvvsv69evp378/AIWFhfTr16/2Ol0N7AlPxb59YHTRs9InwuuF1xmDYcC2LZCSAq8+Vaw5lBYOC3y3kTpyJzk/xTCPHJqsnEOXpC7l1h26LC4OXmIUuY+OIqbWe6SpqzQa4RBp+vXrx6FDh8rdN+D1eouOTdMkEAiwbds2Zs2axbJly0hISGDcuHEldnuHrgmVrwilFMOHD+fVV1+twd7ULIKAKPx+8FZevNFz6aX2AzwtzT4XoUg4YJYUDmS3ZXxcCnOWTeCXgdfo1q/iMCk+H0yaBOnp8NJLevVYY0fPOZwmfvzxR4LBIM2bN69S+ezsbGJiYoiPj2f//v188MEHlV4zfPhwnnzyyaLzI0eO0LdvX5YsWcLmzZsByM3NZePGjdXrRC0hIvzuVsWgMqGfNOUxYoQd37mYYs3h4ktNUtoUCweTAG4jiN/w0p2yWms4l14KEyfCVVfB9dfbWoqm8aI1h1okNOcA9hv8Cy+8gBnmz+ZEZGRkcM4559C5c2dSU1OLzEInYtKkSfzhD3+gW7dumKbJlClTGDVqFHPnzmXs2LH4HMc4M2fOpGPHjtXvWA0jCG3bKi4aBN8ujnRr6j6GYbvQCHHcW8jHnuVsWx+Hq99Rkvb4ivJas4+UX17KGCDM4lguL75YfPzCCzXbZk39QwuHWiQYDJabnpaWVjT3MG7cOMaFTYi8++67Rcdz584t9/rtYTPrmZmZLF68GIDY2FheKOe/eujQoSxbtuzkGn8aERG9Sukk6NnTdqYaYuzadALJyXRu0ZlX175B7t4gA528BA5jdu7I5Mnw8ccRaa6mnqKFg6ZOoYVE5fTpY39CJBbEEFfYhm4tu9Emajlfr95QlJfGDujQgXYGrFwZgcZq6i1aOGgijiAotFCoLk2bCk2cZUUiUXiNnKK8Y8SB240JJCdHpn2a+okWDpqIE25W0s4ST57MTOBs+/6ZTZrhMovj6aX9IkKN0tR79GolTcTRmsMpYhhFwZ3PTPPgN7WA1Zw6WnPQRBwRYU/OHqYunkpidGKkm1P/sEPoAZAa35b1XdYzdfFUAlagjF8kjaaqaOGgqRPMvnR2pJtQv3GEQ6cWnbjog4uY8t5Upi6eojUyTbXRZqVapCouu1etWsX7779fdI3P5+OCCy6gR48ezJs3j5tuuon167W3Us0J8HqLQ8UBo5iPUtA9qSftcltGsGGa+ozWHGqRcN9KixYt4u677+bzzz8v4bJ71apVLF++nIsvvhiAlc56w9B1Y8aMiUDLNfWKf/zDDprkkM4aJk2GCRMup222Xr+qqR5aczhNlOeyu7CwkMmTJzNv3rwiTeG6665j2bJl9OjRgy1btjB48GCWL18O2Jvc7rnnHjIyMujbty/79+8H4ODBg4wePZrevXvTu3dvlixZAsDll1/Oi86212eeeYZrr702Aj3X1DqlNAeAn9YFKCgok6zRVJkqaQ4iMhJ4FDCB55RS95fK9wIvAr2ALGCMUmq7iAwH7gc8QCEwQSn1qXONB3gCGAxYwD1KqbfC6hwNvAn0VkotP5VOAhHx2V2Zy26Px8P06dNZvnw5TzzxBADJycnMmjWrxE7pELm5ufTt25d7772XiRMn8uyzzzJp0iRuv/127rzzTgYMGMDPP//MiBEj2LBhA7Nnz6Z///60a9eOhx56iKVLl9ZU7zV1nA8WFvC3xFjOWwPnRroxmnpJpcJBREzgSWA4sAtYJiJvK6XCDeG/AY4opc4SkWuAB4AxwCHgUqXUHhHpBiwC2jrX3AMcUEp1FBEDKFqmIiJxwO3At6fcwxAR8NnHfQqBAAAMQUlEQVRdVZfdVcXj8XCJE1C4V69efPTRR4Dtqjt8XiI7O5vjx4+TnJzM9OnTGTJkCAsWLCAxUa8Eagzc3/ZxonYXsHt3bAkfTBrNyVAVzeFcYLNSaiuAiLwGXA6EC4fLganO8ZvAEyIiSqlwg+c6IFpEvEopH3Aj0BlAKWVhC5IQM7AFzIST7lEd5UQuu6uK2+0u2iQW7qrbsiyWLl1KVFRUmWvWrFlD8+bN2bNnT7W/V1O/CJheoiig9aE1WN7oSDdHU0+pypxDW2Bn2Pkuit/+y5RRSgWAY0Bp39Sjge+VUj4RCTkcniEi34vIGyKSDCAiPYFUpdR7J2qUiPxWRJaLyPJTeeCeLipy2R0XF0dOTk4FV1WNCy+8kMcff7zoPKStfPfdd3zwwQesXLmSWbNmsW3btlP6Hk09wTQxsLgo8yCZt/WNdGs09ZTTMiEtIl2xNYFbnCQXkAJ8rZTqCXwDzHLMS/8E/lxZnUqp2UqpTKVUZlJ5EdPrAKE5hx49ejBmzJhyXXYPGTKE9evXF01IV4fHHnuM5cuXk56eTpcuXXj66afx+XzcfPPNPP/887Rp04aHHnqIG2+8UTu2awQoMTCwiI8N0uYMvSBRUz2ksoeFiPQDpiqlRjjndwMope4LK7PIKfONiLiAfUCSUkqJSArwKXCDUmqJU16A40CcUsoSkVTgv8B5wBYnD6AVcBi47EST0pmZmSq0oifEhg0bOPvss6t4GzQVoe9j/WNGhxeZu7k/T/5xI+cMTSD5cq09aMpHRFYopTLLy6uK5rAM6CAi7ZwVRtcAb5cq8zbwa+f4SuBTRzA0A94D7goJBgBlS6R3sFcqAQwD1iuljimlWiil0pRSacBSKhEMGo2mJMqwzUpWIIjp1ZqDpnpUKhycOYTbsFcabQBeV0qtE5HpInKZU2wO0FxENgN/Au5y0m8DzgImi8gq5xPasvlXYKqIrAZ+RRVMSRqNpnIsx6yEP4Dh0cJBUz2q9MtRSr0PvF8qbXLYcQFwVTnXzQRmVlDnDuCEUYOVUoOr0j6NRlOMP2BwFW/w/LOdOe9XehecpnroHdIaTQMjobnBTP6OSVBrDppqo4WDRtPA6JH1CQA9+R7TozUHTfXQwkGjaWBk7P0vAAu4AqPjWRFujaa+ooVDLbNv3z6uueYazjzzTHr16sXFF1/Mxo0byy0b7sr7RMTGxtZ0MzUNiEOJHfmCgXxLX0y3/hfXVA/9y6lFlFJcccUVDB48mC1btrBixQruu+++Im+qpQl35a3RVJfON57H44wHwO2OcGM09RYtHGqRzz77DLfbze9+97uitIyMDAYMGMCECRPo1q0b3bt3L9oZHXLlDTB37lxGjRrFyJEj6dChAxMnTixR95133knXrl0ZNmxYkb+mZ599lt69e5ORkcHo0aPJy7MDzb/xxht069aNjIwMBg2yF4gFg0EmTJhA7969SU9P55lnnqn1+6E5PcjUKbzpLB4UHSVUU00azVKGuavmsv3o9hqrL61ZGuN6jDthmbVr19KrV68y6fPnz2fVqlX88MMPHDp0iN69exc9tMNZtWoVK1euxOv10qlTJ8aPH09qaiq5ublkZmby8MMPM336dKZNm8YTTzzBqFGjuPnmmwGYNGkSc+bMYfz48UyfPp1FixbRtm1bjh49CsCcOXOIj49n2bJl+Hw++vfvz4UXXki7du1O/eZoIosjETp1inA7NPWaRiMcKnuQn06++uorxo4di2maJCcnc/7557Ns2TLS09NLlBs2bBjx8fEAdOnShR07dpCamophGEUR4q677jpGjRoF2MJo0qRJHD16lOPHjzNixAgA+vfvz7hx47j66quLyn744YesXr26yIx17NgxNm3apIVDA+LJJyPdAk19ptEIh0jQtWvXU5pD8Hq9RcfhLrpLE3LjPW7cOBYuXEhGRgZz585l8eLFADz99NN8++23vPfee/Tq1YsVK1aglOLxxx8vEiCahkV8PJSjtGo0VUbPOdQiQ4cOxefzMXv27KK01atX06xZM+bNm0cwGOTgwYN88cUXnHtu1eN1WZZVJHReeeUVBgwYAEBOTg6tW7fG7/fz8ssvF5XfsmULffr0Yfr06SQlJbFz505GjBjBU089hd/vB2Djxo3k5ubWRLc1dYBgUIcI1ZwaWnOoRUSEBQsWcMcdd/DAAw8QFRVFWloajzzyCMePHycjIwMR4cEHH6RVq1Zsr2IY05iYGL777jtmzpxJy5Ytiya0Z8yYQZ8+fUhKSqJPnz5FcSImTJjApk2bUEoxbNgwMjIySE9PZ/v27fTs2ROlFElJSSxcuLC2boXmNBMToyejNadGpS676wPaZXftoe9j/aSgAMoJDKjRlOBUXXZrNJp6hhYMmlNFCweNRqPRlKFBC4eGYDKLJPr+aTSNlwYrHKKiosjKytIPuGqilCIrK4sobZ/QaBolDXa1UkpKCrt27SpyLaE5eaKiokhJSYl0MzQaTQRosMLB7Xbr3b4ajUZTTRqsWUmj0Wg01UcLB41Go9GUQQsHjUaj0ZShQeyQFpGDwI5qXt4COFSDzakPNLY+N7b+gu5zY6Am+vsLpVRSeRkNQjicCiKyvKLt4w2VxtbnxtZf0H1uDNR2f7VZSaPRaDRl0MJBo9FoNGXQwgFmV16kwdHY+tzY+gu6z42BWu1vo59z0Gg0Gk1ZtOag0Wg0mjJo4aDRaDSaMjRq4SAiI0XkJxHZLCJ3Rbo91UVEUkXkMxFZLyLrROR2Jz1RRD4SkU3O3wQnXUTkMaffq0WkZ1hdv3bKbxKRX0eqT1VBREwRWSki7zrn7UTkW6df80TE46R7nfPNTn5aWB13O+k/iciIyPSkaohIMxF5U0R+FJENItKvEYzxnc5veq2IvCoiUQ1tnEXkeRE5ICJrw9JqbFxFpJeIrHGueUykigFklVKN8gOYwBagPeABfgC6RLpd1exLa6CncxwHbAS6AA8CdznpdwEPOMcXAx8AAvQFvnXSE4Gtzt8E5zgh0v07Qb//BLwCvOucvw5c4xw/DdzqHP8eeNo5vgaY5xx3ccbdC7Rzfg9mpPt1gv6+ANzkHHuAZg15jIG2wDYgOmx8xzW0cQYGAT2BtWFpNTauwHdOWXGuvahK7Yr0jYnggPQDFoWd3w3cHel21VDf/g8YDvwEtHbSWgM/OcfPAGPDyv/k5I8FnglLL1GuLn2AFOATYCjwrvPDPwS4So8vsAjo5xy7nHJSeszDy9W1DxDvPCilVHpDHuO2wE7ngedyxnlEQxxnIK2UcKiRcXXyfgxLL1HuRJ/GbFYK/fBC7HLS6jWOKn0O8C2QrJTa62TtA5Kd44r6Xp/uySPARMByzpsDR5VSAec8vO1F/XLyjznl61N/2wEHgX87prTnRCSGBjzGSqndwCzgZ2Av9ritoGGPc4iaGte2znHp9EppzMKhwSEiscBbwB1KqezwPGW/NjSIdcsicglwQCm1ItJtOY24sE0PTymlzgFysc0NRTSkMQZw7OyXYwvGNkAMMDKijYoAkRrXxiwcdgOpYecpTlq9RETc2ILhZaXUfCd5v4i0dvJbAwec9Ir6Xl/uSX/gMhHZDryGbVp6FGgmIqEAVuFtL+qXkx8PZFF/+gv2G98updS3zvmb2MKioY4xwAXANqXUQaWUH5iPPfYNeZxD1NS47naOS6dXSmMWDsuADs7KBw/2BNbbEW5TtXBWH8wBNiil/hmW9TYQWrXwa+y5iFD69c7Kh77AMUeFXQRcKCIJzlvbhU5anUIpdbdSKkUplYY9bp8qpa4FPgOudIqV7m/oPlzplFdO+jXOKpd2QAfsybs6h1JqH7BTRDo5ScOA9TTQMXb4GegrIk2c33iozw12nMOokXF18rJFpK9zD68Pq+vERHoiJsKTQBdjr+zZAtwT6facQj8GYKudq4FVzudibHvrJ8Am4GMg0SkvwJNOv9cAmWF13Qhsdj43RLpvVej7YIpXK7XH/qffDLwBeJ30KOd8s5PfPuz6e5z78BNVXMURwb72AJY747wQe1VKgx5jYBrwI7AWeAl7xVGDGmfgVew5FT+2hvibmhxXINO5f1uAJyi1qKGij3afodFoNJoyNGazkkaj0WgqQAsHjUaj0ZRBCweNRqPRlEELB41Go9GUQQsHjUaj0ZRBCweNRqPRlEELB41Go9GU4f8DrXp//HLlDqMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLnd6KPqmXS0"
      },
      "source": [
        "crypto_data = np.array(crypto_data)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UUXf57b72dS"
      },
      "source": [
        "**Scaling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h7GibUiRUuN"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "crypto_data = scaler.fit_transform(crypto_data)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHa2FAIu79Gc"
      },
      "source": [
        "**Train and Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wiScEAjoHoJ"
      },
      "source": [
        "train_x = []\n",
        "test_x = []\n",
        "train_y = []\n",
        "test_y = []\n",
        "\n",
        "train_x = crypto_data[:8000,:6]\n",
        "test_x = crypto_data[8000:,:6]\n",
        "\n",
        "train_y = crypto_data[:8000,6]\n",
        "test_y = crypto_data[8000:,6]\n",
        "\n",
        "\n",
        "train_x, train_y, test_x, test_y = np.array(train_x), np.array(train_y), np.array(test_x), np.array(test_y)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG0xt9_YoDgp",
        "outputId": "baa60e6e-af3e-4eca-b03d-397d9aeaced3"
      },
      "source": [
        "test_x"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.026965, 0.02695 , 0.02697 , 0.026966, 0.026947, 0.02687 ],\n",
              "       [0.026965, 0.02695 , 0.02697 , 0.026967, 0.026947, 0.02687 ],\n",
              "       [0.026967, 0.02695 , 0.02697 , 0.026966, 0.026947, 0.02687 ],\n",
              "       ...,\n",
              "       [0.02732 , 0.02732 , 0.02733 , 0.027316, 0.027305, 0.02732 ],\n",
              "       [0.027316, 0.02732 , 0.02733 , 0.027319, 0.027305, 0.02732 ],\n",
              "       [0.027318, 0.02732 , 0.02732 , 0.027319, 0.027305, 0.02732 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pw5KDUsnXth"
      },
      "source": [
        "train_x = train_x.reshape((train_x.shape[0], 1, train_x.shape[1]))\n",
        "test_x = test_x.reshape((test_x.shape[0], 1, test_x.shape[1]))"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eckL7ZVe9tL8"
      },
      "source": [
        "**Modeling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw-hJ2ko9yf2"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dropout, Dense\n",
        "\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(LSTM(128, input_shape=(train_x.shape[1], train_x.shape[2])))\n",
        "model_lstm.add(Dense(1, activation='sigmoid'))\n",
        "model_lstm. compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit network"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vJ1he9P8Kvn"
      },
      "source": [
        "**Batch size setting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fD2Uyi_zpkpm",
        "outputId": "b6117580-727f-4f96-e978-ce6e62b6af8f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def model_score(model, X_train, y_train, X_test, y_test):\n",
        "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
        "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return trainScore[0], testScore[0]\n",
        "\n",
        "def quick_measure(batch):\n",
        "    model = model_lstm\n",
        "    model.fit(train_x, train_y, batch_size=batch, epochs=100, validation_split=0.1, verbose=1)\n",
        "    trainScore, testScore = model_score(model, train_x, train_y, test_x, test_y)\n",
        "    return trainScore, testScore\n",
        "\n",
        "batchlist = [32, 64, 128, 256, 512]\n",
        "\n",
        "batch_result = {}\n",
        "\n",
        "for batch in batchlist:    \n",
        "    trainScore, testScore = quick_measure(batch)\n",
        "    batch_result[batch] = testScore\n",
        "\n",
        "lists = sorted(batch_result.items())\n",
        "x,y = zip(*lists)\n",
        "plt.plot(x,y)\n",
        "plt.title('Finding the best hyperparameter')\n",
        "plt.xlabel('Batch Size')\n",
        "plt.ylabel('Mean Square Error')\n",
        "plt.show()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6541 - accuracy: 0.5843 - val_loss: 0.6374 - val_accuracy: 0.6388\n",
            "Epoch 2/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6542 - accuracy: 0.5790 - val_loss: 0.6303 - val_accuracy: 0.6112\n",
            "Epoch 3/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6514 - accuracy: 0.5825 - val_loss: 0.6348 - val_accuracy: 0.6350\n",
            "Epoch 4/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6560 - accuracy: 0.5853 - val_loss: 0.6225 - val_accuracy: 0.5987\n",
            "Epoch 5/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6497 - accuracy: 0.5919 - val_loss: 0.6249 - val_accuracy: 0.5975\n",
            "Epoch 6/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6528 - accuracy: 0.5851 - val_loss: 0.6357 - val_accuracy: 0.6400\n",
            "Epoch 7/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6530 - accuracy: 0.5792 - val_loss: 0.6267 - val_accuracy: 0.5913\n",
            "Epoch 8/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6499 - accuracy: 0.5838 - val_loss: 0.6217 - val_accuracy: 0.6100\n",
            "Epoch 9/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6506 - accuracy: 0.5825 - val_loss: 0.6400 - val_accuracy: 0.6475\n",
            "Epoch 10/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6493 - accuracy: 0.5804 - val_loss: 0.6207 - val_accuracy: 0.6087\n",
            "Epoch 11/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6518 - accuracy: 0.5839 - val_loss: 0.6212 - val_accuracy: 0.6150\n",
            "Epoch 12/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6492 - accuracy: 0.5826 - val_loss: 0.6222 - val_accuracy: 0.6187\n",
            "Epoch 13/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6496 - accuracy: 0.5819 - val_loss: 0.6475 - val_accuracy: 0.6363\n",
            "Epoch 14/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6523 - accuracy: 0.5847 - val_loss: 0.6429 - val_accuracy: 0.6463\n",
            "Epoch 15/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6477 - accuracy: 0.5858 - val_loss: 0.6260 - val_accuracy: 0.5938\n",
            "Epoch 16/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6532 - accuracy: 0.5843 - val_loss: 0.6245 - val_accuracy: 0.5987\n",
            "Epoch 17/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6490 - accuracy: 0.5835 - val_loss: 0.6200 - val_accuracy: 0.5987\n",
            "Epoch 18/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6517 - accuracy: 0.5831 - val_loss: 0.6419 - val_accuracy: 0.6450\n",
            "Epoch 19/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6521 - accuracy: 0.5804 - val_loss: 0.6203 - val_accuracy: 0.6037\n",
            "Epoch 20/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6545 - accuracy: 0.5767 - val_loss: 0.6636 - val_accuracy: 0.5950\n",
            "Epoch 21/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6510 - accuracy: 0.5856 - val_loss: 0.6240 - val_accuracy: 0.6175\n",
            "Epoch 22/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6495 - accuracy: 0.5844 - val_loss: 0.6209 - val_accuracy: 0.6087\n",
            "Epoch 23/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6507 - accuracy: 0.5885 - val_loss: 0.6251 - val_accuracy: 0.5987\n",
            "Epoch 24/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6500 - accuracy: 0.5831 - val_loss: 0.6360 - val_accuracy: 0.6488\n",
            "Epoch 25/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6477 - accuracy: 0.5883 - val_loss: 0.6263 - val_accuracy: 0.5913\n",
            "Epoch 26/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6512 - accuracy: 0.5858 - val_loss: 0.6340 - val_accuracy: 0.6350\n",
            "Epoch 27/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6513 - accuracy: 0.5832 - val_loss: 0.6323 - val_accuracy: 0.6275\n",
            "Epoch 28/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6501 - accuracy: 0.5876 - val_loss: 0.6414 - val_accuracy: 0.6463\n",
            "Epoch 29/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6479 - accuracy: 0.5828 - val_loss: 0.6350 - val_accuracy: 0.6488\n",
            "Epoch 30/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6491 - accuracy: 0.5818 - val_loss: 0.6331 - val_accuracy: 0.6350\n",
            "Epoch 31/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6503 - accuracy: 0.5883 - val_loss: 0.6196 - val_accuracy: 0.6112\n",
            "Epoch 32/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6490 - accuracy: 0.5828 - val_loss: 0.6256 - val_accuracy: 0.6012\n",
            "Epoch 33/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6489 - accuracy: 0.5799 - val_loss: 0.6499 - val_accuracy: 0.6338\n",
            "Epoch 34/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6520 - accuracy: 0.5854 - val_loss: 0.6363 - val_accuracy: 0.6463\n",
            "Epoch 35/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6481 - accuracy: 0.5826 - val_loss: 0.6212 - val_accuracy: 0.6175\n",
            "Epoch 36/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6489 - accuracy: 0.5806 - val_loss: 0.6201 - val_accuracy: 0.6162\n",
            "Epoch 37/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6497 - accuracy: 0.5881 - val_loss: 0.6240 - val_accuracy: 0.5950\n",
            "Epoch 38/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6501 - accuracy: 0.5863 - val_loss: 0.6284 - val_accuracy: 0.6075\n",
            "Epoch 39/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6515 - accuracy: 0.5790 - val_loss: 0.6337 - val_accuracy: 0.6438\n",
            "Epoch 40/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6492 - accuracy: 0.5813 - val_loss: 0.6205 - val_accuracy: 0.6125\n",
            "Epoch 41/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6510 - accuracy: 0.5800 - val_loss: 0.6628 - val_accuracy: 0.6000\n",
            "Epoch 42/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6508 - accuracy: 0.5860 - val_loss: 0.6189 - val_accuracy: 0.6087\n",
            "Epoch 43/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6496 - accuracy: 0.5888 - val_loss: 0.6293 - val_accuracy: 0.6150\n",
            "Epoch 44/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6497 - accuracy: 0.5840 - val_loss: 0.6632 - val_accuracy: 0.6012\n",
            "Epoch 45/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6477 - accuracy: 0.5821 - val_loss: 0.6410 - val_accuracy: 0.6425\n",
            "Epoch 46/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6496 - accuracy: 0.5821 - val_loss: 0.6194 - val_accuracy: 0.6037\n",
            "Epoch 47/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6495 - accuracy: 0.5822 - val_loss: 0.6219 - val_accuracy: 0.5975\n",
            "Epoch 48/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6535 - accuracy: 0.5761 - val_loss: 0.6239 - val_accuracy: 0.5962\n",
            "Epoch 49/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6488 - accuracy: 0.5822 - val_loss: 0.6194 - val_accuracy: 0.6112\n",
            "Epoch 50/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6498 - accuracy: 0.5808 - val_loss: 0.6434 - val_accuracy: 0.6463\n",
            "Epoch 51/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6505 - accuracy: 0.5899 - val_loss: 0.6408 - val_accuracy: 0.6475\n",
            "Epoch 52/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6524 - accuracy: 0.5804 - val_loss: 0.6193 - val_accuracy: 0.6037\n",
            "Epoch 53/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6485 - accuracy: 0.5801 - val_loss: 0.6238 - val_accuracy: 0.5975\n",
            "Epoch 54/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6483 - accuracy: 0.5821 - val_loss: 0.6253 - val_accuracy: 0.5913\n",
            "Epoch 55/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6470 - accuracy: 0.5906 - val_loss: 0.6332 - val_accuracy: 0.6450\n",
            "Epoch 56/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6499 - accuracy: 0.5835 - val_loss: 0.6520 - val_accuracy: 0.6350\n",
            "Epoch 57/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6484 - accuracy: 0.5806 - val_loss: 0.6183 - val_accuracy: 0.6100\n",
            "Epoch 58/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6504 - accuracy: 0.5808 - val_loss: 0.6184 - val_accuracy: 0.6100\n",
            "Epoch 59/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6475 - accuracy: 0.5874 - val_loss: 0.6213 - val_accuracy: 0.5950\n",
            "Epoch 60/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6503 - accuracy: 0.5797 - val_loss: 0.6371 - val_accuracy: 0.6450\n",
            "Epoch 61/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6475 - accuracy: 0.5886 - val_loss: 0.6314 - val_accuracy: 0.6350\n",
            "Epoch 62/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6494 - accuracy: 0.5801 - val_loss: 0.6255 - val_accuracy: 0.6037\n",
            "Epoch 63/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6509 - accuracy: 0.5797 - val_loss: 0.6365 - val_accuracy: 0.6425\n",
            "Epoch 64/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6495 - accuracy: 0.5861 - val_loss: 0.6348 - val_accuracy: 0.6500\n",
            "Epoch 65/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6500 - accuracy: 0.5833 - val_loss: 0.6324 - val_accuracy: 0.6388\n",
            "Epoch 66/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6481 - accuracy: 0.5819 - val_loss: 0.6367 - val_accuracy: 0.6400\n",
            "Epoch 67/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6467 - accuracy: 0.5879 - val_loss: 0.6287 - val_accuracy: 0.6212\n",
            "Epoch 68/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6499 - accuracy: 0.5822 - val_loss: 0.6613 - val_accuracy: 0.5875\n",
            "Epoch 69/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6502 - accuracy: 0.5842 - val_loss: 0.6229 - val_accuracy: 0.5962\n",
            "Epoch 70/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6495 - accuracy: 0.5793 - val_loss: 0.6273 - val_accuracy: 0.5987\n",
            "Epoch 71/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6477 - accuracy: 0.5811 - val_loss: 0.6271 - val_accuracy: 0.6075\n",
            "Epoch 72/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6491 - accuracy: 0.5799 - val_loss: 0.6429 - val_accuracy: 0.6375\n",
            "Epoch 73/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6494 - accuracy: 0.5894 - val_loss: 0.6217 - val_accuracy: 0.6100\n",
            "Epoch 74/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6474 - accuracy: 0.5879 - val_loss: 0.6322 - val_accuracy: 0.6438\n",
            "Epoch 75/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6478 - accuracy: 0.5818 - val_loss: 0.6361 - val_accuracy: 0.6488\n",
            "Epoch 76/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6479 - accuracy: 0.5850 - val_loss: 0.6350 - val_accuracy: 0.6438\n",
            "Epoch 77/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6511 - accuracy: 0.5800 - val_loss: 0.6187 - val_accuracy: 0.6075\n",
            "Epoch 78/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6492 - accuracy: 0.5851 - val_loss: 0.6185 - val_accuracy: 0.6075\n",
            "Epoch 79/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6513 - accuracy: 0.5853 - val_loss: 0.6417 - val_accuracy: 0.6500\n",
            "Epoch 80/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6500 - accuracy: 0.5882 - val_loss: 0.6221 - val_accuracy: 0.6012\n",
            "Epoch 81/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6478 - accuracy: 0.5832 - val_loss: 0.6429 - val_accuracy: 0.6400\n",
            "Epoch 82/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6512 - accuracy: 0.5811 - val_loss: 0.6256 - val_accuracy: 0.6037\n",
            "Epoch 83/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6485 - accuracy: 0.5850 - val_loss: 0.6188 - val_accuracy: 0.6100\n",
            "Epoch 84/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6487 - accuracy: 0.5824 - val_loss: 0.6217 - val_accuracy: 0.5975\n",
            "Epoch 85/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6476 - accuracy: 0.5800 - val_loss: 0.6186 - val_accuracy: 0.5987\n",
            "Epoch 86/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6482 - accuracy: 0.5813 - val_loss: 0.6323 - val_accuracy: 0.6388\n",
            "Epoch 87/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6480 - accuracy: 0.5838 - val_loss: 0.6218 - val_accuracy: 0.6025\n",
            "Epoch 88/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6471 - accuracy: 0.5833 - val_loss: 0.6295 - val_accuracy: 0.6300\n",
            "Epoch 89/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6488 - accuracy: 0.5839 - val_loss: 0.6625 - val_accuracy: 0.5987\n",
            "Epoch 90/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6494 - accuracy: 0.5844 - val_loss: 0.6190 - val_accuracy: 0.6162\n",
            "Epoch 91/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6488 - accuracy: 0.5829 - val_loss: 0.6188 - val_accuracy: 0.6175\n",
            "Epoch 92/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6503 - accuracy: 0.5896 - val_loss: 0.6181 - val_accuracy: 0.6087\n",
            "Epoch 93/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6488 - accuracy: 0.5826 - val_loss: 0.6407 - val_accuracy: 0.6475\n",
            "Epoch 94/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6523 - accuracy: 0.5793 - val_loss: 0.6250 - val_accuracy: 0.5975\n",
            "Epoch 95/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6502 - accuracy: 0.5836 - val_loss: 0.6185 - val_accuracy: 0.6075\n",
            "Epoch 96/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6453 - accuracy: 0.5850 - val_loss: 0.6290 - val_accuracy: 0.6212\n",
            "Epoch 97/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6479 - accuracy: 0.5881 - val_loss: 0.6243 - val_accuracy: 0.6050\n",
            "Epoch 98/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6508 - accuracy: 0.5849 - val_loss: 0.6243 - val_accuracy: 0.6075\n",
            "Epoch 99/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6491 - accuracy: 0.5844 - val_loss: 0.6194 - val_accuracy: 0.6187\n",
            "Epoch 100/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6471 - accuracy: 0.5853 - val_loss: 0.6252 - val_accuracy: 0.6075\n",
            "Epoch 1/100\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.6444 - accuracy: 0.5851 - val_loss: 0.6298 - val_accuracy: 0.6350\n",
            "Epoch 2/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6449 - accuracy: 0.5832 - val_loss: 0.6232 - val_accuracy: 0.6012\n",
            "Epoch 3/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6449 - accuracy: 0.5875 - val_loss: 0.6491 - val_accuracy: 0.6425\n",
            "Epoch 4/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6457 - accuracy: 0.5901 - val_loss: 0.6387 - val_accuracy: 0.6463\n",
            "Epoch 5/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6447 - accuracy: 0.5847 - val_loss: 0.6172 - val_accuracy: 0.6125\n",
            "Epoch 6/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6501 - accuracy: 0.5847 - val_loss: 0.6188 - val_accuracy: 0.6187\n",
            "Epoch 7/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6473 - accuracy: 0.5871 - val_loss: 0.6338 - val_accuracy: 0.6438\n",
            "Epoch 8/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6453 - accuracy: 0.5861 - val_loss: 0.6302 - val_accuracy: 0.6350\n",
            "Epoch 9/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6450 - accuracy: 0.5817 - val_loss: 0.6219 - val_accuracy: 0.6000\n",
            "Epoch 10/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6449 - accuracy: 0.5840 - val_loss: 0.6427 - val_accuracy: 0.6388\n",
            "Epoch 11/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6457 - accuracy: 0.5857 - val_loss: 0.6300 - val_accuracy: 0.6350\n",
            "Epoch 12/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6460 - accuracy: 0.5869 - val_loss: 0.6479 - val_accuracy: 0.6388\n",
            "Epoch 13/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6466 - accuracy: 0.5847 - val_loss: 0.6234 - val_accuracy: 0.6000\n",
            "Epoch 14/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6454 - accuracy: 0.5851 - val_loss: 0.6536 - val_accuracy: 0.6250\n",
            "Epoch 15/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6464 - accuracy: 0.5832 - val_loss: 0.6411 - val_accuracy: 0.6350\n",
            "Epoch 16/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6469 - accuracy: 0.5778 - val_loss: 0.6289 - val_accuracy: 0.6388\n",
            "Epoch 17/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6446 - accuracy: 0.5849 - val_loss: 0.6421 - val_accuracy: 0.6388\n",
            "Epoch 18/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6449 - accuracy: 0.5849 - val_loss: 0.6236 - val_accuracy: 0.6050\n",
            "Epoch 19/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6447 - accuracy: 0.5851 - val_loss: 0.6456 - val_accuracy: 0.6350\n",
            "Epoch 20/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6469 - accuracy: 0.5861 - val_loss: 0.6321 - val_accuracy: 0.6450\n",
            "Epoch 21/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6439 - accuracy: 0.5839 - val_loss: 0.6480 - val_accuracy: 0.6425\n",
            "Epoch 22/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6488 - accuracy: 0.5836 - val_loss: 0.6278 - val_accuracy: 0.6288\n",
            "Epoch 23/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6453 - accuracy: 0.5858 - val_loss: 0.6258 - val_accuracy: 0.6100\n",
            "Epoch 24/100\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.6455 - accuracy: 0.5835 - val_loss: 0.6195 - val_accuracy: 0.6012\n",
            "Epoch 25/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6444 - accuracy: 0.5824 - val_loss: 0.6160 - val_accuracy: 0.6062\n",
            "Epoch 26/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6496 - accuracy: 0.5838 - val_loss: 0.6213 - val_accuracy: 0.5925\n",
            "Epoch 27/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6469 - accuracy: 0.5840 - val_loss: 0.6489 - val_accuracy: 0.6375\n",
            "Epoch 28/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6448 - accuracy: 0.5808 - val_loss: 0.6203 - val_accuracy: 0.5987\n",
            "Epoch 29/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6445 - accuracy: 0.5800 - val_loss: 0.6298 - val_accuracy: 0.6375\n",
            "Epoch 30/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6456 - accuracy: 0.5832 - val_loss: 0.6254 - val_accuracy: 0.6087\n",
            "Epoch 31/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6443 - accuracy: 0.5914 - val_loss: 0.6182 - val_accuracy: 0.6112\n",
            "Epoch 32/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6437 - accuracy: 0.5838 - val_loss: 0.6206 - val_accuracy: 0.6025\n",
            "Epoch 33/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6474 - accuracy: 0.5850 - val_loss: 0.6174 - val_accuracy: 0.6137\n",
            "Epoch 34/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6462 - accuracy: 0.5789 - val_loss: 0.6163 - val_accuracy: 0.6112\n",
            "Epoch 35/100\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.6472 - accuracy: 0.5843 - val_loss: 0.6207 - val_accuracy: 0.5950\n",
            "Epoch 36/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6470 - accuracy: 0.5868 - val_loss: 0.6403 - val_accuracy: 0.6350\n",
            "Epoch 37/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6458 - accuracy: 0.5878 - val_loss: 0.6228 - val_accuracy: 0.5950\n",
            "Epoch 38/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6470 - accuracy: 0.5824 - val_loss: 0.6229 - val_accuracy: 0.5975\n",
            "Epoch 39/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6470 - accuracy: 0.5847 - val_loss: 0.6226 - val_accuracy: 0.5975\n",
            "Epoch 40/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6462 - accuracy: 0.5914 - val_loss: 0.6178 - val_accuracy: 0.6125\n",
            "Epoch 41/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6446 - accuracy: 0.5868 - val_loss: 0.6217 - val_accuracy: 0.5962\n",
            "Epoch 42/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6448 - accuracy: 0.5822 - val_loss: 0.6170 - val_accuracy: 0.6175\n",
            "Epoch 43/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6434 - accuracy: 0.5893 - val_loss: 0.6301 - val_accuracy: 0.6463\n",
            "Epoch 44/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6453 - accuracy: 0.5918 - val_loss: 0.6201 - val_accuracy: 0.5925\n",
            "Epoch 45/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6451 - accuracy: 0.5818 - val_loss: 0.6246 - val_accuracy: 0.6100\n",
            "Epoch 46/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6456 - accuracy: 0.5879 - val_loss: 0.6209 - val_accuracy: 0.6037\n",
            "Epoch 47/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6447 - accuracy: 0.5863 - val_loss: 0.6331 - val_accuracy: 0.6438\n",
            "Epoch 48/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6434 - accuracy: 0.5944 - val_loss: 0.6271 - val_accuracy: 0.6275\n",
            "Epoch 49/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6450 - accuracy: 0.5889 - val_loss: 0.6480 - val_accuracy: 0.6400\n",
            "Epoch 50/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6459 - accuracy: 0.5847 - val_loss: 0.6364 - val_accuracy: 0.6450\n",
            "Epoch 51/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6441 - accuracy: 0.5865 - val_loss: 0.6367 - val_accuracy: 0.6450\n",
            "Epoch 52/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6453 - accuracy: 0.5893 - val_loss: 0.6201 - val_accuracy: 0.5925\n",
            "Epoch 53/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6434 - accuracy: 0.5858 - val_loss: 0.6354 - val_accuracy: 0.6400\n",
            "Epoch 54/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6444 - accuracy: 0.5910 - val_loss: 0.6285 - val_accuracy: 0.6363\n",
            "Epoch 55/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6445 - accuracy: 0.5839 - val_loss: 0.6189 - val_accuracy: 0.5987\n",
            "Epoch 56/100\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.6490 - accuracy: 0.5850 - val_loss: 0.6298 - val_accuracy: 0.6438\n",
            "Epoch 57/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6459 - accuracy: 0.5856 - val_loss: 0.6174 - val_accuracy: 0.6112\n",
            "Epoch 58/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6449 - accuracy: 0.5892 - val_loss: 0.6174 - val_accuracy: 0.6137\n",
            "Epoch 59/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6439 - accuracy: 0.5858 - val_loss: 0.6198 - val_accuracy: 0.5913\n",
            "Epoch 60/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6477 - accuracy: 0.5860 - val_loss: 0.6199 - val_accuracy: 0.5913\n",
            "Epoch 61/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6443 - accuracy: 0.5858 - val_loss: 0.6219 - val_accuracy: 0.5938\n",
            "Epoch 62/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6449 - accuracy: 0.5917 - val_loss: 0.6308 - val_accuracy: 0.6388\n",
            "Epoch 63/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6441 - accuracy: 0.5854 - val_loss: 0.6220 - val_accuracy: 0.6075\n",
            "Epoch 64/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6451 - accuracy: 0.5890 - val_loss: 0.6360 - val_accuracy: 0.6400\n",
            "Epoch 65/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6428 - accuracy: 0.5931 - val_loss: 0.6297 - val_accuracy: 0.6400\n",
            "Epoch 66/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6437 - accuracy: 0.5843 - val_loss: 0.6300 - val_accuracy: 0.6450\n",
            "Epoch 67/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6459 - accuracy: 0.5849 - val_loss: 0.6209 - val_accuracy: 0.6000\n",
            "Epoch 68/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6444 - accuracy: 0.5910 - val_loss: 0.6527 - val_accuracy: 0.6187\n",
            "Epoch 69/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6433 - accuracy: 0.5876 - val_loss: 0.6271 - val_accuracy: 0.6300\n",
            "Epoch 70/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6452 - accuracy: 0.5835 - val_loss: 0.6462 - val_accuracy: 0.6463\n",
            "Epoch 71/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6453 - accuracy: 0.5839 - val_loss: 0.6255 - val_accuracy: 0.6150\n",
            "Epoch 72/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6438 - accuracy: 0.5868 - val_loss: 0.6167 - val_accuracy: 0.6112\n",
            "Epoch 73/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6505 - accuracy: 0.5911 - val_loss: 0.6374 - val_accuracy: 0.6313\n",
            "Epoch 74/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6448 - accuracy: 0.5864 - val_loss: 0.6183 - val_accuracy: 0.6150\n",
            "Epoch 75/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6426 - accuracy: 0.5907 - val_loss: 0.6332 - val_accuracy: 0.6425\n",
            "Epoch 76/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6451 - accuracy: 0.5915 - val_loss: 0.6194 - val_accuracy: 0.5913\n",
            "Epoch 77/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6445 - accuracy: 0.5810 - val_loss: 0.6462 - val_accuracy: 0.6338\n",
            "Epoch 78/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6473 - accuracy: 0.5879 - val_loss: 0.6174 - val_accuracy: 0.6075\n",
            "Epoch 79/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6440 - accuracy: 0.5865 - val_loss: 0.6254 - val_accuracy: 0.6125\n",
            "Epoch 80/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6418 - accuracy: 0.5847 - val_loss: 0.6214 - val_accuracy: 0.6050\n",
            "Epoch 81/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6426 - accuracy: 0.5856 - val_loss: 0.6160 - val_accuracy: 0.6175\n",
            "Epoch 82/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6445 - accuracy: 0.5872 - val_loss: 0.6452 - val_accuracy: 0.6400\n",
            "Epoch 83/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6432 - accuracy: 0.5926 - val_loss: 0.6496 - val_accuracy: 0.6325\n",
            "Epoch 84/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6444 - accuracy: 0.5947 - val_loss: 0.6400 - val_accuracy: 0.6400\n",
            "Epoch 85/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6461 - accuracy: 0.5894 - val_loss: 0.6213 - val_accuracy: 0.5962\n",
            "Epoch 86/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6444 - accuracy: 0.5903 - val_loss: 0.6247 - val_accuracy: 0.6187\n",
            "Epoch 87/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6449 - accuracy: 0.5857 - val_loss: 0.6325 - val_accuracy: 0.6438\n",
            "Epoch 88/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6431 - accuracy: 0.5861 - val_loss: 0.6289 - val_accuracy: 0.6500\n",
            "Epoch 89/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6440 - accuracy: 0.5924 - val_loss: 0.6561 - val_accuracy: 0.6250\n",
            "Epoch 90/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6440 - accuracy: 0.5860 - val_loss: 0.6167 - val_accuracy: 0.6187\n",
            "Epoch 91/100\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 0.6427 - accuracy: 0.5876 - val_loss: 0.6370 - val_accuracy: 0.6375\n",
            "Epoch 92/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6447 - accuracy: 0.5875 - val_loss: 0.6452 - val_accuracy: 0.6463\n",
            "Epoch 93/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6434 - accuracy: 0.5899 - val_loss: 0.6287 - val_accuracy: 0.6388\n",
            "Epoch 94/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6454 - accuracy: 0.5907 - val_loss: 0.6181 - val_accuracy: 0.6025\n",
            "Epoch 95/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6490 - accuracy: 0.5851 - val_loss: 0.6193 - val_accuracy: 0.5925\n",
            "Epoch 96/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6463 - accuracy: 0.5839 - val_loss: 0.6168 - val_accuracy: 0.6175\n",
            "Epoch 97/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6435 - accuracy: 0.5925 - val_loss: 0.6168 - val_accuracy: 0.6162\n",
            "Epoch 98/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6444 - accuracy: 0.5842 - val_loss: 0.6234 - val_accuracy: 0.6062\n",
            "Epoch 99/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6425 - accuracy: 0.5892 - val_loss: 0.6195 - val_accuracy: 0.5925\n",
            "Epoch 100/100\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.6427 - accuracy: 0.5863 - val_loss: 0.6317 - val_accuracy: 0.6450\n",
            "Epoch 1/100\n",
            "57/57 [==============================] - 0s 8ms/step - loss: 0.6408 - accuracy: 0.5933 - val_loss: 0.6282 - val_accuracy: 0.6413\n",
            "Epoch 2/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6454 - accuracy: 0.5858 - val_loss: 0.6408 - val_accuracy: 0.6425\n",
            "Epoch 3/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6421 - accuracy: 0.5911 - val_loss: 0.6227 - val_accuracy: 0.6087\n",
            "Epoch 4/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6431 - accuracy: 0.5853 - val_loss: 0.6396 - val_accuracy: 0.6388\n",
            "Epoch 5/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6438 - accuracy: 0.5888 - val_loss: 0.6222 - val_accuracy: 0.6062\n",
            "Epoch 6/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6435 - accuracy: 0.5821 - val_loss: 0.6218 - val_accuracy: 0.6125\n",
            "Epoch 7/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6420 - accuracy: 0.5893 - val_loss: 0.6196 - val_accuracy: 0.5938\n",
            "Epoch 8/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6413 - accuracy: 0.5914 - val_loss: 0.6350 - val_accuracy: 0.6400\n",
            "Epoch 9/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6435 - accuracy: 0.5853 - val_loss: 0.6200 - val_accuracy: 0.6025\n",
            "Epoch 10/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6413 - accuracy: 0.5897 - val_loss: 0.6271 - val_accuracy: 0.6400\n",
            "Epoch 11/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6432 - accuracy: 0.5864 - val_loss: 0.6156 - val_accuracy: 0.6187\n",
            "Epoch 12/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6431 - accuracy: 0.5869 - val_loss: 0.6234 - val_accuracy: 0.6112\n",
            "Epoch 13/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6443 - accuracy: 0.5864 - val_loss: 0.6294 - val_accuracy: 0.6413\n",
            "Epoch 14/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6408 - accuracy: 0.5913 - val_loss: 0.6169 - val_accuracy: 0.6075\n",
            "Epoch 15/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6407 - accuracy: 0.5874 - val_loss: 0.6220 - val_accuracy: 0.6075\n",
            "Epoch 16/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6412 - accuracy: 0.5901 - val_loss: 0.6367 - val_accuracy: 0.6413\n",
            "Epoch 17/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6418 - accuracy: 0.5911 - val_loss: 0.6163 - val_accuracy: 0.6075\n",
            "Epoch 18/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6444 - accuracy: 0.5850 - val_loss: 0.6218 - val_accuracy: 0.6075\n",
            "Epoch 19/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6486 - accuracy: 0.5808 - val_loss: 0.6459 - val_accuracy: 0.6400\n",
            "Epoch 20/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6436 - accuracy: 0.5867 - val_loss: 0.6321 - val_accuracy: 0.6450\n",
            "Epoch 21/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6419 - accuracy: 0.5931 - val_loss: 0.6284 - val_accuracy: 0.6388\n",
            "Epoch 22/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6417 - accuracy: 0.5876 - val_loss: 0.6200 - val_accuracy: 0.6100\n",
            "Epoch 23/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6417 - accuracy: 0.5899 - val_loss: 0.6252 - val_accuracy: 0.6250\n",
            "Epoch 24/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6412 - accuracy: 0.5881 - val_loss: 0.6157 - val_accuracy: 0.6175\n",
            "Epoch 25/100\n",
            "57/57 [==============================] - 1s 10ms/step - loss: 0.6417 - accuracy: 0.5878 - val_loss: 0.6184 - val_accuracy: 0.5975\n",
            "Epoch 26/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6414 - accuracy: 0.5874 - val_loss: 0.6258 - val_accuracy: 0.6313\n",
            "Epoch 27/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6413 - accuracy: 0.5883 - val_loss: 0.6207 - val_accuracy: 0.6125\n",
            "Epoch 28/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6421 - accuracy: 0.5863 - val_loss: 0.6479 - val_accuracy: 0.6250\n",
            "Epoch 29/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6418 - accuracy: 0.5851 - val_loss: 0.6225 - val_accuracy: 0.6012\n",
            "Epoch 30/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6427 - accuracy: 0.5872 - val_loss: 0.6289 - val_accuracy: 0.6450\n",
            "Epoch 31/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6428 - accuracy: 0.5892 - val_loss: 0.6146 - val_accuracy: 0.6150\n",
            "Epoch 32/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6410 - accuracy: 0.5907 - val_loss: 0.6365 - val_accuracy: 0.6388\n",
            "Epoch 33/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6410 - accuracy: 0.5860 - val_loss: 0.6311 - val_accuracy: 0.6388\n",
            "Epoch 34/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6425 - accuracy: 0.5829 - val_loss: 0.6244 - val_accuracy: 0.6237\n",
            "Epoch 35/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6409 - accuracy: 0.5874 - val_loss: 0.6473 - val_accuracy: 0.6375\n",
            "Epoch 36/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6413 - accuracy: 0.5944 - val_loss: 0.6198 - val_accuracy: 0.6112\n",
            "Epoch 37/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6429 - accuracy: 0.5885 - val_loss: 0.6170 - val_accuracy: 0.5925\n",
            "Epoch 38/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6406 - accuracy: 0.5863 - val_loss: 0.6431 - val_accuracy: 0.6413\n",
            "Epoch 39/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.6416 - accuracy: 0.5935 - val_loss: 0.6179 - val_accuracy: 0.5925\n",
            "Epoch 40/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6424 - accuracy: 0.5863 - val_loss: 0.6272 - val_accuracy: 0.6400\n",
            "Epoch 41/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6408 - accuracy: 0.5918 - val_loss: 0.6265 - val_accuracy: 0.6388\n",
            "Epoch 42/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6408 - accuracy: 0.5888 - val_loss: 0.6161 - val_accuracy: 0.6050\n",
            "Epoch 43/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6411 - accuracy: 0.5857 - val_loss: 0.6251 - val_accuracy: 0.6275\n",
            "Epoch 44/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6414 - accuracy: 0.5894 - val_loss: 0.6200 - val_accuracy: 0.6150\n",
            "Epoch 45/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6407 - accuracy: 0.5863 - val_loss: 0.6324 - val_accuracy: 0.6388\n",
            "Epoch 46/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6450 - accuracy: 0.5885 - val_loss: 0.6328 - val_accuracy: 0.6450\n",
            "Epoch 47/100\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.6419 - accuracy: 0.5868 - val_loss: 0.6233 - val_accuracy: 0.6175\n",
            "Epoch 48/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6437 - accuracy: 0.5908 - val_loss: 0.6211 - val_accuracy: 0.6037\n",
            "Epoch 49/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6416 - accuracy: 0.5896 - val_loss: 0.6223 - val_accuracy: 0.6162\n",
            "Epoch 50/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6412 - accuracy: 0.5914 - val_loss: 0.6174 - val_accuracy: 0.5962\n",
            "Epoch 51/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6413 - accuracy: 0.5864 - val_loss: 0.6177 - val_accuracy: 0.5913\n",
            "Epoch 52/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6428 - accuracy: 0.5915 - val_loss: 0.6166 - val_accuracy: 0.5962\n",
            "Epoch 53/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6438 - accuracy: 0.5892 - val_loss: 0.6501 - val_accuracy: 0.6313\n",
            "Epoch 54/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6458 - accuracy: 0.5885 - val_loss: 0.6342 - val_accuracy: 0.6400\n",
            "Epoch 55/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6403 - accuracy: 0.5888 - val_loss: 0.6223 - val_accuracy: 0.6112\n",
            "Epoch 56/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6413 - accuracy: 0.5892 - val_loss: 0.6230 - val_accuracy: 0.6150\n",
            "Epoch 57/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6404 - accuracy: 0.5896 - val_loss: 0.6313 - val_accuracy: 0.6413\n",
            "Epoch 58/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6412 - accuracy: 0.5865 - val_loss: 0.6242 - val_accuracy: 0.6313\n",
            "Epoch 59/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6404 - accuracy: 0.5879 - val_loss: 0.6195 - val_accuracy: 0.6162\n",
            "Epoch 60/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6407 - accuracy: 0.5878 - val_loss: 0.6276 - val_accuracy: 0.6438\n",
            "Epoch 61/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6455 - accuracy: 0.5935 - val_loss: 0.6149 - val_accuracy: 0.6175\n",
            "Epoch 62/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6419 - accuracy: 0.5840 - val_loss: 0.6302 - val_accuracy: 0.6475\n",
            "Epoch 63/100\n",
            "57/57 [==============================] - 1s 10ms/step - loss: 0.6408 - accuracy: 0.5913 - val_loss: 0.6300 - val_accuracy: 0.6363\n",
            "Epoch 64/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6426 - accuracy: 0.5896 - val_loss: 0.6207 - val_accuracy: 0.6037\n",
            "Epoch 65/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6417 - accuracy: 0.5903 - val_loss: 0.6254 - val_accuracy: 0.6313\n",
            "Epoch 66/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6431 - accuracy: 0.5883 - val_loss: 0.6329 - val_accuracy: 0.6400\n",
            "Epoch 67/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6397 - accuracy: 0.5888 - val_loss: 0.6147 - val_accuracy: 0.6075\n",
            "Epoch 68/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6438 - accuracy: 0.5917 - val_loss: 0.6237 - val_accuracy: 0.6137\n",
            "Epoch 69/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6407 - accuracy: 0.5894 - val_loss: 0.6301 - val_accuracy: 0.6475\n",
            "Epoch 70/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6414 - accuracy: 0.5857 - val_loss: 0.6163 - val_accuracy: 0.6025\n",
            "Epoch 71/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6458 - accuracy: 0.5863 - val_loss: 0.6208 - val_accuracy: 0.6100\n",
            "Epoch 72/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6413 - accuracy: 0.5893 - val_loss: 0.6231 - val_accuracy: 0.6175\n",
            "Epoch 73/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6403 - accuracy: 0.5876 - val_loss: 0.6150 - val_accuracy: 0.6175\n",
            "Epoch 74/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6424 - accuracy: 0.5871 - val_loss: 0.6193 - val_accuracy: 0.5950\n",
            "Epoch 75/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6414 - accuracy: 0.5872 - val_loss: 0.6252 - val_accuracy: 0.6313\n",
            "Epoch 76/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6404 - accuracy: 0.5879 - val_loss: 0.6201 - val_accuracy: 0.6087\n",
            "Epoch 77/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6418 - accuracy: 0.5885 - val_loss: 0.6287 - val_accuracy: 0.6375\n",
            "Epoch 78/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6418 - accuracy: 0.5892 - val_loss: 0.6273 - val_accuracy: 0.6375\n",
            "Epoch 79/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6406 - accuracy: 0.5953 - val_loss: 0.6146 - val_accuracy: 0.6087\n",
            "Epoch 80/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6430 - accuracy: 0.5869 - val_loss: 0.6143 - val_accuracy: 0.6162\n",
            "Epoch 81/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6440 - accuracy: 0.5893 - val_loss: 0.6182 - val_accuracy: 0.5925\n",
            "Epoch 82/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6411 - accuracy: 0.5881 - val_loss: 0.6300 - val_accuracy: 0.6425\n",
            "Epoch 83/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6405 - accuracy: 0.5835 - val_loss: 0.6431 - val_accuracy: 0.6363\n",
            "Epoch 84/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6429 - accuracy: 0.5885 - val_loss: 0.6275 - val_accuracy: 0.6388\n",
            "Epoch 85/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6408 - accuracy: 0.5893 - val_loss: 0.6157 - val_accuracy: 0.6050\n",
            "Epoch 86/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6421 - accuracy: 0.5868 - val_loss: 0.6339 - val_accuracy: 0.6363\n",
            "Epoch 87/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6415 - accuracy: 0.5894 - val_loss: 0.6210 - val_accuracy: 0.6037\n",
            "Epoch 88/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6401 - accuracy: 0.5906 - val_loss: 0.6262 - val_accuracy: 0.6400\n",
            "Epoch 89/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6414 - accuracy: 0.5907 - val_loss: 0.6269 - val_accuracy: 0.6375\n",
            "Epoch 90/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6411 - accuracy: 0.5929 - val_loss: 0.6252 - val_accuracy: 0.6338\n",
            "Epoch 91/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6406 - accuracy: 0.5919 - val_loss: 0.6233 - val_accuracy: 0.6212\n",
            "Epoch 92/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6390 - accuracy: 0.5938 - val_loss: 0.6169 - val_accuracy: 0.5938\n",
            "Epoch 93/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6407 - accuracy: 0.5882 - val_loss: 0.6222 - val_accuracy: 0.6137\n",
            "Epoch 94/100\n",
            "57/57 [==============================] - 0s 8ms/step - loss: 0.6405 - accuracy: 0.5906 - val_loss: 0.6163 - val_accuracy: 0.6000\n",
            "Epoch 95/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6402 - accuracy: 0.5944 - val_loss: 0.6317 - val_accuracy: 0.6400\n",
            "Epoch 96/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6442 - accuracy: 0.5876 - val_loss: 0.6136 - val_accuracy: 0.6112\n",
            "Epoch 97/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6416 - accuracy: 0.5924 - val_loss: 0.6540 - val_accuracy: 0.6200\n",
            "Epoch 98/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6447 - accuracy: 0.5919 - val_loss: 0.6239 - val_accuracy: 0.6288\n",
            "Epoch 99/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6421 - accuracy: 0.5910 - val_loss: 0.6300 - val_accuracy: 0.6400\n",
            "Epoch 100/100\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.6418 - accuracy: 0.5929 - val_loss: 0.6203 - val_accuracy: 0.6050\n",
            "Epoch 1/100\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.6426 - accuracy: 0.5889 - val_loss: 0.6205 - val_accuracy: 0.6037\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6389 - accuracy: 0.5917 - val_loss: 0.6139 - val_accuracy: 0.6162\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.6426 - accuracy: 0.5901 - val_loss: 0.6257 - val_accuracy: 0.6400\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.6398 - accuracy: 0.5881 - val_loss: 0.6200 - val_accuracy: 0.6050\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.6400 - accuracy: 0.5921 - val_loss: 0.6191 - val_accuracy: 0.6075\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.6391 - accuracy: 0.5857 - val_loss: 0.6330 - val_accuracy: 0.6388\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6416 - accuracy: 0.5821 - val_loss: 0.6193 - val_accuracy: 0.6075\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6388 - accuracy: 0.5933 - val_loss: 0.6140 - val_accuracy: 0.6162\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6433 - accuracy: 0.5911 - val_loss: 0.6441 - val_accuracy: 0.6350\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6410 - accuracy: 0.5958 - val_loss: 0.6168 - val_accuracy: 0.5925\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.6423 - accuracy: 0.5844 - val_loss: 0.6174 - val_accuracy: 0.5938\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6397 - accuracy: 0.5906 - val_loss: 0.6266 - val_accuracy: 0.6400\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6397 - accuracy: 0.5911 - val_loss: 0.6166 - val_accuracy: 0.5962\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.6412 - accuracy: 0.5949 - val_loss: 0.6237 - val_accuracy: 0.6300\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6396 - accuracy: 0.5889 - val_loss: 0.6240 - val_accuracy: 0.6313\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6398 - accuracy: 0.5858 - val_loss: 0.6319 - val_accuracy: 0.6413\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6397 - accuracy: 0.5947 - val_loss: 0.6237 - val_accuracy: 0.6313\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.6407 - accuracy: 0.5901 - val_loss: 0.6225 - val_accuracy: 0.6263\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6398 - accuracy: 0.5883 - val_loss: 0.6349 - val_accuracy: 0.6375\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6404 - accuracy: 0.5931 - val_loss: 0.6212 - val_accuracy: 0.6100\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.6399 - accuracy: 0.5872 - val_loss: 0.6179 - val_accuracy: 0.6037\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6416 - accuracy: 0.5860 - val_loss: 0.6214 - val_accuracy: 0.6087\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6393 - accuracy: 0.5928 - val_loss: 0.6181 - val_accuracy: 0.6075\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6400 - accuracy: 0.5929 - val_loss: 0.6208 - val_accuracy: 0.6075\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6406 - accuracy: 0.5914 - val_loss: 0.6213 - val_accuracy: 0.6150\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6392 - accuracy: 0.5907 - val_loss: 0.6271 - val_accuracy: 0.6388\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6397 - accuracy: 0.5853 - val_loss: 0.6375 - val_accuracy: 0.6400\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6401 - accuracy: 0.5917 - val_loss: 0.6247 - val_accuracy: 0.6388\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6386 - accuracy: 0.5882 - val_loss: 0.6279 - val_accuracy: 0.6388\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6405 - accuracy: 0.5925 - val_loss: 0.6238 - val_accuracy: 0.6338\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6403 - accuracy: 0.5939 - val_loss: 0.6172 - val_accuracy: 0.6075\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6392 - accuracy: 0.5889 - val_loss: 0.6356 - val_accuracy: 0.6388\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6400 - accuracy: 0.5904 - val_loss: 0.6189 - val_accuracy: 0.6050\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6400 - accuracy: 0.5911 - val_loss: 0.6206 - val_accuracy: 0.6112\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6382 - accuracy: 0.5894 - val_loss: 0.6301 - val_accuracy: 0.6338\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6418 - accuracy: 0.5876 - val_loss: 0.6239 - val_accuracy: 0.6338\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6390 - accuracy: 0.5908 - val_loss: 0.6269 - val_accuracy: 0.6388\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 0s 17ms/step - loss: 0.6396 - accuracy: 0.5931 - val_loss: 0.6144 - val_accuracy: 0.6037\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6409 - accuracy: 0.5904 - val_loss: 0.6234 - val_accuracy: 0.6300\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6407 - accuracy: 0.5940 - val_loss: 0.6178 - val_accuracy: 0.6025\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6419 - accuracy: 0.5911 - val_loss: 0.6135 - val_accuracy: 0.6175\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6384 - accuracy: 0.5957 - val_loss: 0.6177 - val_accuracy: 0.6037\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6406 - accuracy: 0.5860 - val_loss: 0.6185 - val_accuracy: 0.6037\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6385 - accuracy: 0.5897 - val_loss: 0.6227 - val_accuracy: 0.6313\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6394 - accuracy: 0.5899 - val_loss: 0.6267 - val_accuracy: 0.6375\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6437 - accuracy: 0.5956 - val_loss: 0.6140 - val_accuracy: 0.6137\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6426 - accuracy: 0.5864 - val_loss: 0.6167 - val_accuracy: 0.5888\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6404 - accuracy: 0.5911 - val_loss: 0.6278 - val_accuracy: 0.6363\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6431 - accuracy: 0.5925 - val_loss: 0.6203 - val_accuracy: 0.6050\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6384 - accuracy: 0.5903 - val_loss: 0.6326 - val_accuracy: 0.6400\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6386 - accuracy: 0.5904 - val_loss: 0.6193 - val_accuracy: 0.6037\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6387 - accuracy: 0.5881 - val_loss: 0.6233 - val_accuracy: 0.6313\n",
            "Epoch 53/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6397 - accuracy: 0.5944 - val_loss: 0.6157 - val_accuracy: 0.5975\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6400 - accuracy: 0.5868 - val_loss: 0.6185 - val_accuracy: 0.6087\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6402 - accuracy: 0.5935 - val_loss: 0.6189 - val_accuracy: 0.6000\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6386 - accuracy: 0.5875 - val_loss: 0.6342 - val_accuracy: 0.6363\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6398 - accuracy: 0.5925 - val_loss: 0.6147 - val_accuracy: 0.6050\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6394 - accuracy: 0.5931 - val_loss: 0.6196 - val_accuracy: 0.6012\n",
            "Epoch 59/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6394 - accuracy: 0.5847 - val_loss: 0.6205 - val_accuracy: 0.6112\n",
            "Epoch 60/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6396 - accuracy: 0.5881 - val_loss: 0.6212 - val_accuracy: 0.6112\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6379 - accuracy: 0.5899 - val_loss: 0.6214 - val_accuracy: 0.6137\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6388 - accuracy: 0.5947 - val_loss: 0.6264 - val_accuracy: 0.6388\n",
            "Epoch 63/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6389 - accuracy: 0.5896 - val_loss: 0.6235 - val_accuracy: 0.6325\n",
            "Epoch 64/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6390 - accuracy: 0.5907 - val_loss: 0.6305 - val_accuracy: 0.6375\n",
            "Epoch 65/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6391 - accuracy: 0.5918 - val_loss: 0.6313 - val_accuracy: 0.6400\n",
            "Epoch 66/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6410 - accuracy: 0.5890 - val_loss: 0.6204 - val_accuracy: 0.6037\n",
            "Epoch 67/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6390 - accuracy: 0.5904 - val_loss: 0.6189 - val_accuracy: 0.6050\n",
            "Epoch 68/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6390 - accuracy: 0.5918 - val_loss: 0.6162 - val_accuracy: 0.5938\n",
            "Epoch 69/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6391 - accuracy: 0.5896 - val_loss: 0.6220 - val_accuracy: 0.6250\n",
            "Epoch 70/100\n",
            "29/29 [==============================] - 0s 16ms/step - loss: 0.6384 - accuracy: 0.5901 - val_loss: 0.6192 - val_accuracy: 0.6012\n",
            "Epoch 71/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6385 - accuracy: 0.5869 - val_loss: 0.6234 - val_accuracy: 0.6350\n",
            "Epoch 72/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6386 - accuracy: 0.5881 - val_loss: 0.6164 - val_accuracy: 0.6000\n",
            "Epoch 73/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6387 - accuracy: 0.5938 - val_loss: 0.6155 - val_accuracy: 0.5962\n",
            "Epoch 74/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6398 - accuracy: 0.5950 - val_loss: 0.6141 - val_accuracy: 0.6075\n",
            "Epoch 75/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6417 - accuracy: 0.5917 - val_loss: 0.6319 - val_accuracy: 0.6400\n",
            "Epoch 76/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6393 - accuracy: 0.5925 - val_loss: 0.6389 - val_accuracy: 0.6438\n",
            "Epoch 77/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6390 - accuracy: 0.5947 - val_loss: 0.6241 - val_accuracy: 0.6350\n",
            "Epoch 78/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6387 - accuracy: 0.5908 - val_loss: 0.6192 - val_accuracy: 0.6025\n",
            "Epoch 79/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6381 - accuracy: 0.5886 - val_loss: 0.6215 - val_accuracy: 0.6187\n",
            "Epoch 80/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6405 - accuracy: 0.5889 - val_loss: 0.6253 - val_accuracy: 0.6400\n",
            "Epoch 81/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6384 - accuracy: 0.5953 - val_loss: 0.6200 - val_accuracy: 0.6037\n",
            "Epoch 82/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6392 - accuracy: 0.5951 - val_loss: 0.6212 - val_accuracy: 0.6125\n",
            "Epoch 83/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6408 - accuracy: 0.5894 - val_loss: 0.6179 - val_accuracy: 0.6087\n",
            "Epoch 84/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6383 - accuracy: 0.5975 - val_loss: 0.6188 - val_accuracy: 0.6050\n",
            "Epoch 85/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6389 - accuracy: 0.5925 - val_loss: 0.6187 - val_accuracy: 0.5975\n",
            "Epoch 86/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6382 - accuracy: 0.5911 - val_loss: 0.6171 - val_accuracy: 0.6050\n",
            "Epoch 87/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6388 - accuracy: 0.5890 - val_loss: 0.6215 - val_accuracy: 0.6200\n",
            "Epoch 88/100\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 0.6379 - accuracy: 0.5899 - val_loss: 0.6133 - val_accuracy: 0.6150\n",
            "Epoch 89/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6444 - accuracy: 0.5906 - val_loss: 0.6315 - val_accuracy: 0.6375\n",
            "Epoch 90/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6383 - accuracy: 0.5911 - val_loss: 0.6265 - val_accuracy: 0.6350\n",
            "Epoch 91/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6382 - accuracy: 0.5886 - val_loss: 0.6342 - val_accuracy: 0.6375\n",
            "Epoch 92/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6401 - accuracy: 0.5882 - val_loss: 0.6251 - val_accuracy: 0.6400\n",
            "Epoch 93/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6398 - accuracy: 0.5921 - val_loss: 0.6179 - val_accuracy: 0.6087\n",
            "Epoch 94/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6385 - accuracy: 0.5913 - val_loss: 0.6174 - val_accuracy: 0.6062\n",
            "Epoch 95/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6412 - accuracy: 0.5951 - val_loss: 0.6252 - val_accuracy: 0.6413\n",
            "Epoch 96/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6394 - accuracy: 0.5949 - val_loss: 0.6240 - val_accuracy: 0.6413\n",
            "Epoch 97/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6378 - accuracy: 0.5908 - val_loss: 0.6149 - val_accuracy: 0.5975\n",
            "Epoch 98/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6387 - accuracy: 0.5890 - val_loss: 0.6214 - val_accuracy: 0.6263\n",
            "Epoch 99/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.6403 - accuracy: 0.5857 - val_loss: 0.6233 - val_accuracy: 0.6363\n",
            "Epoch 100/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.6380 - accuracy: 0.5924 - val_loss: 0.6241 - val_accuracy: 0.6363\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.6376 - accuracy: 0.5907 - val_loss: 0.6334 - val_accuracy: 0.6413\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6432 - accuracy: 0.5922 - val_loss: 0.6359 - val_accuracy: 0.6388\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6412 - accuracy: 0.5957 - val_loss: 0.6262 - val_accuracy: 0.6375\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 0.6402 - accuracy: 0.5935 - val_loss: 0.6331 - val_accuracy: 0.6388\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6394 - accuracy: 0.5940 - val_loss: 0.6321 - val_accuracy: 0.6363\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6408 - accuracy: 0.5897 - val_loss: 0.6266 - val_accuracy: 0.6363\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.6384 - accuracy: 0.5904 - val_loss: 0.6189 - val_accuracy: 0.6050\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6375 - accuracy: 0.5899 - val_loss: 0.6216 - val_accuracy: 0.6212\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6374 - accuracy: 0.5888 - val_loss: 0.6254 - val_accuracy: 0.6413\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6378 - accuracy: 0.5897 - val_loss: 0.6243 - val_accuracy: 0.6400\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6377 - accuracy: 0.5921 - val_loss: 0.6156 - val_accuracy: 0.6000\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6424 - accuracy: 0.5929 - val_loss: 0.6264 - val_accuracy: 0.6375\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.6391 - accuracy: 0.5947 - val_loss: 0.6216 - val_accuracy: 0.6325\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6379 - accuracy: 0.5910 - val_loss: 0.6260 - val_accuracy: 0.6375\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6374 - accuracy: 0.5900 - val_loss: 0.6329 - val_accuracy: 0.6413\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6430 - accuracy: 0.5861 - val_loss: 0.6472 - val_accuracy: 0.6225\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.6565 - accuracy: 0.5828 - val_loss: 0.6313 - val_accuracy: 0.6313\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6396 - accuracy: 0.5894 - val_loss: 0.6296 - val_accuracy: 0.6313\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6416 - accuracy: 0.5982 - val_loss: 0.6183 - val_accuracy: 0.6050\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6380 - accuracy: 0.5910 - val_loss: 0.6232 - val_accuracy: 0.6388\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6384 - accuracy: 0.5892 - val_loss: 0.6308 - val_accuracy: 0.6400\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6439 - accuracy: 0.5965 - val_loss: 0.6183 - val_accuracy: 0.6037\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6385 - accuracy: 0.5893 - val_loss: 0.6187 - val_accuracy: 0.6037\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6386 - accuracy: 0.5904 - val_loss: 0.6244 - val_accuracy: 0.6425\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6387 - accuracy: 0.5897 - val_loss: 0.6217 - val_accuracy: 0.6350\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6386 - accuracy: 0.5883 - val_loss: 0.6238 - val_accuracy: 0.6363\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6377 - accuracy: 0.5949 - val_loss: 0.6239 - val_accuracy: 0.6400\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6377 - accuracy: 0.5888 - val_loss: 0.6250 - val_accuracy: 0.6413\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6380 - accuracy: 0.5919 - val_loss: 0.6168 - val_accuracy: 0.6037\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6380 - accuracy: 0.5876 - val_loss: 0.6158 - val_accuracy: 0.5987\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6384 - accuracy: 0.5961 - val_loss: 0.6148 - val_accuracy: 0.6025\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.6394 - accuracy: 0.5914 - val_loss: 0.6147 - val_accuracy: 0.5950\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.6394 - accuracy: 0.5882 - val_loss: 0.6152 - val_accuracy: 0.5962\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6392 - accuracy: 0.5908 - val_loss: 0.6153 - val_accuracy: 0.5975\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6371 - accuracy: 0.5900 - val_loss: 0.6209 - val_accuracy: 0.6250\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 0.6394 - accuracy: 0.5908 - val_loss: 0.6201 - val_accuracy: 0.6150\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6410 - accuracy: 0.5896 - val_loss: 0.6165 - val_accuracy: 0.6050\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6423 - accuracy: 0.5893 - val_loss: 0.6191 - val_accuracy: 0.6075\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6383 - accuracy: 0.5921 - val_loss: 0.6219 - val_accuracy: 0.6375\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6372 - accuracy: 0.5908 - val_loss: 0.6192 - val_accuracy: 0.6137\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6385 - accuracy: 0.5889 - val_loss: 0.6200 - val_accuracy: 0.6162\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6383 - accuracy: 0.5942 - val_loss: 0.6172 - val_accuracy: 0.6062\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6374 - accuracy: 0.5919 - val_loss: 0.6164 - val_accuracy: 0.6037\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6373 - accuracy: 0.5931 - val_loss: 0.6253 - val_accuracy: 0.6363\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6382 - accuracy: 0.5922 - val_loss: 0.6190 - val_accuracy: 0.5987\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6380 - accuracy: 0.5899 - val_loss: 0.6169 - val_accuracy: 0.6000\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6380 - accuracy: 0.5904 - val_loss: 0.6232 - val_accuracy: 0.6350\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6373 - accuracy: 0.5947 - val_loss: 0.6228 - val_accuracy: 0.6350\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.6375 - accuracy: 0.5950 - val_loss: 0.6187 - val_accuracy: 0.6062\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6371 - accuracy: 0.5922 - val_loss: 0.6227 - val_accuracy: 0.6350\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.6372 - accuracy: 0.5890 - val_loss: 0.6205 - val_accuracy: 0.6137\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6375 - accuracy: 0.5860 - val_loss: 0.6186 - val_accuracy: 0.6050\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6451 - accuracy: 0.5931 - val_loss: 0.6219 - val_accuracy: 0.6237\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6382 - accuracy: 0.5933 - val_loss: 0.6225 - val_accuracy: 0.6275\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6368 - accuracy: 0.5996 - val_loss: 0.6165 - val_accuracy: 0.6000\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6371 - accuracy: 0.5932 - val_loss: 0.6197 - val_accuracy: 0.6012\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6370 - accuracy: 0.5893 - val_loss: 0.6271 - val_accuracy: 0.6338\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.6384 - accuracy: 0.5935 - val_loss: 0.6373 - val_accuracy: 0.6450\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6394 - accuracy: 0.5914 - val_loss: 0.6234 - val_accuracy: 0.6338\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6371 - accuracy: 0.5956 - val_loss: 0.6180 - val_accuracy: 0.6050\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6373 - accuracy: 0.5910 - val_loss: 0.6165 - val_accuracy: 0.6050\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.6384 - accuracy: 0.5928 - val_loss: 0.6205 - val_accuracy: 0.6150\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6368 - accuracy: 0.5925 - val_loss: 0.6217 - val_accuracy: 0.6300\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6377 - accuracy: 0.5917 - val_loss: 0.6324 - val_accuracy: 0.6413\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.6396 - accuracy: 0.5942 - val_loss: 0.6323 - val_accuracy: 0.6413\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.6368 - accuracy: 0.5949 - val_loss: 0.6160 - val_accuracy: 0.6037\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.6382 - accuracy: 0.5885 - val_loss: 0.6181 - val_accuracy: 0.6025\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6373 - accuracy: 0.5885 - val_loss: 0.6194 - val_accuracy: 0.6137\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6370 - accuracy: 0.5968 - val_loss: 0.6158 - val_accuracy: 0.6050\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6387 - accuracy: 0.5886 - val_loss: 0.6164 - val_accuracy: 0.6075\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 0.6389 - accuracy: 0.5943 - val_loss: 0.6141 - val_accuracy: 0.5962\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.6387 - accuracy: 0.5993 - val_loss: 0.6142 - val_accuracy: 0.6000\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6384 - accuracy: 0.5962 - val_loss: 0.6194 - val_accuracy: 0.6112\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.6381 - accuracy: 0.5867 - val_loss: 0.6201 - val_accuracy: 0.6137\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6393 - accuracy: 0.5906 - val_loss: 0.6304 - val_accuracy: 0.6400\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6459 - accuracy: 0.5951 - val_loss: 0.6333 - val_accuracy: 0.6375\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6398 - accuracy: 0.5947 - val_loss: 0.6315 - val_accuracy: 0.6413\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.6459 - accuracy: 0.5936 - val_loss: 0.6342 - val_accuracy: 0.6363\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.6459 - accuracy: 0.5883 - val_loss: 0.6259 - val_accuracy: 0.6338\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6380 - accuracy: 0.5919 - val_loss: 0.6313 - val_accuracy: 0.6350\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6365 - accuracy: 0.5911 - val_loss: 0.6163 - val_accuracy: 0.5962\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.6381 - accuracy: 0.5882 - val_loss: 0.6195 - val_accuracy: 0.6037\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.6379 - accuracy: 0.5943 - val_loss: 0.6230 - val_accuracy: 0.6338\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6368 - accuracy: 0.5950 - val_loss: 0.6251 - val_accuracy: 0.6400\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6381 - accuracy: 0.5967 - val_loss: 0.6220 - val_accuracy: 0.6300\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6401 - accuracy: 0.5903 - val_loss: 0.6262 - val_accuracy: 0.6338\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.6377 - accuracy: 0.5888 - val_loss: 0.6252 - val_accuracy: 0.6350\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6377 - accuracy: 0.5899 - val_loss: 0.6252 - val_accuracy: 0.6338\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6375 - accuracy: 0.5944 - val_loss: 0.6291 - val_accuracy: 0.6450\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6374 - accuracy: 0.5947 - val_loss: 0.6284 - val_accuracy: 0.6400\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6369 - accuracy: 0.5908 - val_loss: 0.6209 - val_accuracy: 0.6125\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6369 - accuracy: 0.5951 - val_loss: 0.6231 - val_accuracy: 0.6325\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6373 - accuracy: 0.5947 - val_loss: 0.6252 - val_accuracy: 0.6400\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6371 - accuracy: 0.5888 - val_loss: 0.6214 - val_accuracy: 0.6212\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6377 - accuracy: 0.5925 - val_loss: 0.6178 - val_accuracy: 0.6012\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6379 - accuracy: 0.5893 - val_loss: 0.6151 - val_accuracy: 0.5938\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6404 - accuracy: 0.5942 - val_loss: 0.6159 - val_accuracy: 0.5987\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6391 - accuracy: 0.5971 - val_loss: 0.6179 - val_accuracy: 0.6075\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6405 - accuracy: 0.5886 - val_loss: 0.6172 - val_accuracy: 0.5975\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6382 - accuracy: 0.5882 - val_loss: 0.6218 - val_accuracy: 0.6288\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsYuZ-6f8Nu9"
      },
      "source": [
        "**Epoch number setting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxBR8PaC9ykZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d37f9f2-8f01-45e4-dd88-c9644b6fafcc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def model_score(model, X_train, y_train, X_test, y_test):\n",
        "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
        "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return trainScore[0], testScore[0]\n",
        "\n",
        "def quick_measure(epoch):\n",
        "    model = model_lstm\n",
        "    model.fit(train_x, train_y, batch_size=32, epochs=epoch, validation_split=0.1, verbose=1)\n",
        "    trainScore, testScore = model_score(model, train_x, train_y, test_x, test_y)\n",
        "    return trainScore, testScore\n",
        "\n",
        "epochlist = [50, 100, 250, 500, 1000]\n",
        "\n",
        "epoch_result = {}\n",
        "\n",
        "for epoch in epochlist:    \n",
        "    trainScore, testScore = quick_measure(epoch)\n",
        "    epoch_result[epoch] = testScore\n",
        "\n",
        "lists = sorted(epoch_result.items())\n",
        "x,y = zip(*lists)\n",
        "plt.plot(x,y)\n",
        "plt.title('Finding the best hyperparameter')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Square Error')\n",
        "plt.show()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6440 - accuracy: 0.5926 - val_loss: 0.6236 - val_accuracy: 0.6375\n",
            "Epoch 2/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6478 - accuracy: 0.5978 - val_loss: 0.6219 - val_accuracy: 0.6187\n",
            "Epoch 3/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6438 - accuracy: 0.5936 - val_loss: 0.6239 - val_accuracy: 0.6350\n",
            "Epoch 4/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6425 - accuracy: 0.5896 - val_loss: 0.6127 - val_accuracy: 0.6150\n",
            "Epoch 5/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6487 - accuracy: 0.5924 - val_loss: 0.6143 - val_accuracy: 0.6150\n",
            "Epoch 6/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6464 - accuracy: 0.5892 - val_loss: 0.6212 - val_accuracy: 0.6000\n",
            "Epoch 7/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6433 - accuracy: 0.5826 - val_loss: 0.6134 - val_accuracy: 0.6175\n",
            "Epoch 8/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6410 - accuracy: 0.5936 - val_loss: 0.6119 - val_accuracy: 0.6100\n",
            "Epoch 9/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6449 - accuracy: 0.5913 - val_loss: 0.6194 - val_accuracy: 0.6100\n",
            "Epoch 10/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6426 - accuracy: 0.5924 - val_loss: 0.6130 - val_accuracy: 0.6150\n",
            "Epoch 11/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6425 - accuracy: 0.5946 - val_loss: 0.6165 - val_accuracy: 0.6075\n",
            "Epoch 12/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6416 - accuracy: 0.5903 - val_loss: 0.6216 - val_accuracy: 0.6212\n",
            "Epoch 13/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6421 - accuracy: 0.5944 - val_loss: 0.6304 - val_accuracy: 0.6438\n",
            "Epoch 14/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6476 - accuracy: 0.5846 - val_loss: 0.6144 - val_accuracy: 0.6125\n",
            "Epoch 15/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6435 - accuracy: 0.5910 - val_loss: 0.6133 - val_accuracy: 0.6075\n",
            "Epoch 16/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6417 - accuracy: 0.5907 - val_loss: 0.6184 - val_accuracy: 0.6000\n",
            "Epoch 17/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6460 - accuracy: 0.5881 - val_loss: 0.6298 - val_accuracy: 0.6313\n",
            "Epoch 18/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6416 - accuracy: 0.5961 - val_loss: 0.6137 - val_accuracy: 0.6162\n",
            "Epoch 19/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6436 - accuracy: 0.5903 - val_loss: 0.6153 - val_accuracy: 0.6000\n",
            "Epoch 20/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6437 - accuracy: 0.5865 - val_loss: 0.6464 - val_accuracy: 0.6300\n",
            "Epoch 21/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6411 - accuracy: 0.5932 - val_loss: 0.6239 - val_accuracy: 0.6425\n",
            "Epoch 22/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6420 - accuracy: 0.5926 - val_loss: 0.6154 - val_accuracy: 0.6037\n",
            "Epoch 23/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6418 - accuracy: 0.5883 - val_loss: 0.6259 - val_accuracy: 0.6363\n",
            "Epoch 24/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6418 - accuracy: 0.5947 - val_loss: 0.6332 - val_accuracy: 0.6313\n",
            "Epoch 25/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6409 - accuracy: 0.5899 - val_loss: 0.6197 - val_accuracy: 0.6125\n",
            "Epoch 26/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6419 - accuracy: 0.5942 - val_loss: 0.6205 - val_accuracy: 0.6275\n",
            "Epoch 27/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6438 - accuracy: 0.5926 - val_loss: 0.6215 - val_accuracy: 0.6375\n",
            "Epoch 28/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6437 - accuracy: 0.5863 - val_loss: 0.6266 - val_accuracy: 0.6325\n",
            "Epoch 29/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6427 - accuracy: 0.5965 - val_loss: 0.6256 - val_accuracy: 0.6375\n",
            "Epoch 30/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6400 - accuracy: 0.5921 - val_loss: 0.6142 - val_accuracy: 0.6087\n",
            "Epoch 31/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6444 - accuracy: 0.5956 - val_loss: 0.6241 - val_accuracy: 0.6413\n",
            "Epoch 32/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6424 - accuracy: 0.5982 - val_loss: 0.6200 - val_accuracy: 0.6275\n",
            "Epoch 33/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6421 - accuracy: 0.5931 - val_loss: 0.6203 - val_accuracy: 0.6225\n",
            "Epoch 34/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6418 - accuracy: 0.5940 - val_loss: 0.6219 - val_accuracy: 0.6425\n",
            "Epoch 35/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6409 - accuracy: 0.5907 - val_loss: 0.6308 - val_accuracy: 0.6388\n",
            "Epoch 36/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6452 - accuracy: 0.5931 - val_loss: 0.6132 - val_accuracy: 0.6050\n",
            "Epoch 37/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6428 - accuracy: 0.5888 - val_loss: 0.6118 - val_accuracy: 0.6075\n",
            "Epoch 38/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6420 - accuracy: 0.5903 - val_loss: 0.6316 - val_accuracy: 0.6300\n",
            "Epoch 39/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6397 - accuracy: 0.5972 - val_loss: 0.6110 - val_accuracy: 0.6100\n",
            "Epoch 40/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6418 - accuracy: 0.5933 - val_loss: 0.6587 - val_accuracy: 0.6062\n",
            "Epoch 41/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6469 - accuracy: 0.5903 - val_loss: 0.6108 - val_accuracy: 0.6075\n",
            "Epoch 42/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6438 - accuracy: 0.5874 - val_loss: 0.6452 - val_accuracy: 0.6388\n",
            "Epoch 43/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6430 - accuracy: 0.5929 - val_loss: 0.6153 - val_accuracy: 0.6037\n",
            "Epoch 44/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6415 - accuracy: 0.5899 - val_loss: 0.6250 - val_accuracy: 0.6413\n",
            "Epoch 45/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6441 - accuracy: 0.5892 - val_loss: 0.6112 - val_accuracy: 0.6162\n",
            "Epoch 46/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6437 - accuracy: 0.5893 - val_loss: 0.6149 - val_accuracy: 0.6025\n",
            "Epoch 47/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6417 - accuracy: 0.5910 - val_loss: 0.6125 - val_accuracy: 0.6100\n",
            "Epoch 48/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6417 - accuracy: 0.5978 - val_loss: 0.6110 - val_accuracy: 0.6125\n",
            "Epoch 49/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6411 - accuracy: 0.5921 - val_loss: 0.6186 - val_accuracy: 0.6212\n",
            "Epoch 50/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6407 - accuracy: 0.5914 - val_loss: 0.6137 - val_accuracy: 0.6112\n",
            "Epoch 1/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6419 - accuracy: 0.5965 - val_loss: 0.6226 - val_accuracy: 0.6425\n",
            "Epoch 2/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6409 - accuracy: 0.5938 - val_loss: 0.6204 - val_accuracy: 0.6388\n",
            "Epoch 3/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6418 - accuracy: 0.5900 - val_loss: 0.6112 - val_accuracy: 0.6125\n",
            "Epoch 4/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6411 - accuracy: 0.5950 - val_loss: 0.6624 - val_accuracy: 0.6100\n",
            "Epoch 5/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6408 - accuracy: 0.5938 - val_loss: 0.6141 - val_accuracy: 0.6100\n",
            "Epoch 6/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6414 - accuracy: 0.5954 - val_loss: 0.6107 - val_accuracy: 0.6150\n",
            "Epoch 7/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6406 - accuracy: 0.5958 - val_loss: 0.6147 - val_accuracy: 0.5950\n",
            "Epoch 8/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6410 - accuracy: 0.5915 - val_loss: 0.6112 - val_accuracy: 0.6162\n",
            "Epoch 9/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6427 - accuracy: 0.5900 - val_loss: 0.6211 - val_accuracy: 0.6375\n",
            "Epoch 10/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6402 - accuracy: 0.5971 - val_loss: 0.6229 - val_accuracy: 0.6413\n",
            "Epoch 11/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6409 - accuracy: 0.5922 - val_loss: 0.6278 - val_accuracy: 0.6550\n",
            "Epoch 12/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6406 - accuracy: 0.5932 - val_loss: 0.6216 - val_accuracy: 0.6438\n",
            "Epoch 13/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6410 - accuracy: 0.5875 - val_loss: 0.6290 - val_accuracy: 0.6338\n",
            "Epoch 14/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6426 - accuracy: 0.5874 - val_loss: 0.6110 - val_accuracy: 0.6125\n",
            "Epoch 15/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6399 - accuracy: 0.5947 - val_loss: 0.6292 - val_accuracy: 0.6313\n",
            "Epoch 16/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6387 - accuracy: 0.5972 - val_loss: 0.6164 - val_accuracy: 0.6212\n",
            "Epoch 17/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6395 - accuracy: 0.5908 - val_loss: 0.6125 - val_accuracy: 0.6087\n",
            "Epoch 18/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6428 - accuracy: 0.5908 - val_loss: 0.6212 - val_accuracy: 0.6025\n",
            "Epoch 19/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6426 - accuracy: 0.5908 - val_loss: 0.6104 - val_accuracy: 0.6125\n",
            "Epoch 20/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6389 - accuracy: 0.5979 - val_loss: 0.6144 - val_accuracy: 0.5975\n",
            "Epoch 21/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6396 - accuracy: 0.5961 - val_loss: 0.6219 - val_accuracy: 0.6425\n",
            "Epoch 22/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6425 - accuracy: 0.5847 - val_loss: 0.6288 - val_accuracy: 0.6375\n",
            "Epoch 23/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6407 - accuracy: 0.5951 - val_loss: 0.6249 - val_accuracy: 0.6313\n",
            "Epoch 24/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6417 - accuracy: 0.5953 - val_loss: 0.6178 - val_accuracy: 0.6288\n",
            "Epoch 25/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6435 - accuracy: 0.5897 - val_loss: 0.6449 - val_accuracy: 0.6275\n",
            "Epoch 26/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6419 - accuracy: 0.5947 - val_loss: 0.6379 - val_accuracy: 0.6463\n",
            "Epoch 27/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6392 - accuracy: 0.5950 - val_loss: 0.6293 - val_accuracy: 0.6325\n",
            "Epoch 28/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6376 - accuracy: 0.5971 - val_loss: 0.6307 - val_accuracy: 0.6475\n",
            "Epoch 29/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6396 - accuracy: 0.5953 - val_loss: 0.6159 - val_accuracy: 0.6150\n",
            "Epoch 30/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6375 - accuracy: 0.5946 - val_loss: 0.6212 - val_accuracy: 0.6425\n",
            "Epoch 31/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6375 - accuracy: 0.6001 - val_loss: 0.6312 - val_accuracy: 0.6413\n",
            "Epoch 32/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6397 - accuracy: 0.5950 - val_loss: 0.6387 - val_accuracy: 0.6375\n",
            "Epoch 33/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6429 - accuracy: 0.5996 - val_loss: 0.6136 - val_accuracy: 0.6025\n",
            "Epoch 34/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6405 - accuracy: 0.5946 - val_loss: 0.6261 - val_accuracy: 0.6300\n",
            "Epoch 35/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6397 - accuracy: 0.5989 - val_loss: 0.6131 - val_accuracy: 0.6025\n",
            "Epoch 36/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6383 - accuracy: 0.5979 - val_loss: 0.6387 - val_accuracy: 0.6350\n",
            "Epoch 37/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6382 - accuracy: 0.5994 - val_loss: 0.6232 - val_accuracy: 0.6325\n",
            "Epoch 38/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6395 - accuracy: 0.5958 - val_loss: 0.6318 - val_accuracy: 0.6513\n",
            "Epoch 39/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6397 - accuracy: 0.5983 - val_loss: 0.6149 - val_accuracy: 0.6062\n",
            "Epoch 40/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6420 - accuracy: 0.5904 - val_loss: 0.6096 - val_accuracy: 0.6137\n",
            "Epoch 41/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6413 - accuracy: 0.5938 - val_loss: 0.6148 - val_accuracy: 0.6000\n",
            "Epoch 42/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6380 - accuracy: 0.5938 - val_loss: 0.6222 - val_accuracy: 0.6288\n",
            "Epoch 43/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6385 - accuracy: 0.5951 - val_loss: 0.6150 - val_accuracy: 0.6125\n",
            "Epoch 44/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6404 - accuracy: 0.5954 - val_loss: 0.6179 - val_accuracy: 0.6400\n",
            "Epoch 45/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6435 - accuracy: 0.5921 - val_loss: 0.6193 - val_accuracy: 0.6375\n",
            "Epoch 46/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6393 - accuracy: 0.5939 - val_loss: 0.6183 - val_accuracy: 0.6375\n",
            "Epoch 47/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6399 - accuracy: 0.5976 - val_loss: 0.6311 - val_accuracy: 0.6288\n",
            "Epoch 48/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6399 - accuracy: 0.5949 - val_loss: 0.6252 - val_accuracy: 0.6338\n",
            "Epoch 49/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6388 - accuracy: 0.5974 - val_loss: 0.6309 - val_accuracy: 0.6300\n",
            "Epoch 50/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6390 - accuracy: 0.5962 - val_loss: 0.6154 - val_accuracy: 0.6000\n",
            "Epoch 51/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6405 - accuracy: 0.5936 - val_loss: 0.6147 - val_accuracy: 0.6162\n",
            "Epoch 52/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6421 - accuracy: 0.5950 - val_loss: 0.6297 - val_accuracy: 0.6313\n",
            "Epoch 53/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6422 - accuracy: 0.5971 - val_loss: 0.6080 - val_accuracy: 0.6000\n",
            "Epoch 54/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6399 - accuracy: 0.5976 - val_loss: 0.6152 - val_accuracy: 0.6187\n",
            "Epoch 55/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6390 - accuracy: 0.5992 - val_loss: 0.6154 - val_accuracy: 0.6150\n",
            "Epoch 56/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6441 - accuracy: 0.5876 - val_loss: 0.6082 - val_accuracy: 0.6112\n",
            "Epoch 57/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6411 - accuracy: 0.5944 - val_loss: 0.6316 - val_accuracy: 0.6425\n",
            "Epoch 58/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6381 - accuracy: 0.5926 - val_loss: 0.6342 - val_accuracy: 0.6400\n",
            "Epoch 59/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6373 - accuracy: 0.6008 - val_loss: 0.6201 - val_accuracy: 0.6400\n",
            "Epoch 60/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6375 - accuracy: 0.5924 - val_loss: 0.6286 - val_accuracy: 0.6363\n",
            "Epoch 61/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6404 - accuracy: 0.5942 - val_loss: 0.6205 - val_accuracy: 0.6400\n",
            "Epoch 62/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6380 - accuracy: 0.5972 - val_loss: 0.6471 - val_accuracy: 0.6225\n",
            "Epoch 63/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6394 - accuracy: 0.5944 - val_loss: 0.6155 - val_accuracy: 0.6338\n",
            "Epoch 64/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6409 - accuracy: 0.5919 - val_loss: 0.6096 - val_accuracy: 0.6137\n",
            "Epoch 65/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6382 - accuracy: 0.5985 - val_loss: 0.6250 - val_accuracy: 0.6313\n",
            "Epoch 66/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6415 - accuracy: 0.5944 - val_loss: 0.6277 - val_accuracy: 0.6313\n",
            "Epoch 67/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6474 - accuracy: 0.5882 - val_loss: 0.6454 - val_accuracy: 0.6250\n",
            "Epoch 68/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6381 - accuracy: 0.5933 - val_loss: 0.6235 - val_accuracy: 0.6325\n",
            "Epoch 69/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6377 - accuracy: 0.5964 - val_loss: 0.6146 - val_accuracy: 0.6150\n",
            "Epoch 70/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6385 - accuracy: 0.5975 - val_loss: 0.6266 - val_accuracy: 0.6463\n",
            "Epoch 71/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6401 - accuracy: 0.5918 - val_loss: 0.6130 - val_accuracy: 0.6012\n",
            "Epoch 72/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6380 - accuracy: 0.5972 - val_loss: 0.6163 - val_accuracy: 0.6413\n",
            "Epoch 73/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6410 - accuracy: 0.6024 - val_loss: 0.6359 - val_accuracy: 0.6388\n",
            "Epoch 74/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6406 - accuracy: 0.6003 - val_loss: 0.6133 - val_accuracy: 0.6062\n",
            "Epoch 75/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6405 - accuracy: 0.5969 - val_loss: 0.6664 - val_accuracy: 0.5975\n",
            "Epoch 76/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6420 - accuracy: 0.5921 - val_loss: 0.6283 - val_accuracy: 0.6325\n",
            "Epoch 77/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6396 - accuracy: 0.5976 - val_loss: 0.6075 - val_accuracy: 0.6150\n",
            "Epoch 78/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6418 - accuracy: 0.5932 - val_loss: 0.6121 - val_accuracy: 0.6025\n",
            "Epoch 79/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6370 - accuracy: 0.5992 - val_loss: 0.6091 - val_accuracy: 0.6137\n",
            "Epoch 80/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6406 - accuracy: 0.5958 - val_loss: 0.6105 - val_accuracy: 0.6050\n",
            "Epoch 81/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6402 - accuracy: 0.5974 - val_loss: 0.6796 - val_accuracy: 0.5962\n",
            "Epoch 82/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6400 - accuracy: 0.5933 - val_loss: 0.6113 - val_accuracy: 0.6012\n",
            "Epoch 83/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6405 - accuracy: 0.5978 - val_loss: 0.6327 - val_accuracy: 0.6425\n",
            "Epoch 84/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6382 - accuracy: 0.5993 - val_loss: 0.6119 - val_accuracy: 0.6025\n",
            "Epoch 85/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6398 - accuracy: 0.5946 - val_loss: 0.6136 - val_accuracy: 0.6288\n",
            "Epoch 86/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6354 - accuracy: 0.6018 - val_loss: 0.6288 - val_accuracy: 0.6550\n",
            "Epoch 87/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6393 - accuracy: 0.5987 - val_loss: 0.6236 - val_accuracy: 0.6325\n",
            "Epoch 88/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6369 - accuracy: 0.5996 - val_loss: 0.6240 - val_accuracy: 0.6300\n",
            "Epoch 89/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6361 - accuracy: 0.5986 - val_loss: 0.6310 - val_accuracy: 0.6388\n",
            "Epoch 90/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6395 - accuracy: 0.5979 - val_loss: 0.6121 - val_accuracy: 0.6125\n",
            "Epoch 91/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6380 - accuracy: 0.5986 - val_loss: 0.6140 - val_accuracy: 0.6112\n",
            "Epoch 92/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6381 - accuracy: 0.5979 - val_loss: 0.6283 - val_accuracy: 0.6338\n",
            "Epoch 93/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6402 - accuracy: 0.5960 - val_loss: 0.6235 - val_accuracy: 0.6325\n",
            "Epoch 94/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6420 - accuracy: 0.5939 - val_loss: 0.6152 - val_accuracy: 0.6413\n",
            "Epoch 95/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6390 - accuracy: 0.5960 - val_loss: 0.6115 - val_accuracy: 0.6025\n",
            "Epoch 96/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6402 - accuracy: 0.5961 - val_loss: 0.6243 - val_accuracy: 0.6388\n",
            "Epoch 97/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6378 - accuracy: 0.5944 - val_loss: 0.6079 - val_accuracy: 0.6112\n",
            "Epoch 98/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6414 - accuracy: 0.5967 - val_loss: 0.6086 - val_accuracy: 0.6150\n",
            "Epoch 99/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6380 - accuracy: 0.5968 - val_loss: 0.6102 - val_accuracy: 0.5987\n",
            "Epoch 100/100\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6365 - accuracy: 0.6021 - val_loss: 0.6202 - val_accuracy: 0.6413\n",
            "Epoch 1/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6388 - accuracy: 0.5913 - val_loss: 0.6150 - val_accuracy: 0.6463\n",
            "Epoch 2/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6405 - accuracy: 0.5969 - val_loss: 0.6401 - val_accuracy: 0.6150\n",
            "Epoch 3/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6385 - accuracy: 0.5982 - val_loss: 0.6163 - val_accuracy: 0.6400\n",
            "Epoch 4/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6390 - accuracy: 0.5983 - val_loss: 0.6572 - val_accuracy: 0.6050\n",
            "Epoch 5/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6379 - accuracy: 0.6018 - val_loss: 0.6122 - val_accuracy: 0.6162\n",
            "Epoch 6/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6379 - accuracy: 0.5949 - val_loss: 0.6122 - val_accuracy: 0.6125\n",
            "Epoch 7/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6380 - accuracy: 0.5992 - val_loss: 0.6219 - val_accuracy: 0.6325\n",
            "Epoch 8/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6369 - accuracy: 0.5953 - val_loss: 0.6247 - val_accuracy: 0.6375\n",
            "Epoch 9/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6404 - accuracy: 0.5967 - val_loss: 0.6140 - val_accuracy: 0.6300\n",
            "Epoch 10/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6378 - accuracy: 0.6025 - val_loss: 0.6336 - val_accuracy: 0.6237\n",
            "Epoch 11/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6381 - accuracy: 0.5943 - val_loss: 0.6172 - val_accuracy: 0.6363\n",
            "Epoch 12/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6371 - accuracy: 0.5974 - val_loss: 0.6097 - val_accuracy: 0.5987\n",
            "Epoch 13/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6380 - accuracy: 0.6031 - val_loss: 0.6137 - val_accuracy: 0.6137\n",
            "Epoch 14/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6386 - accuracy: 0.5928 - val_loss: 0.6225 - val_accuracy: 0.6313\n",
            "Epoch 15/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6364 - accuracy: 0.5957 - val_loss: 0.6143 - val_accuracy: 0.6463\n",
            "Epoch 16/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6360 - accuracy: 0.6021 - val_loss: 0.6078 - val_accuracy: 0.6125\n",
            "Epoch 17/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6367 - accuracy: 0.6040 - val_loss: 0.6094 - val_accuracy: 0.5987\n",
            "Epoch 18/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6357 - accuracy: 0.5999 - val_loss: 0.6090 - val_accuracy: 0.6012\n",
            "Epoch 19/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6375 - accuracy: 0.5975 - val_loss: 0.6094 - val_accuracy: 0.6000\n",
            "Epoch 20/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6372 - accuracy: 0.6039 - val_loss: 0.6171 - val_accuracy: 0.6375\n",
            "Epoch 21/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6421 - accuracy: 0.5929 - val_loss: 0.6080 - val_accuracy: 0.6075\n",
            "Epoch 22/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6373 - accuracy: 0.6028 - val_loss: 0.6118 - val_accuracy: 0.6112\n",
            "Epoch 23/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6396 - accuracy: 0.5986 - val_loss: 0.6175 - val_accuracy: 0.6375\n",
            "Epoch 24/250\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6402 - accuracy: 0.5949 - val_loss: 0.6082 - val_accuracy: 0.6050\n",
            "Epoch 25/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6369 - accuracy: 0.6015 - val_loss: 0.6131 - val_accuracy: 0.6263\n",
            "Epoch 26/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6373 - accuracy: 0.5997 - val_loss: 0.6145 - val_accuracy: 0.6450\n",
            "Epoch 27/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6383 - accuracy: 0.5978 - val_loss: 0.6116 - val_accuracy: 0.6300\n",
            "Epoch 28/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6358 - accuracy: 0.6029 - val_loss: 0.6141 - val_accuracy: 0.6400\n",
            "Epoch 29/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6390 - accuracy: 0.5967 - val_loss: 0.6149 - val_accuracy: 0.6388\n",
            "Epoch 30/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6358 - accuracy: 0.5971 - val_loss: 0.6093 - val_accuracy: 0.6100\n",
            "Epoch 31/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6370 - accuracy: 0.5987 - val_loss: 0.6090 - val_accuracy: 0.5987\n",
            "Epoch 32/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6389 - accuracy: 0.5974 - val_loss: 0.6110 - val_accuracy: 0.6187\n",
            "Epoch 33/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6356 - accuracy: 0.6028 - val_loss: 0.6233 - val_accuracy: 0.6350\n",
            "Epoch 34/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6369 - accuracy: 0.6007 - val_loss: 0.6132 - val_accuracy: 0.6425\n",
            "Epoch 35/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6351 - accuracy: 0.6014 - val_loss: 0.6119 - val_accuracy: 0.6438\n",
            "Epoch 36/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6383 - accuracy: 0.5965 - val_loss: 0.6092 - val_accuracy: 0.6125\n",
            "Epoch 37/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6408 - accuracy: 0.5953 - val_loss: 0.6060 - val_accuracy: 0.6137\n",
            "Epoch 38/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6372 - accuracy: 0.5992 - val_loss: 0.6082 - val_accuracy: 0.5975\n",
            "Epoch 39/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6386 - accuracy: 0.5974 - val_loss: 0.6250 - val_accuracy: 0.6363\n",
            "Epoch 40/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6357 - accuracy: 0.6029 - val_loss: 0.6049 - val_accuracy: 0.6137\n",
            "Epoch 41/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6361 - accuracy: 0.5983 - val_loss: 0.6176 - val_accuracy: 0.6363\n",
            "Epoch 42/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6364 - accuracy: 0.5997 - val_loss: 0.6520 - val_accuracy: 0.6237\n",
            "Epoch 43/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6397 - accuracy: 0.5974 - val_loss: 0.6063 - val_accuracy: 0.6137\n",
            "Epoch 44/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6353 - accuracy: 0.5989 - val_loss: 0.6119 - val_accuracy: 0.6162\n",
            "Epoch 45/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6354 - accuracy: 0.6032 - val_loss: 0.6183 - val_accuracy: 0.6325\n",
            "Epoch 46/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6361 - accuracy: 0.5985 - val_loss: 0.6245 - val_accuracy: 0.6325\n",
            "Epoch 47/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6362 - accuracy: 0.5996 - val_loss: 0.6078 - val_accuracy: 0.6025\n",
            "Epoch 48/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6357 - accuracy: 0.6029 - val_loss: 0.6113 - val_accuracy: 0.6325\n",
            "Epoch 49/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6364 - accuracy: 0.6026 - val_loss: 0.6285 - val_accuracy: 0.6300\n",
            "Epoch 50/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6358 - accuracy: 0.6024 - val_loss: 0.6170 - val_accuracy: 0.6350\n",
            "Epoch 51/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6352 - accuracy: 0.6019 - val_loss: 0.6125 - val_accuracy: 0.6313\n",
            "Epoch 52/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6342 - accuracy: 0.5978 - val_loss: 0.6127 - val_accuracy: 0.6425\n",
            "Epoch 53/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6356 - accuracy: 0.6042 - val_loss: 0.6656 - val_accuracy: 0.6363\n",
            "Epoch 54/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6360 - accuracy: 0.6000 - val_loss: 0.6196 - val_accuracy: 0.6400\n",
            "Epoch 55/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6370 - accuracy: 0.6019 - val_loss: 0.6218 - val_accuracy: 0.6350\n",
            "Epoch 56/250\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6404 - accuracy: 0.5976 - val_loss: 0.6035 - val_accuracy: 0.6125\n",
            "Epoch 57/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6358 - accuracy: 0.5999 - val_loss: 0.6045 - val_accuracy: 0.6125\n",
            "Epoch 58/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6370 - accuracy: 0.6006 - val_loss: 0.6119 - val_accuracy: 0.6313\n",
            "Epoch 59/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6347 - accuracy: 0.6053 - val_loss: 0.6234 - val_accuracy: 0.6350\n",
            "Epoch 60/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6380 - accuracy: 0.6035 - val_loss: 0.6135 - val_accuracy: 0.6388\n",
            "Epoch 61/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6357 - accuracy: 0.6039 - val_loss: 0.6465 - val_accuracy: 0.6237\n",
            "Epoch 62/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6356 - accuracy: 0.6028 - val_loss: 0.6365 - val_accuracy: 0.6212\n",
            "Epoch 63/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6364 - accuracy: 0.6029 - val_loss: 0.6051 - val_accuracy: 0.6075\n",
            "Epoch 64/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6377 - accuracy: 0.6022 - val_loss: 0.6141 - val_accuracy: 0.6400\n",
            "Epoch 65/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6379 - accuracy: 0.6011 - val_loss: 0.6347 - val_accuracy: 0.6250\n",
            "Epoch 66/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6359 - accuracy: 0.6031 - val_loss: 0.6188 - val_accuracy: 0.6350\n",
            "Epoch 67/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6361 - accuracy: 0.5953 - val_loss: 0.6102 - val_accuracy: 0.6400\n",
            "Epoch 68/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6375 - accuracy: 0.6006 - val_loss: 0.6259 - val_accuracy: 0.6313\n",
            "Epoch 69/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6371 - accuracy: 0.6004 - val_loss: 0.6171 - val_accuracy: 0.6375\n",
            "Epoch 70/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6353 - accuracy: 0.5962 - val_loss: 0.6297 - val_accuracy: 0.6375\n",
            "Epoch 71/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6336 - accuracy: 0.6024 - val_loss: 0.6254 - val_accuracy: 0.6338\n",
            "Epoch 72/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6367 - accuracy: 0.6037 - val_loss: 0.6247 - val_accuracy: 0.6300\n",
            "Epoch 73/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6407 - accuracy: 0.5997 - val_loss: 0.6404 - val_accuracy: 0.6012\n",
            "Epoch 74/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6349 - accuracy: 0.6054 - val_loss: 0.6314 - val_accuracy: 0.6212\n",
            "Epoch 75/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6379 - accuracy: 0.6036 - val_loss: 0.6241 - val_accuracy: 0.6338\n",
            "Epoch 76/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6344 - accuracy: 0.5976 - val_loss: 0.6103 - val_accuracy: 0.6513\n",
            "Epoch 77/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6342 - accuracy: 0.6037 - val_loss: 0.6074 - val_accuracy: 0.6125\n",
            "Epoch 78/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6353 - accuracy: 0.6064 - val_loss: 0.6166 - val_accuracy: 0.6350\n",
            "Epoch 79/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6379 - accuracy: 0.5989 - val_loss: 0.6135 - val_accuracy: 0.6388\n",
            "Epoch 80/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6364 - accuracy: 0.5982 - val_loss: 0.6091 - val_accuracy: 0.6212\n",
            "Epoch 81/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6391 - accuracy: 0.5969 - val_loss: 0.6114 - val_accuracy: 0.6388\n",
            "Epoch 82/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6357 - accuracy: 0.6033 - val_loss: 0.6059 - val_accuracy: 0.6037\n",
            "Epoch 83/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6347 - accuracy: 0.6040 - val_loss: 0.6318 - val_accuracy: 0.6425\n",
            "Epoch 84/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6350 - accuracy: 0.6021 - val_loss: 0.6046 - val_accuracy: 0.6137\n",
            "Epoch 85/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6385 - accuracy: 0.5986 - val_loss: 0.6191 - val_accuracy: 0.6400\n",
            "Epoch 86/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6347 - accuracy: 0.6026 - val_loss: 0.6209 - val_accuracy: 0.6338\n",
            "Epoch 87/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6370 - accuracy: 0.6039 - val_loss: 0.6094 - val_accuracy: 0.6475\n",
            "Epoch 88/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6362 - accuracy: 0.6007 - val_loss: 0.6158 - val_accuracy: 0.6363\n",
            "Epoch 89/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6346 - accuracy: 0.6101 - val_loss: 0.6054 - val_accuracy: 0.6000\n",
            "Epoch 90/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6348 - accuracy: 0.6060 - val_loss: 0.6146 - val_accuracy: 0.6363\n",
            "Epoch 91/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6346 - accuracy: 0.6042 - val_loss: 0.6136 - val_accuracy: 0.6413\n",
            "Epoch 92/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6364 - accuracy: 0.5994 - val_loss: 0.6067 - val_accuracy: 0.6050\n",
            "Epoch 93/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6367 - accuracy: 0.6036 - val_loss: 0.6224 - val_accuracy: 0.6338\n",
            "Epoch 94/250\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6339 - accuracy: 0.6049 - val_loss: 0.6076 - val_accuracy: 0.6175\n",
            "Epoch 95/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6370 - accuracy: 0.6010 - val_loss: 0.6195 - val_accuracy: 0.6363\n",
            "Epoch 96/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6338 - accuracy: 0.6017 - val_loss: 0.6078 - val_accuracy: 0.6263\n",
            "Epoch 97/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6369 - accuracy: 0.5972 - val_loss: 0.6109 - val_accuracy: 0.6463\n",
            "Epoch 98/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6388 - accuracy: 0.6003 - val_loss: 0.6195 - val_accuracy: 0.6375\n",
            "Epoch 99/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6341 - accuracy: 0.6076 - val_loss: 0.6059 - val_accuracy: 0.6125\n",
            "Epoch 100/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6360 - accuracy: 0.6043 - val_loss: 0.6074 - val_accuracy: 0.6112\n",
            "Epoch 101/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6346 - accuracy: 0.6047 - val_loss: 0.6216 - val_accuracy: 0.6363\n",
            "Epoch 102/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6381 - accuracy: 0.5971 - val_loss: 0.6228 - val_accuracy: 0.6300\n",
            "Epoch 103/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6351 - accuracy: 0.6015 - val_loss: 0.6048 - val_accuracy: 0.6050\n",
            "Epoch 104/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6344 - accuracy: 0.6042 - val_loss: 0.6102 - val_accuracy: 0.6350\n",
            "Epoch 105/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6350 - accuracy: 0.6051 - val_loss: 0.6263 - val_accuracy: 0.6313\n",
            "Epoch 106/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6355 - accuracy: 0.6006 - val_loss: 0.6243 - val_accuracy: 0.6288\n",
            "Epoch 107/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6332 - accuracy: 0.6061 - val_loss: 0.6099 - val_accuracy: 0.6388\n",
            "Epoch 108/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6384 - accuracy: 0.6040 - val_loss: 0.6027 - val_accuracy: 0.6075\n",
            "Epoch 109/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6374 - accuracy: 0.6008 - val_loss: 0.6130 - val_accuracy: 0.6438\n",
            "Epoch 110/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6354 - accuracy: 0.6039 - val_loss: 0.6156 - val_accuracy: 0.6363\n",
            "Epoch 111/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6347 - accuracy: 0.6026 - val_loss: 0.6171 - val_accuracy: 0.6338\n",
            "Epoch 112/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6337 - accuracy: 0.6025 - val_loss: 0.6065 - val_accuracy: 0.6037\n",
            "Epoch 113/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6344 - accuracy: 0.6072 - val_loss: 0.6164 - val_accuracy: 0.6375\n",
            "Epoch 114/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6364 - accuracy: 0.6024 - val_loss: 0.6201 - val_accuracy: 0.6350\n",
            "Epoch 115/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6349 - accuracy: 0.6065 - val_loss: 0.6129 - val_accuracy: 0.6388\n",
            "Epoch 116/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6345 - accuracy: 0.5982 - val_loss: 0.6300 - val_accuracy: 0.6263\n",
            "Epoch 117/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6349 - accuracy: 0.6051 - val_loss: 0.6160 - val_accuracy: 0.6425\n",
            "Epoch 118/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6362 - accuracy: 0.6004 - val_loss: 0.6081 - val_accuracy: 0.6413\n",
            "Epoch 119/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6342 - accuracy: 0.6068 - val_loss: 0.6169 - val_accuracy: 0.6413\n",
            "Epoch 120/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6332 - accuracy: 0.6032 - val_loss: 0.6397 - val_accuracy: 0.6125\n",
            "Epoch 121/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6349 - accuracy: 0.6054 - val_loss: 0.6311 - val_accuracy: 0.6175\n",
            "Epoch 122/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6381 - accuracy: 0.5990 - val_loss: 0.6467 - val_accuracy: 0.6137\n",
            "Epoch 123/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6337 - accuracy: 0.6094 - val_loss: 0.6077 - val_accuracy: 0.6500\n",
            "Epoch 124/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6330 - accuracy: 0.6076 - val_loss: 0.6103 - val_accuracy: 0.6375\n",
            "Epoch 125/250\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6335 - accuracy: 0.6094 - val_loss: 0.6241 - val_accuracy: 0.6313\n",
            "Epoch 126/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6331 - accuracy: 0.6086 - val_loss: 0.6148 - val_accuracy: 0.6375\n",
            "Epoch 127/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6330 - accuracy: 0.6074 - val_loss: 0.6112 - val_accuracy: 0.6363\n",
            "Epoch 128/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6342 - accuracy: 0.6100 - val_loss: 0.6074 - val_accuracy: 0.6363\n",
            "Epoch 129/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6309 - accuracy: 0.6047 - val_loss: 0.6298 - val_accuracy: 0.6212\n",
            "Epoch 130/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6344 - accuracy: 0.6022 - val_loss: 0.6026 - val_accuracy: 0.6100\n",
            "Epoch 131/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6338 - accuracy: 0.6083 - val_loss: 0.6384 - val_accuracy: 0.6012\n",
            "Epoch 132/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6345 - accuracy: 0.6067 - val_loss: 0.6045 - val_accuracy: 0.6025\n",
            "Epoch 133/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6349 - accuracy: 0.6053 - val_loss: 0.6669 - val_accuracy: 0.6050\n",
            "Epoch 134/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6357 - accuracy: 0.6094 - val_loss: 0.6191 - val_accuracy: 0.6388\n",
            "Epoch 135/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6347 - accuracy: 0.6104 - val_loss: 0.6117 - val_accuracy: 0.6388\n",
            "Epoch 136/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6337 - accuracy: 0.6046 - val_loss: 0.6120 - val_accuracy: 0.6338\n",
            "Epoch 137/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6342 - accuracy: 0.6032 - val_loss: 0.6050 - val_accuracy: 0.6025\n",
            "Epoch 138/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6320 - accuracy: 0.6068 - val_loss: 0.6262 - val_accuracy: 0.6375\n",
            "Epoch 139/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6318 - accuracy: 0.6037 - val_loss: 0.6535 - val_accuracy: 0.6112\n",
            "Epoch 140/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6318 - accuracy: 0.6083 - val_loss: 0.6117 - val_accuracy: 0.6375\n",
            "Epoch 141/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6331 - accuracy: 0.6047 - val_loss: 0.6140 - val_accuracy: 0.6438\n",
            "Epoch 142/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6317 - accuracy: 0.6062 - val_loss: 0.6176 - val_accuracy: 0.6375\n",
            "Epoch 143/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6352 - accuracy: 0.5994 - val_loss: 0.6084 - val_accuracy: 0.6463\n",
            "Epoch 144/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6338 - accuracy: 0.6064 - val_loss: 0.6040 - val_accuracy: 0.6012\n",
            "Epoch 145/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6347 - accuracy: 0.6115 - val_loss: 0.6013 - val_accuracy: 0.6175\n",
            "Epoch 146/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6375 - accuracy: 0.6039 - val_loss: 0.6050 - val_accuracy: 0.6137\n",
            "Epoch 147/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6326 - accuracy: 0.6106 - val_loss: 0.6070 - val_accuracy: 0.6263\n",
            "Epoch 148/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6323 - accuracy: 0.6072 - val_loss: 0.6060 - val_accuracy: 0.6300\n",
            "Epoch 149/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6343 - accuracy: 0.6037 - val_loss: 0.6128 - val_accuracy: 0.6375\n",
            "Epoch 150/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6351 - accuracy: 0.6014 - val_loss: 0.6035 - val_accuracy: 0.6075\n",
            "Epoch 151/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6350 - accuracy: 0.6068 - val_loss: 0.6545 - val_accuracy: 0.6200\n",
            "Epoch 152/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6339 - accuracy: 0.6068 - val_loss: 0.6107 - val_accuracy: 0.6425\n",
            "Epoch 153/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6352 - accuracy: 0.6035 - val_loss: 0.6040 - val_accuracy: 0.6075\n",
            "Epoch 154/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6330 - accuracy: 0.6060 - val_loss: 0.6129 - val_accuracy: 0.6425\n",
            "Epoch 155/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6345 - accuracy: 0.6062 - val_loss: 0.6146 - val_accuracy: 0.6375\n",
            "Epoch 156/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6325 - accuracy: 0.6058 - val_loss: 0.6077 - val_accuracy: 0.6463\n",
            "Epoch 157/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6308 - accuracy: 0.6094 - val_loss: 0.6090 - val_accuracy: 0.6463\n",
            "Epoch 158/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6351 - accuracy: 0.6082 - val_loss: 0.6031 - val_accuracy: 0.6200\n",
            "Epoch 159/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6325 - accuracy: 0.6040 - val_loss: 0.6407 - val_accuracy: 0.6125\n",
            "Epoch 160/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6337 - accuracy: 0.6019 - val_loss: 0.6138 - val_accuracy: 0.6375\n",
            "Epoch 161/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6327 - accuracy: 0.6081 - val_loss: 0.6088 - val_accuracy: 0.6413\n",
            "Epoch 162/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6327 - accuracy: 0.6054 - val_loss: 0.6031 - val_accuracy: 0.6037\n",
            "Epoch 163/250\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6365 - accuracy: 0.6065 - val_loss: 0.6154 - val_accuracy: 0.6363\n",
            "Epoch 164/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6319 - accuracy: 0.6099 - val_loss: 0.6094 - val_accuracy: 0.6438\n",
            "Epoch 165/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6316 - accuracy: 0.6062 - val_loss: 0.6119 - val_accuracy: 0.6363\n",
            "Epoch 166/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6337 - accuracy: 0.6036 - val_loss: 0.6264 - val_accuracy: 0.6225\n",
            "Epoch 167/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6342 - accuracy: 0.6058 - val_loss: 0.6049 - val_accuracy: 0.6150\n",
            "Epoch 168/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6324 - accuracy: 0.6047 - val_loss: 0.6057 - val_accuracy: 0.6012\n",
            "Epoch 169/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6341 - accuracy: 0.6096 - val_loss: 0.6145 - val_accuracy: 0.6300\n",
            "Epoch 170/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6327 - accuracy: 0.6075 - val_loss: 0.6059 - val_accuracy: 0.6587\n",
            "Epoch 171/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6343 - accuracy: 0.6114 - val_loss: 0.6183 - val_accuracy: 0.6350\n",
            "Epoch 172/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6315 - accuracy: 0.6090 - val_loss: 0.6268 - val_accuracy: 0.6338\n",
            "Epoch 173/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6321 - accuracy: 0.6151 - val_loss: 0.6016 - val_accuracy: 0.6100\n",
            "Epoch 174/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6327 - accuracy: 0.6086 - val_loss: 0.6076 - val_accuracy: 0.6463\n",
            "Epoch 175/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6332 - accuracy: 0.6107 - val_loss: 0.6045 - val_accuracy: 0.6212\n",
            "Epoch 176/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6304 - accuracy: 0.6110 - val_loss: 0.6225 - val_accuracy: 0.6250\n",
            "Epoch 177/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6352 - accuracy: 0.6086 - val_loss: 0.6146 - val_accuracy: 0.6388\n",
            "Epoch 178/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6320 - accuracy: 0.6125 - val_loss: 0.6103 - val_accuracy: 0.6438\n",
            "Epoch 179/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6358 - accuracy: 0.6025 - val_loss: 0.6058 - val_accuracy: 0.6538\n",
            "Epoch 180/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6321 - accuracy: 0.6043 - val_loss: 0.6104 - val_accuracy: 0.6425\n",
            "Epoch 181/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6328 - accuracy: 0.6085 - val_loss: 0.6089 - val_accuracy: 0.6413\n",
            "Epoch 182/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6327 - accuracy: 0.6040 - val_loss: 0.6139 - val_accuracy: 0.6363\n",
            "Epoch 183/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6313 - accuracy: 0.6086 - val_loss: 0.6205 - val_accuracy: 0.6350\n",
            "Epoch 184/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6316 - accuracy: 0.6107 - val_loss: 0.6013 - val_accuracy: 0.6125\n",
            "Epoch 185/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6327 - accuracy: 0.6111 - val_loss: 0.6060 - val_accuracy: 0.6525\n",
            "Epoch 186/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6308 - accuracy: 0.6082 - val_loss: 0.6129 - val_accuracy: 0.6375\n",
            "Epoch 187/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6315 - accuracy: 0.6094 - val_loss: 0.6157 - val_accuracy: 0.6413\n",
            "Epoch 188/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6353 - accuracy: 0.6060 - val_loss: 0.6172 - val_accuracy: 0.6375\n",
            "Epoch 189/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6359 - accuracy: 0.6024 - val_loss: 0.5996 - val_accuracy: 0.6162\n",
            "Epoch 190/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6317 - accuracy: 0.6036 - val_loss: 0.6228 - val_accuracy: 0.6350\n",
            "Epoch 191/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6319 - accuracy: 0.6069 - val_loss: 0.6205 - val_accuracy: 0.6375\n",
            "Epoch 192/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6346 - accuracy: 0.6089 - val_loss: 0.6079 - val_accuracy: 0.6425\n",
            "Epoch 193/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6362 - accuracy: 0.6099 - val_loss: 0.6183 - val_accuracy: 0.6350\n",
            "Epoch 194/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6320 - accuracy: 0.6161 - val_loss: 0.6255 - val_accuracy: 0.6200\n",
            "Epoch 195/250\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6326 - accuracy: 0.6096 - val_loss: 0.6105 - val_accuracy: 0.6425\n",
            "Epoch 196/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6349 - accuracy: 0.6075 - val_loss: 0.6028 - val_accuracy: 0.6313\n",
            "Epoch 197/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6317 - accuracy: 0.6079 - val_loss: 0.6106 - val_accuracy: 0.6438\n",
            "Epoch 198/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6328 - accuracy: 0.6044 - val_loss: 0.6279 - val_accuracy: 0.6162\n",
            "Epoch 199/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6314 - accuracy: 0.6093 - val_loss: 0.6140 - val_accuracy: 0.6363\n",
            "Epoch 200/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6336 - accuracy: 0.6076 - val_loss: 0.6149 - val_accuracy: 0.6388\n",
            "Epoch 201/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6338 - accuracy: 0.6104 - val_loss: 0.6258 - val_accuracy: 0.6200\n",
            "Epoch 202/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6308 - accuracy: 0.6078 - val_loss: 0.6020 - val_accuracy: 0.6112\n",
            "Epoch 203/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6305 - accuracy: 0.6092 - val_loss: 0.6065 - val_accuracy: 0.6463\n",
            "Epoch 204/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6312 - accuracy: 0.6086 - val_loss: 0.6036 - val_accuracy: 0.6388\n",
            "Epoch 205/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6320 - accuracy: 0.6119 - val_loss: 0.6345 - val_accuracy: 0.6200\n",
            "Epoch 206/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6330 - accuracy: 0.6053 - val_loss: 0.6100 - val_accuracy: 0.6413\n",
            "Epoch 207/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6290 - accuracy: 0.6119 - val_loss: 0.6185 - val_accuracy: 0.6350\n",
            "Epoch 208/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6335 - accuracy: 0.6089 - val_loss: 0.6136 - val_accuracy: 0.6338\n",
            "Epoch 209/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6346 - accuracy: 0.6108 - val_loss: 0.6173 - val_accuracy: 0.6363\n",
            "Epoch 210/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6305 - accuracy: 0.6110 - val_loss: 0.6212 - val_accuracy: 0.6275\n",
            "Epoch 211/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6308 - accuracy: 0.6082 - val_loss: 0.6106 - val_accuracy: 0.6450\n",
            "Epoch 212/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6343 - accuracy: 0.6078 - val_loss: 0.6127 - val_accuracy: 0.6400\n",
            "Epoch 213/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6310 - accuracy: 0.6118 - val_loss: 0.6117 - val_accuracy: 0.6438\n",
            "Epoch 214/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6346 - accuracy: 0.6139 - val_loss: 0.6107 - val_accuracy: 0.6413\n",
            "Epoch 215/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6334 - accuracy: 0.6061 - val_loss: 0.6010 - val_accuracy: 0.6037\n",
            "Epoch 216/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6313 - accuracy: 0.6094 - val_loss: 0.6138 - val_accuracy: 0.6363\n",
            "Epoch 217/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6321 - accuracy: 0.6124 - val_loss: 0.6147 - val_accuracy: 0.6400\n",
            "Epoch 218/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6314 - accuracy: 0.6100 - val_loss: 0.6331 - val_accuracy: 0.6250\n",
            "Epoch 219/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6312 - accuracy: 0.6128 - val_loss: 0.6009 - val_accuracy: 0.6313\n",
            "Epoch 220/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6337 - accuracy: 0.6068 - val_loss: 0.6217 - val_accuracy: 0.6313\n",
            "Epoch 221/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6319 - accuracy: 0.6106 - val_loss: 0.6024 - val_accuracy: 0.6450\n",
            "Epoch 222/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6324 - accuracy: 0.6074 - val_loss: 0.6359 - val_accuracy: 0.6200\n",
            "Epoch 223/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6313 - accuracy: 0.6083 - val_loss: 0.6063 - val_accuracy: 0.6525\n",
            "Epoch 224/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6314 - accuracy: 0.6099 - val_loss: 0.6167 - val_accuracy: 0.6325\n",
            "Epoch 225/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6316 - accuracy: 0.6079 - val_loss: 0.5990 - val_accuracy: 0.6187\n",
            "Epoch 226/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6321 - accuracy: 0.6104 - val_loss: 0.6081 - val_accuracy: 0.6450\n",
            "Epoch 227/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6305 - accuracy: 0.6124 - val_loss: 0.6078 - val_accuracy: 0.6400\n",
            "Epoch 228/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6297 - accuracy: 0.6119 - val_loss: 0.6123 - val_accuracy: 0.6413\n",
            "Epoch 229/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6316 - accuracy: 0.6175 - val_loss: 0.6350 - val_accuracy: 0.6125\n",
            "Epoch 230/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6288 - accuracy: 0.6199 - val_loss: 0.6090 - val_accuracy: 0.6475\n",
            "Epoch 231/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6313 - accuracy: 0.6111 - val_loss: 0.6057 - val_accuracy: 0.6513\n",
            "Epoch 232/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6308 - accuracy: 0.6033 - val_loss: 0.5994 - val_accuracy: 0.6037\n",
            "Epoch 233/250\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6336 - accuracy: 0.6093 - val_loss: 0.6010 - val_accuracy: 0.6162\n",
            "Epoch 234/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6316 - accuracy: 0.6122 - val_loss: 0.6098 - val_accuracy: 0.6413\n",
            "Epoch 235/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6328 - accuracy: 0.6069 - val_loss: 0.6016 - val_accuracy: 0.6375\n",
            "Epoch 236/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6304 - accuracy: 0.6125 - val_loss: 0.6052 - val_accuracy: 0.6475\n",
            "Epoch 237/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6308 - accuracy: 0.6086 - val_loss: 0.6033 - val_accuracy: 0.6400\n",
            "Epoch 238/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6298 - accuracy: 0.6082 - val_loss: 0.6269 - val_accuracy: 0.6125\n",
            "Epoch 239/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6331 - accuracy: 0.6074 - val_loss: 0.6038 - val_accuracy: 0.6562\n",
            "Epoch 240/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6324 - accuracy: 0.6099 - val_loss: 0.6080 - val_accuracy: 0.6388\n",
            "Epoch 241/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6294 - accuracy: 0.6068 - val_loss: 0.6232 - val_accuracy: 0.6225\n",
            "Epoch 242/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6290 - accuracy: 0.6128 - val_loss: 0.6113 - val_accuracy: 0.6413\n",
            "Epoch 243/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6316 - accuracy: 0.6058 - val_loss: 0.5995 - val_accuracy: 0.6075\n",
            "Epoch 244/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6303 - accuracy: 0.6168 - val_loss: 0.5994 - val_accuracy: 0.6100\n",
            "Epoch 245/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6305 - accuracy: 0.6110 - val_loss: 0.6201 - val_accuracy: 0.6288\n",
            "Epoch 246/250\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6326 - accuracy: 0.6128 - val_loss: 0.6004 - val_accuracy: 0.6150\n",
            "Epoch 247/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6311 - accuracy: 0.6112 - val_loss: 0.6094 - val_accuracy: 0.6350\n",
            "Epoch 248/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6297 - accuracy: 0.6178 - val_loss: 0.6018 - val_accuracy: 0.6475\n",
            "Epoch 249/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6310 - accuracy: 0.6144 - val_loss: 0.6167 - val_accuracy: 0.6338\n",
            "Epoch 250/250\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6298 - accuracy: 0.6062 - val_loss: 0.6284 - val_accuracy: 0.6162\n",
            "Epoch 1/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6306 - accuracy: 0.6093 - val_loss: 0.6169 - val_accuracy: 0.6313\n",
            "Epoch 2/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6316 - accuracy: 0.6125 - val_loss: 0.6099 - val_accuracy: 0.6450\n",
            "Epoch 3/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6370 - accuracy: 0.6124 - val_loss: 0.6300 - val_accuracy: 0.6075\n",
            "Epoch 4/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6316 - accuracy: 0.6154 - val_loss: 0.6141 - val_accuracy: 0.6375\n",
            "Epoch 5/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6302 - accuracy: 0.6094 - val_loss: 0.6148 - val_accuracy: 0.6375\n",
            "Epoch 6/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6335 - accuracy: 0.6067 - val_loss: 0.6108 - val_accuracy: 0.6375\n",
            "Epoch 7/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6287 - accuracy: 0.6133 - val_loss: 0.6356 - val_accuracy: 0.6087\n",
            "Epoch 8/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6304 - accuracy: 0.6115 - val_loss: 0.6212 - val_accuracy: 0.6263\n",
            "Epoch 9/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6284 - accuracy: 0.6143 - val_loss: 0.6257 - val_accuracy: 0.6338\n",
            "Epoch 10/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6286 - accuracy: 0.6143 - val_loss: 0.6124 - val_accuracy: 0.6375\n",
            "Epoch 11/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6311 - accuracy: 0.6119 - val_loss: 0.6129 - val_accuracy: 0.6338\n",
            "Epoch 12/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6290 - accuracy: 0.6126 - val_loss: 0.6028 - val_accuracy: 0.6612\n",
            "Epoch 13/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6296 - accuracy: 0.6099 - val_loss: 0.6345 - val_accuracy: 0.6237\n",
            "Epoch 14/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6308 - accuracy: 0.6178 - val_loss: 0.6258 - val_accuracy: 0.6137\n",
            "Epoch 15/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6310 - accuracy: 0.6126 - val_loss: 0.6078 - val_accuracy: 0.6488\n",
            "Epoch 16/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6298 - accuracy: 0.6090 - val_loss: 0.6094 - val_accuracy: 0.6463\n",
            "Epoch 17/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6322 - accuracy: 0.6089 - val_loss: 0.6103 - val_accuracy: 0.6400\n",
            "Epoch 18/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6289 - accuracy: 0.6228 - val_loss: 0.5982 - val_accuracy: 0.6050\n",
            "Epoch 19/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6284 - accuracy: 0.6100 - val_loss: 0.5978 - val_accuracy: 0.6125\n",
            "Epoch 20/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6288 - accuracy: 0.6108 - val_loss: 0.5969 - val_accuracy: 0.6062\n",
            "Epoch 21/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6286 - accuracy: 0.6106 - val_loss: 0.6159 - val_accuracy: 0.6350\n",
            "Epoch 22/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6308 - accuracy: 0.6144 - val_loss: 0.6052 - val_accuracy: 0.6538\n",
            "Epoch 23/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6346 - accuracy: 0.6082 - val_loss: 0.6135 - val_accuracy: 0.6375\n",
            "Epoch 24/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6308 - accuracy: 0.6119 - val_loss: 0.6023 - val_accuracy: 0.6625\n",
            "Epoch 25/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6335 - accuracy: 0.6144 - val_loss: 0.6047 - val_accuracy: 0.6100\n",
            "Epoch 26/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6304 - accuracy: 0.6103 - val_loss: 0.6017 - val_accuracy: 0.6200\n",
            "Epoch 27/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6315 - accuracy: 0.6096 - val_loss: 0.6128 - val_accuracy: 0.6413\n",
            "Epoch 28/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6296 - accuracy: 0.6143 - val_loss: 0.5968 - val_accuracy: 0.6025\n",
            "Epoch 29/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6305 - accuracy: 0.6107 - val_loss: 0.6063 - val_accuracy: 0.6450\n",
            "Epoch 30/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6280 - accuracy: 0.6187 - val_loss: 0.6082 - val_accuracy: 0.6375\n",
            "Epoch 31/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6285 - accuracy: 0.6072 - val_loss: 0.6290 - val_accuracy: 0.6162\n",
            "Epoch 32/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6308 - accuracy: 0.6182 - val_loss: 0.6352 - val_accuracy: 0.6112\n",
            "Epoch 33/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6293 - accuracy: 0.6176 - val_loss: 0.6292 - val_accuracy: 0.6237\n",
            "Epoch 34/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6300 - accuracy: 0.6115 - val_loss: 0.6234 - val_accuracy: 0.6300\n",
            "Epoch 35/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6312 - accuracy: 0.6136 - val_loss: 0.6027 - val_accuracy: 0.6500\n",
            "Epoch 36/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6277 - accuracy: 0.6126 - val_loss: 0.6192 - val_accuracy: 0.6300\n",
            "Epoch 37/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6293 - accuracy: 0.6149 - val_loss: 0.5986 - val_accuracy: 0.6037\n",
            "Epoch 38/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6281 - accuracy: 0.6196 - val_loss: 0.6234 - val_accuracy: 0.6425\n",
            "Epoch 39/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6273 - accuracy: 0.6128 - val_loss: 0.5961 - val_accuracy: 0.6050\n",
            "Epoch 40/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6301 - accuracy: 0.6129 - val_loss: 0.6042 - val_accuracy: 0.6550\n",
            "Epoch 41/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6301 - accuracy: 0.6157 - val_loss: 0.5979 - val_accuracy: 0.6125\n",
            "Epoch 42/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6285 - accuracy: 0.6131 - val_loss: 0.5980 - val_accuracy: 0.6313\n",
            "Epoch 43/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6305 - accuracy: 0.6119 - val_loss: 0.5958 - val_accuracy: 0.6037\n",
            "Epoch 44/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6298 - accuracy: 0.6090 - val_loss: 0.6051 - val_accuracy: 0.6438\n",
            "Epoch 45/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6291 - accuracy: 0.6164 - val_loss: 0.5961 - val_accuracy: 0.6037\n",
            "Epoch 46/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6287 - accuracy: 0.6136 - val_loss: 0.6067 - val_accuracy: 0.6463\n",
            "Epoch 47/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6294 - accuracy: 0.6118 - val_loss: 0.6267 - val_accuracy: 0.6250\n",
            "Epoch 48/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6268 - accuracy: 0.6162 - val_loss: 0.6217 - val_accuracy: 0.6225\n",
            "Epoch 49/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6287 - accuracy: 0.6139 - val_loss: 0.6143 - val_accuracy: 0.6313\n",
            "Epoch 50/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6319 - accuracy: 0.6160 - val_loss: 0.6084 - val_accuracy: 0.6425\n",
            "Epoch 51/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6293 - accuracy: 0.6097 - val_loss: 0.5982 - val_accuracy: 0.6662\n",
            "Epoch 52/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6284 - accuracy: 0.6147 - val_loss: 0.6021 - val_accuracy: 0.6538\n",
            "Epoch 53/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6281 - accuracy: 0.6194 - val_loss: 0.6298 - val_accuracy: 0.6162\n",
            "Epoch 54/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6307 - accuracy: 0.6062 - val_loss: 0.6064 - val_accuracy: 0.6488\n",
            "Epoch 55/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6321 - accuracy: 0.6090 - val_loss: 0.6013 - val_accuracy: 0.6538\n",
            "Epoch 56/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6274 - accuracy: 0.6172 - val_loss: 0.6027 - val_accuracy: 0.6575\n",
            "Epoch 57/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6272 - accuracy: 0.6150 - val_loss: 0.6091 - val_accuracy: 0.6463\n",
            "Epoch 58/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6294 - accuracy: 0.6144 - val_loss: 0.6140 - val_accuracy: 0.6350\n",
            "Epoch 59/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6286 - accuracy: 0.6144 - val_loss: 0.6117 - val_accuracy: 0.6375\n",
            "Epoch 60/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6301 - accuracy: 0.6106 - val_loss: 0.5999 - val_accuracy: 0.6525\n",
            "Epoch 61/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6292 - accuracy: 0.6122 - val_loss: 0.6257 - val_accuracy: 0.6137\n",
            "Epoch 62/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6282 - accuracy: 0.6162 - val_loss: 0.6067 - val_accuracy: 0.6450\n",
            "Epoch 63/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6279 - accuracy: 0.6168 - val_loss: 0.6204 - val_accuracy: 0.6325\n",
            "Epoch 64/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6292 - accuracy: 0.6146 - val_loss: 0.5977 - val_accuracy: 0.6150\n",
            "Epoch 65/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6264 - accuracy: 0.6158 - val_loss: 0.6597 - val_accuracy: 0.6125\n",
            "Epoch 66/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6321 - accuracy: 0.6100 - val_loss: 0.5987 - val_accuracy: 0.6625\n",
            "Epoch 67/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6323 - accuracy: 0.6074 - val_loss: 0.5986 - val_accuracy: 0.6475\n",
            "Epoch 68/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6270 - accuracy: 0.6165 - val_loss: 0.6044 - val_accuracy: 0.6500\n",
            "Epoch 69/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6274 - accuracy: 0.6086 - val_loss: 0.5971 - val_accuracy: 0.6288\n",
            "Epoch 70/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6284 - accuracy: 0.6175 - val_loss: 0.6043 - val_accuracy: 0.6488\n",
            "Epoch 71/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6299 - accuracy: 0.6117 - val_loss: 0.5974 - val_accuracy: 0.6612\n",
            "Epoch 72/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6270 - accuracy: 0.6181 - val_loss: 0.6129 - val_accuracy: 0.6363\n",
            "Epoch 73/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6277 - accuracy: 0.6129 - val_loss: 0.6165 - val_accuracy: 0.6325\n",
            "Epoch 74/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6290 - accuracy: 0.6087 - val_loss: 0.5995 - val_accuracy: 0.6650\n",
            "Epoch 75/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6299 - accuracy: 0.6150 - val_loss: 0.6172 - val_accuracy: 0.6338\n",
            "Epoch 76/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6292 - accuracy: 0.6117 - val_loss: 0.6164 - val_accuracy: 0.6350\n",
            "Epoch 77/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6288 - accuracy: 0.6124 - val_loss: 0.6340 - val_accuracy: 0.6250\n",
            "Epoch 78/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6282 - accuracy: 0.6117 - val_loss: 0.5987 - val_accuracy: 0.6463\n",
            "Epoch 79/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6284 - accuracy: 0.6151 - val_loss: 0.6113 - val_accuracy: 0.6338\n",
            "Epoch 80/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6278 - accuracy: 0.6168 - val_loss: 0.6132 - val_accuracy: 0.6350\n",
            "Epoch 81/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6279 - accuracy: 0.6143 - val_loss: 0.6116 - val_accuracy: 0.6338\n",
            "Epoch 82/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6266 - accuracy: 0.6206 - val_loss: 0.6296 - val_accuracy: 0.6237\n",
            "Epoch 83/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6293 - accuracy: 0.6135 - val_loss: 0.5987 - val_accuracy: 0.6612\n",
            "Epoch 84/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6292 - accuracy: 0.6154 - val_loss: 0.5962 - val_accuracy: 0.6162\n",
            "Epoch 85/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6287 - accuracy: 0.6144 - val_loss: 0.6093 - val_accuracy: 0.6338\n",
            "Epoch 86/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6273 - accuracy: 0.6207 - val_loss: 0.6052 - val_accuracy: 0.6450\n",
            "Epoch 87/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6276 - accuracy: 0.6157 - val_loss: 0.6079 - val_accuracy: 0.6425\n",
            "Epoch 88/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6293 - accuracy: 0.6147 - val_loss: 0.6019 - val_accuracy: 0.6575\n",
            "Epoch 89/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6283 - accuracy: 0.6151 - val_loss: 0.6291 - val_accuracy: 0.6237\n",
            "Epoch 90/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6319 - accuracy: 0.6149 - val_loss: 0.6160 - val_accuracy: 0.6300\n",
            "Epoch 91/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6283 - accuracy: 0.6167 - val_loss: 0.5969 - val_accuracy: 0.6162\n",
            "Epoch 92/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6274 - accuracy: 0.6169 - val_loss: 0.6189 - val_accuracy: 0.6375\n",
            "Epoch 93/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6282 - accuracy: 0.6204 - val_loss: 0.6024 - val_accuracy: 0.6538\n",
            "Epoch 94/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6284 - accuracy: 0.6126 - val_loss: 0.5994 - val_accuracy: 0.6575\n",
            "Epoch 95/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6275 - accuracy: 0.6167 - val_loss: 0.6108 - val_accuracy: 0.6338\n",
            "Epoch 96/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6287 - accuracy: 0.6114 - val_loss: 0.6251 - val_accuracy: 0.6338\n",
            "Epoch 97/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6281 - accuracy: 0.6108 - val_loss: 0.6232 - val_accuracy: 0.6275\n",
            "Epoch 98/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6274 - accuracy: 0.6118 - val_loss: 0.6018 - val_accuracy: 0.6525\n",
            "Epoch 99/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6273 - accuracy: 0.6146 - val_loss: 0.6021 - val_accuracy: 0.6525\n",
            "Epoch 100/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6297 - accuracy: 0.6167 - val_loss: 0.5974 - val_accuracy: 0.6525\n",
            "Epoch 101/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6280 - accuracy: 0.6149 - val_loss: 0.6134 - val_accuracy: 0.6325\n",
            "Epoch 102/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6280 - accuracy: 0.6169 - val_loss: 0.6164 - val_accuracy: 0.6275\n",
            "Epoch 103/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6265 - accuracy: 0.6189 - val_loss: 0.6041 - val_accuracy: 0.6425\n",
            "Epoch 104/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6271 - accuracy: 0.6179 - val_loss: 0.5962 - val_accuracy: 0.6612\n",
            "Epoch 105/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6248 - accuracy: 0.6151 - val_loss: 0.6177 - val_accuracy: 0.6212\n",
            "Epoch 106/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6244 - accuracy: 0.6179 - val_loss: 0.6054 - val_accuracy: 0.6463\n",
            "Epoch 107/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6301 - accuracy: 0.6181 - val_loss: 0.5953 - val_accuracy: 0.6562\n",
            "Epoch 108/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6285 - accuracy: 0.6157 - val_loss: 0.6061 - val_accuracy: 0.6463\n",
            "Epoch 109/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6268 - accuracy: 0.6160 - val_loss: 0.6322 - val_accuracy: 0.6250\n",
            "Epoch 110/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6273 - accuracy: 0.6164 - val_loss: 0.5958 - val_accuracy: 0.6087\n",
            "Epoch 111/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6284 - accuracy: 0.6161 - val_loss: 0.6143 - val_accuracy: 0.6300\n",
            "Epoch 112/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6260 - accuracy: 0.6161 - val_loss: 0.6093 - val_accuracy: 0.6350\n",
            "Epoch 113/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6277 - accuracy: 0.6182 - val_loss: 0.6159 - val_accuracy: 0.6250\n",
            "Epoch 114/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6253 - accuracy: 0.6147 - val_loss: 0.6465 - val_accuracy: 0.6263\n",
            "Epoch 115/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6271 - accuracy: 0.6117 - val_loss: 0.6358 - val_accuracy: 0.6087\n",
            "Epoch 116/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6288 - accuracy: 0.6149 - val_loss: 0.5942 - val_accuracy: 0.6175\n",
            "Epoch 117/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6279 - accuracy: 0.6128 - val_loss: 0.6018 - val_accuracy: 0.6550\n",
            "Epoch 118/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6287 - accuracy: 0.6162 - val_loss: 0.5946 - val_accuracy: 0.6350\n",
            "Epoch 119/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6270 - accuracy: 0.6161 - val_loss: 0.6010 - val_accuracy: 0.6525\n",
            "Epoch 120/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6270 - accuracy: 0.6162 - val_loss: 0.6089 - val_accuracy: 0.6400\n",
            "Epoch 121/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6280 - accuracy: 0.6165 - val_loss: 0.5999 - val_accuracy: 0.6587\n",
            "Epoch 122/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6266 - accuracy: 0.6232 - val_loss: 0.6278 - val_accuracy: 0.6263\n",
            "Epoch 123/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6288 - accuracy: 0.6146 - val_loss: 0.6027 - val_accuracy: 0.6450\n",
            "Epoch 124/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6256 - accuracy: 0.6194 - val_loss: 0.6143 - val_accuracy: 0.6300\n",
            "Epoch 125/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6271 - accuracy: 0.6186 - val_loss: 0.6028 - val_accuracy: 0.6425\n",
            "Epoch 126/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6261 - accuracy: 0.6181 - val_loss: 0.6000 - val_accuracy: 0.6513\n",
            "Epoch 127/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6260 - accuracy: 0.6210 - val_loss: 0.6081 - val_accuracy: 0.6413\n",
            "Epoch 128/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6252 - accuracy: 0.6150 - val_loss: 0.6012 - val_accuracy: 0.6575\n",
            "Epoch 129/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6276 - accuracy: 0.6128 - val_loss: 0.5981 - val_accuracy: 0.6575\n",
            "Epoch 130/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6267 - accuracy: 0.6181 - val_loss: 0.6252 - val_accuracy: 0.6200\n",
            "Epoch 131/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6288 - accuracy: 0.6164 - val_loss: 0.5959 - val_accuracy: 0.6137\n",
            "Epoch 132/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6267 - accuracy: 0.6164 - val_loss: 0.6272 - val_accuracy: 0.6225\n",
            "Epoch 133/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6280 - accuracy: 0.6136 - val_loss: 0.6161 - val_accuracy: 0.6288\n",
            "Epoch 134/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6257 - accuracy: 0.6197 - val_loss: 0.6038 - val_accuracy: 0.6538\n",
            "Epoch 135/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6260 - accuracy: 0.6200 - val_loss: 0.6039 - val_accuracy: 0.6538\n",
            "Epoch 136/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6285 - accuracy: 0.6194 - val_loss: 0.6279 - val_accuracy: 0.6162\n",
            "Epoch 137/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6278 - accuracy: 0.6179 - val_loss: 0.5983 - val_accuracy: 0.6650\n",
            "Epoch 138/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6255 - accuracy: 0.6165 - val_loss: 0.5945 - val_accuracy: 0.6037\n",
            "Epoch 139/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6263 - accuracy: 0.6168 - val_loss: 0.6310 - val_accuracy: 0.6212\n",
            "Epoch 140/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6254 - accuracy: 0.6206 - val_loss: 0.6186 - val_accuracy: 0.6250\n",
            "Epoch 141/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6286 - accuracy: 0.6140 - val_loss: 0.6032 - val_accuracy: 0.6538\n",
            "Epoch 142/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6251 - accuracy: 0.6201 - val_loss: 0.6043 - val_accuracy: 0.6500\n",
            "Epoch 143/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6257 - accuracy: 0.6181 - val_loss: 0.5948 - val_accuracy: 0.6687\n",
            "Epoch 144/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6266 - accuracy: 0.6181 - val_loss: 0.6088 - val_accuracy: 0.6363\n",
            "Epoch 145/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6253 - accuracy: 0.6193 - val_loss: 0.6007 - val_accuracy: 0.6538\n",
            "Epoch 146/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6266 - accuracy: 0.6132 - val_loss: 0.6131 - val_accuracy: 0.6363\n",
            "Epoch 147/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6257 - accuracy: 0.6207 - val_loss: 0.5967 - val_accuracy: 0.6675\n",
            "Epoch 148/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6267 - accuracy: 0.6178 - val_loss: 0.5930 - val_accuracy: 0.6237\n",
            "Epoch 149/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6275 - accuracy: 0.6150 - val_loss: 0.6324 - val_accuracy: 0.6150\n",
            "Epoch 150/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6270 - accuracy: 0.6162 - val_loss: 0.5966 - val_accuracy: 0.6700\n",
            "Epoch 151/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6269 - accuracy: 0.6197 - val_loss: 0.5960 - val_accuracy: 0.6612\n",
            "Epoch 152/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6262 - accuracy: 0.6186 - val_loss: 0.6083 - val_accuracy: 0.6338\n",
            "Epoch 153/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6258 - accuracy: 0.6133 - val_loss: 0.6458 - val_accuracy: 0.6225\n",
            "Epoch 154/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6245 - accuracy: 0.6206 - val_loss: 0.6026 - val_accuracy: 0.6575\n",
            "Epoch 155/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6245 - accuracy: 0.6212 - val_loss: 0.5982 - val_accuracy: 0.6513\n",
            "Epoch 156/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6243 - accuracy: 0.6206 - val_loss: 0.6114 - val_accuracy: 0.6463\n",
            "Epoch 157/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6264 - accuracy: 0.6151 - val_loss: 0.6187 - val_accuracy: 0.6263\n",
            "Epoch 158/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6257 - accuracy: 0.6150 - val_loss: 0.6030 - val_accuracy: 0.6450\n",
            "Epoch 159/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6239 - accuracy: 0.6215 - val_loss: 0.5990 - val_accuracy: 0.6612\n",
            "Epoch 160/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6275 - accuracy: 0.6204 - val_loss: 0.6115 - val_accuracy: 0.6325\n",
            "Epoch 161/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6265 - accuracy: 0.6185 - val_loss: 0.6250 - val_accuracy: 0.6250\n",
            "Epoch 162/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6246 - accuracy: 0.6211 - val_loss: 0.6292 - val_accuracy: 0.6263\n",
            "Epoch 163/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6250 - accuracy: 0.6249 - val_loss: 0.5910 - val_accuracy: 0.6137\n",
            "Epoch 164/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6257 - accuracy: 0.6160 - val_loss: 0.6033 - val_accuracy: 0.6525\n",
            "Epoch 165/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6249 - accuracy: 0.6135 - val_loss: 0.6195 - val_accuracy: 0.6137\n",
            "Epoch 166/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6267 - accuracy: 0.6190 - val_loss: 0.6029 - val_accuracy: 0.6500\n",
            "Epoch 167/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6268 - accuracy: 0.6142 - val_loss: 0.6006 - val_accuracy: 0.6550\n",
            "Epoch 168/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6240 - accuracy: 0.6210 - val_loss: 0.6174 - val_accuracy: 0.6150\n",
            "Epoch 169/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6243 - accuracy: 0.6210 - val_loss: 0.6008 - val_accuracy: 0.6513\n",
            "Epoch 170/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6269 - accuracy: 0.6169 - val_loss: 0.6147 - val_accuracy: 0.6263\n",
            "Epoch 171/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6281 - accuracy: 0.6142 - val_loss: 0.6189 - val_accuracy: 0.6125\n",
            "Epoch 172/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6247 - accuracy: 0.6254 - val_loss: 0.6076 - val_accuracy: 0.6375\n",
            "Epoch 173/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6227 - accuracy: 0.6189 - val_loss: 0.5933 - val_accuracy: 0.6112\n",
            "Epoch 174/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6261 - accuracy: 0.6160 - val_loss: 0.5932 - val_accuracy: 0.6587\n",
            "Epoch 175/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6244 - accuracy: 0.6197 - val_loss: 0.6155 - val_accuracy: 0.6363\n",
            "Epoch 176/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6239 - accuracy: 0.6212 - val_loss: 0.6136 - val_accuracy: 0.6400\n",
            "Epoch 177/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6258 - accuracy: 0.6251 - val_loss: 0.5914 - val_accuracy: 0.6162\n",
            "Epoch 178/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6247 - accuracy: 0.6208 - val_loss: 0.6223 - val_accuracy: 0.6200\n",
            "Epoch 179/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6252 - accuracy: 0.6192 - val_loss: 0.6116 - val_accuracy: 0.6388\n",
            "Epoch 180/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6258 - accuracy: 0.6201 - val_loss: 0.6225 - val_accuracy: 0.6150\n",
            "Epoch 181/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6262 - accuracy: 0.6197 - val_loss: 0.6012 - val_accuracy: 0.6587\n",
            "Epoch 182/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6269 - accuracy: 0.6165 - val_loss: 0.5953 - val_accuracy: 0.6712\n",
            "Epoch 183/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6260 - accuracy: 0.6210 - val_loss: 0.6094 - val_accuracy: 0.6413\n",
            "Epoch 184/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6254 - accuracy: 0.6187 - val_loss: 0.5970 - val_accuracy: 0.6612\n",
            "Epoch 185/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6271 - accuracy: 0.6211 - val_loss: 0.6085 - val_accuracy: 0.6338\n",
            "Epoch 186/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6239 - accuracy: 0.6183 - val_loss: 0.6196 - val_accuracy: 0.6137\n",
            "Epoch 187/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6288 - accuracy: 0.6143 - val_loss: 0.5931 - val_accuracy: 0.6450\n",
            "Epoch 188/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6245 - accuracy: 0.6269 - val_loss: 0.5955 - val_accuracy: 0.6687\n",
            "Epoch 189/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6314 - accuracy: 0.6217 - val_loss: 0.6256 - val_accuracy: 0.6212\n",
            "Epoch 190/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6257 - accuracy: 0.6161 - val_loss: 0.6047 - val_accuracy: 0.6425\n",
            "Epoch 191/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6223 - accuracy: 0.6203 - val_loss: 0.6039 - val_accuracy: 0.6513\n",
            "Epoch 192/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6237 - accuracy: 0.6193 - val_loss: 0.6109 - val_accuracy: 0.6275\n",
            "Epoch 193/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6248 - accuracy: 0.6199 - val_loss: 0.6016 - val_accuracy: 0.6538\n",
            "Epoch 194/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6227 - accuracy: 0.6226 - val_loss: 0.6335 - val_accuracy: 0.6313\n",
            "Epoch 195/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6247 - accuracy: 0.6254 - val_loss: 0.6018 - val_accuracy: 0.6513\n",
            "Epoch 196/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6219 - accuracy: 0.6265 - val_loss: 0.5908 - val_accuracy: 0.6125\n",
            "Epoch 197/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6257 - accuracy: 0.6185 - val_loss: 0.5950 - val_accuracy: 0.6637\n",
            "Epoch 198/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6272 - accuracy: 0.6218 - val_loss: 0.5975 - val_accuracy: 0.6612\n",
            "Epoch 199/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6247 - accuracy: 0.6236 - val_loss: 0.6351 - val_accuracy: 0.6488\n",
            "Epoch 200/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6291 - accuracy: 0.6182 - val_loss: 0.6552 - val_accuracy: 0.6137\n",
            "Epoch 201/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6259 - accuracy: 0.6196 - val_loss: 0.5962 - val_accuracy: 0.6600\n",
            "Epoch 202/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6238 - accuracy: 0.6182 - val_loss: 0.5892 - val_accuracy: 0.6125\n",
            "Epoch 203/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6266 - accuracy: 0.6161 - val_loss: 0.5926 - val_accuracy: 0.6488\n",
            "Epoch 204/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6259 - accuracy: 0.6142 - val_loss: 0.6060 - val_accuracy: 0.6463\n",
            "Epoch 205/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6231 - accuracy: 0.6214 - val_loss: 0.5917 - val_accuracy: 0.6750\n",
            "Epoch 206/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6226 - accuracy: 0.6249 - val_loss: 0.6199 - val_accuracy: 0.6100\n",
            "Epoch 207/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6313 - accuracy: 0.6074 - val_loss: 0.6193 - val_accuracy: 0.6275\n",
            "Epoch 208/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6261 - accuracy: 0.6232 - val_loss: 0.6047 - val_accuracy: 0.6413\n",
            "Epoch 209/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6244 - accuracy: 0.6204 - val_loss: 0.6446 - val_accuracy: 0.6225\n",
            "Epoch 210/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6239 - accuracy: 0.6172 - val_loss: 0.5928 - val_accuracy: 0.6625\n",
            "Epoch 211/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6235 - accuracy: 0.6194 - val_loss: 0.5922 - val_accuracy: 0.6538\n",
            "Epoch 212/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6282 - accuracy: 0.6235 - val_loss: 0.6208 - val_accuracy: 0.6175\n",
            "Epoch 213/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6234 - accuracy: 0.6179 - val_loss: 0.5922 - val_accuracy: 0.6587\n",
            "Epoch 214/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6229 - accuracy: 0.6246 - val_loss: 0.5949 - val_accuracy: 0.6675\n",
            "Epoch 215/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6264 - accuracy: 0.6172 - val_loss: 0.6640 - val_accuracy: 0.6050\n",
            "Epoch 216/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6234 - accuracy: 0.6215 - val_loss: 0.5928 - val_accuracy: 0.6762\n",
            "Epoch 217/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6247 - accuracy: 0.6219 - val_loss: 0.5943 - val_accuracy: 0.6062\n",
            "Epoch 218/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6275 - accuracy: 0.6171 - val_loss: 0.6260 - val_accuracy: 0.6300\n",
            "Epoch 219/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6226 - accuracy: 0.6203 - val_loss: 0.6118 - val_accuracy: 0.6275\n",
            "Epoch 220/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6251 - accuracy: 0.6199 - val_loss: 0.5995 - val_accuracy: 0.6600\n",
            "Epoch 221/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6248 - accuracy: 0.6219 - val_loss: 0.6071 - val_accuracy: 0.6450\n",
            "Epoch 222/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6242 - accuracy: 0.6207 - val_loss: 0.6292 - val_accuracy: 0.6313\n",
            "Epoch 223/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6254 - accuracy: 0.6193 - val_loss: 0.5975 - val_accuracy: 0.6575\n",
            "Epoch 224/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6248 - accuracy: 0.6212 - val_loss: 0.6073 - val_accuracy: 0.6413\n",
            "Epoch 225/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6258 - accuracy: 0.6187 - val_loss: 0.6046 - val_accuracy: 0.6438\n",
            "Epoch 226/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6238 - accuracy: 0.6212 - val_loss: 0.6453 - val_accuracy: 0.6237\n",
            "Epoch 227/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6230 - accuracy: 0.6197 - val_loss: 0.6171 - val_accuracy: 0.6200\n",
            "Epoch 228/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6234 - accuracy: 0.6215 - val_loss: 0.5972 - val_accuracy: 0.6625\n",
            "Epoch 229/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6226 - accuracy: 0.6185 - val_loss: 0.5950 - val_accuracy: 0.6637\n",
            "Epoch 230/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6258 - accuracy: 0.6212 - val_loss: 0.6111 - val_accuracy: 0.6263\n",
            "Epoch 231/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6221 - accuracy: 0.6236 - val_loss: 0.5978 - val_accuracy: 0.6550\n",
            "Epoch 232/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6235 - accuracy: 0.6258 - val_loss: 0.5865 - val_accuracy: 0.6100\n",
            "Epoch 233/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6260 - accuracy: 0.6219 - val_loss: 0.6037 - val_accuracy: 0.6400\n",
            "Epoch 234/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6246 - accuracy: 0.6231 - val_loss: 0.5893 - val_accuracy: 0.6338\n",
            "Epoch 235/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6243 - accuracy: 0.6210 - val_loss: 0.6105 - val_accuracy: 0.6338\n",
            "Epoch 236/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6250 - accuracy: 0.6221 - val_loss: 0.5928 - val_accuracy: 0.6737\n",
            "Epoch 237/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6251 - accuracy: 0.6211 - val_loss: 0.6125 - val_accuracy: 0.6162\n",
            "Epoch 238/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6254 - accuracy: 0.6175 - val_loss: 0.5963 - val_accuracy: 0.6450\n",
            "Epoch 239/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6212 - accuracy: 0.6235 - val_loss: 0.6027 - val_accuracy: 0.6488\n",
            "Epoch 240/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6216 - accuracy: 0.6253 - val_loss: 0.6105 - val_accuracy: 0.6288\n",
            "Epoch 241/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6233 - accuracy: 0.6235 - val_loss: 0.5936 - val_accuracy: 0.6650\n",
            "Epoch 242/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6236 - accuracy: 0.6258 - val_loss: 0.5990 - val_accuracy: 0.6562\n",
            "Epoch 243/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6199 - accuracy: 0.6315 - val_loss: 0.5882 - val_accuracy: 0.6212\n",
            "Epoch 244/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6223 - accuracy: 0.6207 - val_loss: 0.6107 - val_accuracy: 0.6313\n",
            "Epoch 245/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6232 - accuracy: 0.6217 - val_loss: 0.6059 - val_accuracy: 0.6425\n",
            "Epoch 246/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6240 - accuracy: 0.6239 - val_loss: 0.6004 - val_accuracy: 0.6513\n",
            "Epoch 247/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6232 - accuracy: 0.6239 - val_loss: 0.5967 - val_accuracy: 0.6438\n",
            "Epoch 248/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6227 - accuracy: 0.6258 - val_loss: 0.5935 - val_accuracy: 0.6650\n",
            "Epoch 249/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6218 - accuracy: 0.6190 - val_loss: 0.5860 - val_accuracy: 0.6250\n",
            "Epoch 250/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6218 - accuracy: 0.6239 - val_loss: 0.5959 - val_accuracy: 0.6575\n",
            "Epoch 251/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6241 - accuracy: 0.6211 - val_loss: 0.6196 - val_accuracy: 0.6275\n",
            "Epoch 252/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6207 - accuracy: 0.6285 - val_loss: 0.5888 - val_accuracy: 0.6275\n",
            "Epoch 253/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6237 - accuracy: 0.6260 - val_loss: 0.5951 - val_accuracy: 0.6575\n",
            "Epoch 254/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6226 - accuracy: 0.6257 - val_loss: 0.6008 - val_accuracy: 0.6513\n",
            "Epoch 255/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6233 - accuracy: 0.6187 - val_loss: 0.5999 - val_accuracy: 0.6500\n",
            "Epoch 256/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6222 - accuracy: 0.6228 - val_loss: 0.5981 - val_accuracy: 0.6538\n",
            "Epoch 257/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6227 - accuracy: 0.6244 - val_loss: 0.6114 - val_accuracy: 0.6288\n",
            "Epoch 258/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6218 - accuracy: 0.6256 - val_loss: 0.5959 - val_accuracy: 0.6550\n",
            "Epoch 259/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6246 - accuracy: 0.6208 - val_loss: 0.5951 - val_accuracy: 0.6600\n",
            "Epoch 260/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6211 - accuracy: 0.6207 - val_loss: 0.6123 - val_accuracy: 0.6225\n",
            "Epoch 261/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6247 - accuracy: 0.6225 - val_loss: 0.5909 - val_accuracy: 0.6725\n",
            "Epoch 262/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6250 - accuracy: 0.6189 - val_loss: 0.6179 - val_accuracy: 0.6187\n",
            "Epoch 263/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6248 - accuracy: 0.6176 - val_loss: 0.5916 - val_accuracy: 0.6637\n",
            "Epoch 264/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6213 - accuracy: 0.6217 - val_loss: 0.6129 - val_accuracy: 0.6162\n",
            "Epoch 265/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6212 - accuracy: 0.6258 - val_loss: 0.5943 - val_accuracy: 0.6112\n",
            "Epoch 266/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6252 - accuracy: 0.6192 - val_loss: 0.5894 - val_accuracy: 0.6575\n",
            "Epoch 267/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6247 - accuracy: 0.6200 - val_loss: 0.5917 - val_accuracy: 0.6762\n",
            "Epoch 268/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6236 - accuracy: 0.6208 - val_loss: 0.6103 - val_accuracy: 0.6263\n",
            "Epoch 269/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6232 - accuracy: 0.6240 - val_loss: 0.5939 - val_accuracy: 0.6150\n",
            "Epoch 270/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6257 - accuracy: 0.6214 - val_loss: 0.6421 - val_accuracy: 0.6250\n",
            "Epoch 271/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6225 - accuracy: 0.6221 - val_loss: 0.6235 - val_accuracy: 0.6325\n",
            "Epoch 272/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6234 - accuracy: 0.6233 - val_loss: 0.5912 - val_accuracy: 0.6637\n",
            "Epoch 273/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6236 - accuracy: 0.6267 - val_loss: 0.5929 - val_accuracy: 0.6650\n",
            "Epoch 274/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6208 - accuracy: 0.6268 - val_loss: 0.6188 - val_accuracy: 0.6288\n",
            "Epoch 275/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6232 - accuracy: 0.6226 - val_loss: 0.5930 - val_accuracy: 0.6600\n",
            "Epoch 276/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6239 - accuracy: 0.6197 - val_loss: 0.5968 - val_accuracy: 0.6438\n",
            "Epoch 277/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6244 - accuracy: 0.6161 - val_loss: 0.5997 - val_accuracy: 0.6525\n",
            "Epoch 278/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6227 - accuracy: 0.6239 - val_loss: 0.5918 - val_accuracy: 0.6513\n",
            "Epoch 279/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6229 - accuracy: 0.6232 - val_loss: 0.6047 - val_accuracy: 0.6450\n",
            "Epoch 280/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6252 - accuracy: 0.6240 - val_loss: 0.6241 - val_accuracy: 0.6263\n",
            "Epoch 281/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6215 - accuracy: 0.6261 - val_loss: 0.5878 - val_accuracy: 0.6212\n",
            "Epoch 282/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6202 - accuracy: 0.6274 - val_loss: 0.5937 - val_accuracy: 0.6637\n",
            "Epoch 283/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6221 - accuracy: 0.6257 - val_loss: 0.5953 - val_accuracy: 0.6625\n",
            "Epoch 284/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6203 - accuracy: 0.6271 - val_loss: 0.6137 - val_accuracy: 0.6275\n",
            "Epoch 285/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6235 - accuracy: 0.6235 - val_loss: 0.5995 - val_accuracy: 0.6513\n",
            "Epoch 286/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6216 - accuracy: 0.6250 - val_loss: 0.5891 - val_accuracy: 0.6625\n",
            "Epoch 287/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6240 - accuracy: 0.6210 - val_loss: 0.5857 - val_accuracy: 0.6150\n",
            "Epoch 288/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6257 - accuracy: 0.6190 - val_loss: 0.5872 - val_accuracy: 0.6612\n",
            "Epoch 289/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6205 - accuracy: 0.6263 - val_loss: 0.6206 - val_accuracy: 0.6200\n",
            "Epoch 290/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6237 - accuracy: 0.6239 - val_loss: 0.6195 - val_accuracy: 0.6162\n",
            "Epoch 291/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6227 - accuracy: 0.6254 - val_loss: 0.5935 - val_accuracy: 0.6575\n",
            "Epoch 292/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6218 - accuracy: 0.6263 - val_loss: 0.5899 - val_accuracy: 0.6625\n",
            "Epoch 293/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6210 - accuracy: 0.6211 - val_loss: 0.6084 - val_accuracy: 0.6288\n",
            "Epoch 294/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6238 - accuracy: 0.6172 - val_loss: 0.6143 - val_accuracy: 0.6250\n",
            "Epoch 295/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6208 - accuracy: 0.6229 - val_loss: 0.5918 - val_accuracy: 0.6650\n",
            "Epoch 296/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6218 - accuracy: 0.6268 - val_loss: 0.5894 - val_accuracy: 0.6600\n",
            "Epoch 297/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6202 - accuracy: 0.6306 - val_loss: 0.5881 - val_accuracy: 0.6737\n",
            "Epoch 298/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6219 - accuracy: 0.6225 - val_loss: 0.5961 - val_accuracy: 0.6513\n",
            "Epoch 299/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6249 - accuracy: 0.6279 - val_loss: 0.5892 - val_accuracy: 0.6562\n",
            "Epoch 300/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6226 - accuracy: 0.6271 - val_loss: 0.5960 - val_accuracy: 0.6538\n",
            "Epoch 301/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6195 - accuracy: 0.6276 - val_loss: 0.5978 - val_accuracy: 0.6513\n",
            "Epoch 302/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6187 - accuracy: 0.6282 - val_loss: 0.6106 - val_accuracy: 0.6288\n",
            "Epoch 303/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6203 - accuracy: 0.6242 - val_loss: 0.5892 - val_accuracy: 0.6388\n",
            "Epoch 304/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6208 - accuracy: 0.6264 - val_loss: 0.5913 - val_accuracy: 0.6687\n",
            "Epoch 305/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6215 - accuracy: 0.6263 - val_loss: 0.6112 - val_accuracy: 0.6150\n",
            "Epoch 306/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6210 - accuracy: 0.6201 - val_loss: 0.6051 - val_accuracy: 0.6413\n",
            "Epoch 307/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6216 - accuracy: 0.6250 - val_loss: 0.6153 - val_accuracy: 0.6175\n",
            "Epoch 308/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6225 - accuracy: 0.6200 - val_loss: 0.6034 - val_accuracy: 0.6375\n",
            "Epoch 309/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6206 - accuracy: 0.6247 - val_loss: 0.5925 - val_accuracy: 0.6662\n",
            "Epoch 310/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6214 - accuracy: 0.6265 - val_loss: 0.5924 - val_accuracy: 0.6612\n",
            "Epoch 311/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6249 - accuracy: 0.6181 - val_loss: 0.6045 - val_accuracy: 0.6388\n",
            "Epoch 312/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6198 - accuracy: 0.6250 - val_loss: 0.5904 - val_accuracy: 0.6687\n",
            "Epoch 313/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6214 - accuracy: 0.6218 - val_loss: 0.5981 - val_accuracy: 0.6525\n",
            "Epoch 314/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6224 - accuracy: 0.6250 - val_loss: 0.5968 - val_accuracy: 0.6562\n",
            "Epoch 315/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6228 - accuracy: 0.6232 - val_loss: 0.6004 - val_accuracy: 0.6500\n",
            "Epoch 316/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6189 - accuracy: 0.6251 - val_loss: 0.5954 - val_accuracy: 0.6550\n",
            "Epoch 317/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6217 - accuracy: 0.6243 - val_loss: 0.5914 - val_accuracy: 0.6662\n",
            "Epoch 318/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6207 - accuracy: 0.6253 - val_loss: 0.5886 - val_accuracy: 0.6637\n",
            "Epoch 319/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6215 - accuracy: 0.6197 - val_loss: 0.6128 - val_accuracy: 0.6338\n",
            "Epoch 320/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6198 - accuracy: 0.6274 - val_loss: 0.5962 - val_accuracy: 0.6525\n",
            "Epoch 321/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6184 - accuracy: 0.6306 - val_loss: 0.6450 - val_accuracy: 0.6187\n",
            "Epoch 322/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6213 - accuracy: 0.6290 - val_loss: 0.5919 - val_accuracy: 0.6612\n",
            "Epoch 323/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6198 - accuracy: 0.6260 - val_loss: 0.6029 - val_accuracy: 0.6450\n",
            "Epoch 324/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6188 - accuracy: 0.6254 - val_loss: 0.6002 - val_accuracy: 0.6513\n",
            "Epoch 325/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6185 - accuracy: 0.6306 - val_loss: 0.6036 - val_accuracy: 0.6525\n",
            "Epoch 326/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6200 - accuracy: 0.6250 - val_loss: 0.5917 - val_accuracy: 0.6600\n",
            "Epoch 327/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6189 - accuracy: 0.6357 - val_loss: 0.6181 - val_accuracy: 0.6275\n",
            "Epoch 328/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6186 - accuracy: 0.6256 - val_loss: 0.5907 - val_accuracy: 0.6712\n",
            "Epoch 329/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6194 - accuracy: 0.6260 - val_loss: 0.6224 - val_accuracy: 0.6275\n",
            "Epoch 330/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6234 - accuracy: 0.6210 - val_loss: 0.6125 - val_accuracy: 0.6200\n",
            "Epoch 331/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6186 - accuracy: 0.6275 - val_loss: 0.5956 - val_accuracy: 0.6513\n",
            "Epoch 332/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6210 - accuracy: 0.6275 - val_loss: 0.6196 - val_accuracy: 0.6200\n",
            "Epoch 333/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6205 - accuracy: 0.6236 - val_loss: 0.5920 - val_accuracy: 0.6600\n",
            "Epoch 334/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6180 - accuracy: 0.6286 - val_loss: 0.5897 - val_accuracy: 0.6762\n",
            "Epoch 335/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6194 - accuracy: 0.6268 - val_loss: 0.6079 - val_accuracy: 0.6250\n",
            "Epoch 336/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6226 - accuracy: 0.6246 - val_loss: 0.6224 - val_accuracy: 0.6350\n",
            "Epoch 337/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6205 - accuracy: 0.6247 - val_loss: 0.6197 - val_accuracy: 0.6288\n",
            "Epoch 338/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6199 - accuracy: 0.6283 - val_loss: 0.5904 - val_accuracy: 0.6650\n",
            "Epoch 339/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6195 - accuracy: 0.6256 - val_loss: 0.5905 - val_accuracy: 0.6575\n",
            "Epoch 340/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6176 - accuracy: 0.6256 - val_loss: 0.5850 - val_accuracy: 0.6237\n",
            "Epoch 341/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6204 - accuracy: 0.6250 - val_loss: 0.6176 - val_accuracy: 0.6212\n",
            "Epoch 342/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6211 - accuracy: 0.6194 - val_loss: 0.6139 - val_accuracy: 0.6187\n",
            "Epoch 343/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6205 - accuracy: 0.6243 - val_loss: 0.6140 - val_accuracy: 0.6300\n",
            "Epoch 344/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6186 - accuracy: 0.6329 - val_loss: 0.5932 - val_accuracy: 0.6587\n",
            "Epoch 345/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6195 - accuracy: 0.6278 - val_loss: 0.5938 - val_accuracy: 0.6562\n",
            "Epoch 346/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6200 - accuracy: 0.6299 - val_loss: 0.5861 - val_accuracy: 0.6175\n",
            "Epoch 347/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6202 - accuracy: 0.6260 - val_loss: 0.5970 - val_accuracy: 0.6463\n",
            "Epoch 348/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6217 - accuracy: 0.6239 - val_loss: 0.6067 - val_accuracy: 0.6275\n",
            "Epoch 349/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6195 - accuracy: 0.6267 - val_loss: 0.5912 - val_accuracy: 0.6612\n",
            "Epoch 350/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6208 - accuracy: 0.6290 - val_loss: 0.6090 - val_accuracy: 0.6200\n",
            "Epoch 351/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6204 - accuracy: 0.6263 - val_loss: 0.6115 - val_accuracy: 0.6175\n",
            "Epoch 352/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6222 - accuracy: 0.6217 - val_loss: 0.5944 - val_accuracy: 0.6550\n",
            "Epoch 353/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6198 - accuracy: 0.6237 - val_loss: 0.5864 - val_accuracy: 0.6762\n",
            "Epoch 354/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6191 - accuracy: 0.6318 - val_loss: 0.5949 - val_accuracy: 0.6488\n",
            "Epoch 355/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6189 - accuracy: 0.6276 - val_loss: 0.5853 - val_accuracy: 0.6787\n",
            "Epoch 356/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6187 - accuracy: 0.6268 - val_loss: 0.5830 - val_accuracy: 0.6175\n",
            "Epoch 357/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6189 - accuracy: 0.6290 - val_loss: 0.5874 - val_accuracy: 0.6725\n",
            "Epoch 358/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6216 - accuracy: 0.6263 - val_loss: 0.6257 - val_accuracy: 0.6338\n",
            "Epoch 359/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6243 - accuracy: 0.6242 - val_loss: 0.5907 - val_accuracy: 0.6637\n",
            "Epoch 360/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6225 - accuracy: 0.6242 - val_loss: 0.5940 - val_accuracy: 0.6587\n",
            "Epoch 361/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6218 - accuracy: 0.6235 - val_loss: 0.5870 - val_accuracy: 0.6637\n",
            "Epoch 362/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6190 - accuracy: 0.6249 - val_loss: 0.5932 - val_accuracy: 0.6587\n",
            "Epoch 363/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6194 - accuracy: 0.6268 - val_loss: 0.6060 - val_accuracy: 0.6288\n",
            "Epoch 364/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6201 - accuracy: 0.6250 - val_loss: 0.6022 - val_accuracy: 0.6438\n",
            "Epoch 365/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6176 - accuracy: 0.6286 - val_loss: 0.5937 - val_accuracy: 0.6550\n",
            "Epoch 366/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6181 - accuracy: 0.6285 - val_loss: 0.5947 - val_accuracy: 0.6550\n",
            "Epoch 367/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6187 - accuracy: 0.6217 - val_loss: 0.5896 - val_accuracy: 0.6750\n",
            "Epoch 368/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6181 - accuracy: 0.6329 - val_loss: 0.6161 - val_accuracy: 0.6200\n",
            "Epoch 369/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6191 - accuracy: 0.6303 - val_loss: 0.5943 - val_accuracy: 0.6525\n",
            "Epoch 370/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6157 - accuracy: 0.6296 - val_loss: 0.5933 - val_accuracy: 0.6538\n",
            "Epoch 371/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6185 - accuracy: 0.6279 - val_loss: 0.5883 - val_accuracy: 0.6450\n",
            "Epoch 372/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6200 - accuracy: 0.6269 - val_loss: 0.5924 - val_accuracy: 0.6450\n",
            "Epoch 373/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6190 - accuracy: 0.6260 - val_loss: 0.6510 - val_accuracy: 0.6463\n",
            "Epoch 374/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6176 - accuracy: 0.6308 - val_loss: 0.5828 - val_accuracy: 0.6650\n",
            "Epoch 375/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6203 - accuracy: 0.6261 - val_loss: 0.5972 - val_accuracy: 0.6513\n",
            "Epoch 376/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6196 - accuracy: 0.6244 - val_loss: 0.5878 - val_accuracy: 0.6750\n",
            "Epoch 377/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6175 - accuracy: 0.6283 - val_loss: 0.5888 - val_accuracy: 0.6700\n",
            "Epoch 378/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6190 - accuracy: 0.6286 - val_loss: 0.5849 - val_accuracy: 0.6175\n",
            "Epoch 379/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6185 - accuracy: 0.6293 - val_loss: 0.6010 - val_accuracy: 0.6413\n",
            "Epoch 380/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6205 - accuracy: 0.6296 - val_loss: 0.5858 - val_accuracy: 0.6687\n",
            "Epoch 381/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6183 - accuracy: 0.6308 - val_loss: 0.6001 - val_accuracy: 0.6463\n",
            "Epoch 382/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6162 - accuracy: 0.6365 - val_loss: 0.5948 - val_accuracy: 0.6550\n",
            "Epoch 383/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6196 - accuracy: 0.6313 - val_loss: 0.5834 - val_accuracy: 0.6513\n",
            "Epoch 384/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6263 - accuracy: 0.6231 - val_loss: 0.5938 - val_accuracy: 0.6550\n",
            "Epoch 385/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6166 - accuracy: 0.6299 - val_loss: 0.5828 - val_accuracy: 0.6400\n",
            "Epoch 386/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6185 - accuracy: 0.6293 - val_loss: 0.5923 - val_accuracy: 0.6600\n",
            "Epoch 387/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6182 - accuracy: 0.6286 - val_loss: 0.6137 - val_accuracy: 0.6388\n",
            "Epoch 388/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6164 - accuracy: 0.6360 - val_loss: 0.6018 - val_accuracy: 0.6425\n",
            "Epoch 389/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6229 - accuracy: 0.6272 - val_loss: 0.5993 - val_accuracy: 0.6488\n",
            "Epoch 390/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6180 - accuracy: 0.6274 - val_loss: 0.5898 - val_accuracy: 0.6612\n",
            "Epoch 391/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6177 - accuracy: 0.6321 - val_loss: 0.5877 - val_accuracy: 0.6675\n",
            "Epoch 392/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6160 - accuracy: 0.6338 - val_loss: 0.5815 - val_accuracy: 0.6700\n",
            "Epoch 393/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6179 - accuracy: 0.6304 - val_loss: 0.5872 - val_accuracy: 0.6750\n",
            "Epoch 394/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6190 - accuracy: 0.6264 - val_loss: 0.6114 - val_accuracy: 0.6375\n",
            "Epoch 395/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6188 - accuracy: 0.6319 - val_loss: 0.5855 - val_accuracy: 0.6812\n",
            "Epoch 396/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6212 - accuracy: 0.6282 - val_loss: 0.5954 - val_accuracy: 0.6525\n",
            "Epoch 397/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6198 - accuracy: 0.6294 - val_loss: 0.5859 - val_accuracy: 0.6812\n",
            "Epoch 398/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6161 - accuracy: 0.6293 - val_loss: 0.5875 - val_accuracy: 0.6787\n",
            "Epoch 399/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6177 - accuracy: 0.6300 - val_loss: 0.5857 - val_accuracy: 0.6837\n",
            "Epoch 400/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6181 - accuracy: 0.6336 - val_loss: 0.5979 - val_accuracy: 0.6513\n",
            "Epoch 401/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6174 - accuracy: 0.6321 - val_loss: 0.6302 - val_accuracy: 0.6363\n",
            "Epoch 402/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6161 - accuracy: 0.6367 - val_loss: 0.5870 - val_accuracy: 0.6725\n",
            "Epoch 403/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6167 - accuracy: 0.6347 - val_loss: 0.5884 - val_accuracy: 0.6650\n",
            "Epoch 404/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6173 - accuracy: 0.6339 - val_loss: 0.5869 - val_accuracy: 0.6675\n",
            "Epoch 405/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6175 - accuracy: 0.6271 - val_loss: 0.5889 - val_accuracy: 0.6662\n",
            "Epoch 406/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6198 - accuracy: 0.6294 - val_loss: 0.6117 - val_accuracy: 0.6313\n",
            "Epoch 407/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6181 - accuracy: 0.6315 - val_loss: 0.5926 - val_accuracy: 0.6575\n",
            "Epoch 408/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6186 - accuracy: 0.6338 - val_loss: 0.5946 - val_accuracy: 0.6550\n",
            "Epoch 409/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6178 - accuracy: 0.6296 - val_loss: 0.6227 - val_accuracy: 0.6338\n",
            "Epoch 410/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6177 - accuracy: 0.6265 - val_loss: 0.5868 - val_accuracy: 0.6812\n",
            "Epoch 411/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6181 - accuracy: 0.6326 - val_loss: 0.5865 - val_accuracy: 0.6750\n",
            "Epoch 412/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6194 - accuracy: 0.6274 - val_loss: 0.5995 - val_accuracy: 0.6400\n",
            "Epoch 413/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6164 - accuracy: 0.6311 - val_loss: 0.5847 - val_accuracy: 0.6787\n",
            "Epoch 414/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6168 - accuracy: 0.6317 - val_loss: 0.6123 - val_accuracy: 0.6313\n",
            "Epoch 415/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6169 - accuracy: 0.6336 - val_loss: 0.5866 - val_accuracy: 0.6775\n",
            "Epoch 416/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6167 - accuracy: 0.6317 - val_loss: 0.5984 - val_accuracy: 0.6463\n",
            "Epoch 417/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6186 - accuracy: 0.6329 - val_loss: 0.6359 - val_accuracy: 0.6325\n",
            "Epoch 418/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6161 - accuracy: 0.6239 - val_loss: 0.6313 - val_accuracy: 0.6288\n",
            "Epoch 419/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6164 - accuracy: 0.6304 - val_loss: 0.5826 - val_accuracy: 0.6162\n",
            "Epoch 420/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6208 - accuracy: 0.6315 - val_loss: 0.6035 - val_accuracy: 0.6313\n",
            "Epoch 421/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6191 - accuracy: 0.6317 - val_loss: 0.6246 - val_accuracy: 0.6275\n",
            "Epoch 422/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6176 - accuracy: 0.6286 - val_loss: 0.6085 - val_accuracy: 0.6288\n",
            "Epoch 423/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6158 - accuracy: 0.6294 - val_loss: 0.5999 - val_accuracy: 0.6400\n",
            "Epoch 424/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6176 - accuracy: 0.6318 - val_loss: 0.5932 - val_accuracy: 0.6525\n",
            "Epoch 425/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6254 - accuracy: 0.6257 - val_loss: 0.5878 - val_accuracy: 0.6662\n",
            "Epoch 426/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6152 - accuracy: 0.6325 - val_loss: 0.5847 - val_accuracy: 0.6650\n",
            "Epoch 427/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6174 - accuracy: 0.6311 - val_loss: 0.6087 - val_accuracy: 0.6338\n",
            "Epoch 428/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6162 - accuracy: 0.6310 - val_loss: 0.5947 - val_accuracy: 0.6500\n",
            "Epoch 429/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6167 - accuracy: 0.6354 - val_loss: 0.5866 - val_accuracy: 0.6712\n",
            "Epoch 430/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6176 - accuracy: 0.6325 - val_loss: 0.6443 - val_accuracy: 0.6200\n",
            "Epoch 431/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6159 - accuracy: 0.6278 - val_loss: 0.5869 - val_accuracy: 0.6725\n",
            "Epoch 432/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6160 - accuracy: 0.6361 - val_loss: 0.5772 - val_accuracy: 0.6338\n",
            "Epoch 433/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6195 - accuracy: 0.6286 - val_loss: 0.6351 - val_accuracy: 0.6500\n",
            "Epoch 434/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6196 - accuracy: 0.6299 - val_loss: 0.6014 - val_accuracy: 0.6363\n",
            "Epoch 435/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6167 - accuracy: 0.6278 - val_loss: 0.6072 - val_accuracy: 0.6250\n",
            "Epoch 436/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6166 - accuracy: 0.6332 - val_loss: 0.5805 - val_accuracy: 0.6612\n",
            "Epoch 437/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6204 - accuracy: 0.6222 - val_loss: 0.5885 - val_accuracy: 0.6612\n",
            "Epoch 438/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6168 - accuracy: 0.6288 - val_loss: 0.5842 - val_accuracy: 0.6812\n",
            "Epoch 439/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6176 - accuracy: 0.6328 - val_loss: 0.6081 - val_accuracy: 0.6250\n",
            "Epoch 440/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6149 - accuracy: 0.6314 - val_loss: 0.6079 - val_accuracy: 0.6400\n",
            "Epoch 441/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6153 - accuracy: 0.6299 - val_loss: 0.5845 - val_accuracy: 0.6800\n",
            "Epoch 442/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6190 - accuracy: 0.6314 - val_loss: 0.6104 - val_accuracy: 0.6400\n",
            "Epoch 443/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6152 - accuracy: 0.6303 - val_loss: 0.6023 - val_accuracy: 0.6275\n",
            "Epoch 444/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6175 - accuracy: 0.6296 - val_loss: 0.6219 - val_accuracy: 0.6325\n",
            "Epoch 445/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6178 - accuracy: 0.6296 - val_loss: 0.6015 - val_accuracy: 0.6300\n",
            "Epoch 446/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6153 - accuracy: 0.6331 - val_loss: 0.5912 - val_accuracy: 0.6538\n",
            "Epoch 447/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6203 - accuracy: 0.6283 - val_loss: 0.5918 - val_accuracy: 0.6550\n",
            "Epoch 448/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6189 - accuracy: 0.6271 - val_loss: 0.5904 - val_accuracy: 0.6600\n",
            "Epoch 449/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6156 - accuracy: 0.6378 - val_loss: 0.5876 - val_accuracy: 0.6625\n",
            "Epoch 450/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6183 - accuracy: 0.6317 - val_loss: 0.5834 - val_accuracy: 0.6700\n",
            "Epoch 451/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6160 - accuracy: 0.6297 - val_loss: 0.5866 - val_accuracy: 0.6675\n",
            "Epoch 452/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6196 - accuracy: 0.6263 - val_loss: 0.5988 - val_accuracy: 0.6500\n",
            "Epoch 453/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6158 - accuracy: 0.6318 - val_loss: 0.5907 - val_accuracy: 0.6562\n",
            "Epoch 454/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6156 - accuracy: 0.6285 - val_loss: 0.6288 - val_accuracy: 0.6263\n",
            "Epoch 455/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6164 - accuracy: 0.6339 - val_loss: 0.5803 - val_accuracy: 0.6375\n",
            "Epoch 456/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6151 - accuracy: 0.6321 - val_loss: 0.6168 - val_accuracy: 0.6350\n",
            "Epoch 457/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6137 - accuracy: 0.6347 - val_loss: 0.5963 - val_accuracy: 0.6488\n",
            "Epoch 458/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6158 - accuracy: 0.6344 - val_loss: 0.5779 - val_accuracy: 0.6587\n",
            "Epoch 459/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6146 - accuracy: 0.6360 - val_loss: 0.6108 - val_accuracy: 0.6200\n",
            "Epoch 460/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6164 - accuracy: 0.6322 - val_loss: 0.5902 - val_accuracy: 0.6612\n",
            "Epoch 461/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6137 - accuracy: 0.6356 - val_loss: 0.5824 - val_accuracy: 0.6187\n",
            "Epoch 462/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6179 - accuracy: 0.6325 - val_loss: 0.5885 - val_accuracy: 0.6612\n",
            "Epoch 463/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6148 - accuracy: 0.6331 - val_loss: 0.6039 - val_accuracy: 0.6313\n",
            "Epoch 464/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6178 - accuracy: 0.6313 - val_loss: 0.6063 - val_accuracy: 0.6225\n",
            "Epoch 465/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6167 - accuracy: 0.6354 - val_loss: 0.5786 - val_accuracy: 0.6463\n",
            "Epoch 466/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6137 - accuracy: 0.6385 - val_loss: 0.5836 - val_accuracy: 0.6812\n",
            "Epoch 467/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6208 - accuracy: 0.6243 - val_loss: 0.6132 - val_accuracy: 0.6325\n",
            "Epoch 468/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6136 - accuracy: 0.6353 - val_loss: 0.5960 - val_accuracy: 0.6587\n",
            "Epoch 469/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6181 - accuracy: 0.6307 - val_loss: 0.5869 - val_accuracy: 0.6612\n",
            "Epoch 470/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6144 - accuracy: 0.6324 - val_loss: 0.5802 - val_accuracy: 0.6513\n",
            "Epoch 471/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6140 - accuracy: 0.6392 - val_loss: 0.5911 - val_accuracy: 0.6463\n",
            "Epoch 472/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6158 - accuracy: 0.6361 - val_loss: 0.6163 - val_accuracy: 0.6225\n",
            "Epoch 473/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6178 - accuracy: 0.6247 - val_loss: 0.5937 - val_accuracy: 0.6525\n",
            "Epoch 474/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6167 - accuracy: 0.6340 - val_loss: 0.5824 - val_accuracy: 0.6825\n",
            "Epoch 475/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6154 - accuracy: 0.6286 - val_loss: 0.5765 - val_accuracy: 0.6712\n",
            "Epoch 476/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6166 - accuracy: 0.6340 - val_loss: 0.6254 - val_accuracy: 0.6250\n",
            "Epoch 477/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6150 - accuracy: 0.6310 - val_loss: 0.6034 - val_accuracy: 0.6288\n",
            "Epoch 478/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6158 - accuracy: 0.6364 - val_loss: 0.5865 - val_accuracy: 0.6650\n",
            "Epoch 479/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6164 - accuracy: 0.6339 - val_loss: 0.5823 - val_accuracy: 0.6662\n",
            "Epoch 480/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6145 - accuracy: 0.6347 - val_loss: 0.5993 - val_accuracy: 0.6413\n",
            "Epoch 481/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6182 - accuracy: 0.6350 - val_loss: 0.5790 - val_accuracy: 0.6712\n",
            "Epoch 482/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6135 - accuracy: 0.6310 - val_loss: 0.5791 - val_accuracy: 0.6575\n",
            "Epoch 483/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6151 - accuracy: 0.6265 - val_loss: 0.5939 - val_accuracy: 0.6525\n",
            "Epoch 484/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6160 - accuracy: 0.6343 - val_loss: 0.5790 - val_accuracy: 0.6637\n",
            "Epoch 485/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6138 - accuracy: 0.6363 - val_loss: 0.5848 - val_accuracy: 0.6825\n",
            "Epoch 486/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6195 - accuracy: 0.6311 - val_loss: 0.6052 - val_accuracy: 0.6313\n",
            "Epoch 487/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6132 - accuracy: 0.6367 - val_loss: 0.6107 - val_accuracy: 0.6212\n",
            "Epoch 488/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6161 - accuracy: 0.6360 - val_loss: 0.5820 - val_accuracy: 0.6825\n",
            "Epoch 489/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6156 - accuracy: 0.6357 - val_loss: 0.5841 - val_accuracy: 0.6162\n",
            "Epoch 490/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6130 - accuracy: 0.6374 - val_loss: 0.5767 - val_accuracy: 0.6500\n",
            "Epoch 491/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6147 - accuracy: 0.6358 - val_loss: 0.5866 - val_accuracy: 0.6662\n",
            "Epoch 492/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6185 - accuracy: 0.6308 - val_loss: 0.6259 - val_accuracy: 0.6338\n",
            "Epoch 493/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6172 - accuracy: 0.6308 - val_loss: 0.5825 - val_accuracy: 0.6812\n",
            "Epoch 494/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6139 - accuracy: 0.6399 - val_loss: 0.6001 - val_accuracy: 0.6450\n",
            "Epoch 495/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6139 - accuracy: 0.6372 - val_loss: 0.5830 - val_accuracy: 0.6787\n",
            "Epoch 496/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6111 - accuracy: 0.6428 - val_loss: 0.6312 - val_accuracy: 0.6463\n",
            "Epoch 497/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6130 - accuracy: 0.6371 - val_loss: 0.5795 - val_accuracy: 0.6625\n",
            "Epoch 498/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6151 - accuracy: 0.6293 - val_loss: 0.6192 - val_accuracy: 0.6300\n",
            "Epoch 499/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6183 - accuracy: 0.6306 - val_loss: 0.5799 - val_accuracy: 0.6875\n",
            "Epoch 500/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6168 - accuracy: 0.6328 - val_loss: 0.5920 - val_accuracy: 0.6513\n",
            "Epoch 1/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6134 - accuracy: 0.6347 - val_loss: 0.6247 - val_accuracy: 0.6313\n",
            "Epoch 2/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6164 - accuracy: 0.6318 - val_loss: 0.5723 - val_accuracy: 0.6250\n",
            "Epoch 3/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6144 - accuracy: 0.6376 - val_loss: 0.5802 - val_accuracy: 0.6875\n",
            "Epoch 4/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6136 - accuracy: 0.6413 - val_loss: 0.6176 - val_accuracy: 0.6313\n",
            "Epoch 5/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6123 - accuracy: 0.6396 - val_loss: 0.6115 - val_accuracy: 0.6375\n",
            "Epoch 6/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6139 - accuracy: 0.6365 - val_loss: 0.6062 - val_accuracy: 0.6250\n",
            "Epoch 7/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6169 - accuracy: 0.6336 - val_loss: 0.5817 - val_accuracy: 0.6700\n",
            "Epoch 8/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6126 - accuracy: 0.6354 - val_loss: 0.5780 - val_accuracy: 0.6850\n",
            "Epoch 9/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6165 - accuracy: 0.6326 - val_loss: 0.5862 - val_accuracy: 0.6612\n",
            "Epoch 10/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6156 - accuracy: 0.6254 - val_loss: 0.5861 - val_accuracy: 0.6625\n",
            "Epoch 11/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6118 - accuracy: 0.6365 - val_loss: 0.5809 - val_accuracy: 0.6800\n",
            "Epoch 12/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6148 - accuracy: 0.6367 - val_loss: 0.6058 - val_accuracy: 0.6388\n",
            "Epoch 13/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6140 - accuracy: 0.6350 - val_loss: 0.5849 - val_accuracy: 0.6587\n",
            "Epoch 14/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6131 - accuracy: 0.6331 - val_loss: 0.5859 - val_accuracy: 0.6612\n",
            "Epoch 15/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6120 - accuracy: 0.6422 - val_loss: 0.5979 - val_accuracy: 0.6463\n",
            "Epoch 16/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6136 - accuracy: 0.6331 - val_loss: 0.5768 - val_accuracy: 0.6450\n",
            "Epoch 17/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6129 - accuracy: 0.6379 - val_loss: 0.6405 - val_accuracy: 0.6625\n",
            "Epoch 18/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6150 - accuracy: 0.6379 - val_loss: 0.5812 - val_accuracy: 0.6775\n",
            "Epoch 19/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6183 - accuracy: 0.6310 - val_loss: 0.5915 - val_accuracy: 0.6475\n",
            "Epoch 20/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6148 - accuracy: 0.6360 - val_loss: 0.6141 - val_accuracy: 0.6363\n",
            "Epoch 21/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6124 - accuracy: 0.6383 - val_loss: 0.6122 - val_accuracy: 0.6288\n",
            "Epoch 22/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6129 - accuracy: 0.6376 - val_loss: 0.5918 - val_accuracy: 0.6513\n",
            "Epoch 23/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6111 - accuracy: 0.6346 - val_loss: 0.5791 - val_accuracy: 0.6913\n",
            "Epoch 24/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6138 - accuracy: 0.6386 - val_loss: 0.5827 - val_accuracy: 0.6650\n",
            "Epoch 25/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6117 - accuracy: 0.6390 - val_loss: 0.5797 - val_accuracy: 0.6862\n",
            "Epoch 26/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6146 - accuracy: 0.6332 - val_loss: 0.5796 - val_accuracy: 0.6812\n",
            "Epoch 27/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6130 - accuracy: 0.6346 - val_loss: 0.5787 - val_accuracy: 0.6800\n",
            "Epoch 28/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6152 - accuracy: 0.6379 - val_loss: 0.5867 - val_accuracy: 0.6600\n",
            "Epoch 29/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6142 - accuracy: 0.6357 - val_loss: 0.5985 - val_accuracy: 0.6363\n",
            "Epoch 30/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6121 - accuracy: 0.6357 - val_loss: 0.5775 - val_accuracy: 0.6837\n",
            "Epoch 31/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6159 - accuracy: 0.6344 - val_loss: 0.5832 - val_accuracy: 0.6775\n",
            "Epoch 32/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6124 - accuracy: 0.6381 - val_loss: 0.6131 - val_accuracy: 0.6313\n",
            "Epoch 33/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6128 - accuracy: 0.6372 - val_loss: 0.5837 - val_accuracy: 0.6762\n",
            "Epoch 34/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6139 - accuracy: 0.6360 - val_loss: 0.5847 - val_accuracy: 0.6587\n",
            "Epoch 35/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6144 - accuracy: 0.6351 - val_loss: 0.5968 - val_accuracy: 0.6400\n",
            "Epoch 36/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6152 - accuracy: 0.6325 - val_loss: 0.5904 - val_accuracy: 0.6463\n",
            "Epoch 37/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6121 - accuracy: 0.6350 - val_loss: 0.6232 - val_accuracy: 0.6275\n",
            "Epoch 38/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6120 - accuracy: 0.6357 - val_loss: 0.6278 - val_accuracy: 0.6562\n",
            "Epoch 39/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6141 - accuracy: 0.6336 - val_loss: 0.5727 - val_accuracy: 0.6800\n",
            "Epoch 40/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6118 - accuracy: 0.6406 - val_loss: 0.6229 - val_accuracy: 0.6325\n",
            "Epoch 41/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6155 - accuracy: 0.6308 - val_loss: 0.5782 - val_accuracy: 0.6450\n",
            "Epoch 42/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6116 - accuracy: 0.6411 - val_loss: 0.5766 - val_accuracy: 0.6775\n",
            "Epoch 43/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6136 - accuracy: 0.6333 - val_loss: 0.5964 - val_accuracy: 0.6375\n",
            "Epoch 44/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6124 - accuracy: 0.6392 - val_loss: 0.5744 - val_accuracy: 0.6737\n",
            "Epoch 45/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6127 - accuracy: 0.6356 - val_loss: 0.5897 - val_accuracy: 0.6488\n",
            "Epoch 46/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6119 - accuracy: 0.6361 - val_loss: 0.5866 - val_accuracy: 0.6600\n",
            "Epoch 47/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6185 - accuracy: 0.6285 - val_loss: 0.6348 - val_accuracy: 0.6313\n",
            "Epoch 48/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6149 - accuracy: 0.6396 - val_loss: 0.5839 - val_accuracy: 0.6612\n",
            "Epoch 49/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6133 - accuracy: 0.6361 - val_loss: 0.5904 - val_accuracy: 0.6525\n",
            "Epoch 50/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6124 - accuracy: 0.6392 - val_loss: 0.5792 - val_accuracy: 0.6862\n",
            "Epoch 51/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6125 - accuracy: 0.6425 - val_loss: 0.6164 - val_accuracy: 0.6325\n",
            "Epoch 52/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6109 - accuracy: 0.6422 - val_loss: 0.5709 - val_accuracy: 0.6587\n",
            "Epoch 53/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6113 - accuracy: 0.6382 - val_loss: 0.5788 - val_accuracy: 0.6812\n",
            "Epoch 54/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6111 - accuracy: 0.6346 - val_loss: 0.5764 - val_accuracy: 0.6862\n",
            "Epoch 55/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6118 - accuracy: 0.6396 - val_loss: 0.5832 - val_accuracy: 0.6750\n",
            "Epoch 56/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6134 - accuracy: 0.6332 - val_loss: 0.5794 - val_accuracy: 0.6787\n",
            "Epoch 57/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6116 - accuracy: 0.6389 - val_loss: 0.5838 - val_accuracy: 0.6625\n",
            "Epoch 58/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6156 - accuracy: 0.6304 - val_loss: 0.5964 - val_accuracy: 0.6313\n",
            "Epoch 59/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6108 - accuracy: 0.6386 - val_loss: 0.5979 - val_accuracy: 0.6425\n",
            "Epoch 60/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6103 - accuracy: 0.6393 - val_loss: 0.5797 - val_accuracy: 0.6900\n",
            "Epoch 61/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6141 - accuracy: 0.6369 - val_loss: 0.5793 - val_accuracy: 0.6812\n",
            "Epoch 62/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6131 - accuracy: 0.6354 - val_loss: 0.5808 - val_accuracy: 0.6775\n",
            "Epoch 63/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6122 - accuracy: 0.6340 - val_loss: 0.5827 - val_accuracy: 0.6725\n",
            "Epoch 64/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6096 - accuracy: 0.6354 - val_loss: 0.5745 - val_accuracy: 0.6850\n",
            "Epoch 65/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6122 - accuracy: 0.6396 - val_loss: 0.6053 - val_accuracy: 0.6350\n",
            "Epoch 66/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6141 - accuracy: 0.6371 - val_loss: 0.5748 - val_accuracy: 0.6150\n",
            "Epoch 67/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6119 - accuracy: 0.6381 - val_loss: 0.6092 - val_accuracy: 0.6375\n",
            "Epoch 68/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6183 - accuracy: 0.6340 - val_loss: 0.5759 - val_accuracy: 0.6687\n",
            "Epoch 69/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6102 - accuracy: 0.6419 - val_loss: 0.6175 - val_accuracy: 0.6300\n",
            "Epoch 70/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6112 - accuracy: 0.6378 - val_loss: 0.6011 - val_accuracy: 0.6363\n",
            "Epoch 71/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6131 - accuracy: 0.6379 - val_loss: 0.5818 - val_accuracy: 0.6762\n",
            "Epoch 72/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6115 - accuracy: 0.6388 - val_loss: 0.5789 - val_accuracy: 0.6812\n",
            "Epoch 73/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6144 - accuracy: 0.6353 - val_loss: 0.5954 - val_accuracy: 0.6388\n",
            "Epoch 74/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6100 - accuracy: 0.6360 - val_loss: 0.5732 - val_accuracy: 0.6762\n",
            "Epoch 75/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6133 - accuracy: 0.6340 - val_loss: 0.5799 - val_accuracy: 0.6800\n",
            "Epoch 76/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6140 - accuracy: 0.6339 - val_loss: 0.5723 - val_accuracy: 0.6850\n",
            "Epoch 77/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6146 - accuracy: 0.6383 - val_loss: 0.5890 - val_accuracy: 0.6637\n",
            "Epoch 78/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6127 - accuracy: 0.6372 - val_loss: 0.5719 - val_accuracy: 0.6875\n",
            "Epoch 79/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6121 - accuracy: 0.6335 - val_loss: 0.6106 - val_accuracy: 0.6288\n",
            "Epoch 80/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6104 - accuracy: 0.6374 - val_loss: 0.5793 - val_accuracy: 0.6787\n",
            "Epoch 81/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6113 - accuracy: 0.6368 - val_loss: 0.5774 - val_accuracy: 0.6850\n",
            "Epoch 82/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6087 - accuracy: 0.6400 - val_loss: 0.5721 - val_accuracy: 0.6775\n",
            "Epoch 83/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6117 - accuracy: 0.6397 - val_loss: 0.5782 - val_accuracy: 0.6812\n",
            "Epoch 84/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6112 - accuracy: 0.6411 - val_loss: 0.5746 - val_accuracy: 0.6475\n",
            "Epoch 85/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6137 - accuracy: 0.6365 - val_loss: 0.5804 - val_accuracy: 0.6800\n",
            "Epoch 86/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6098 - accuracy: 0.6401 - val_loss: 0.5805 - val_accuracy: 0.6675\n",
            "Epoch 87/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6102 - accuracy: 0.6363 - val_loss: 0.6251 - val_accuracy: 0.6587\n",
            "Epoch 88/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6125 - accuracy: 0.6367 - val_loss: 0.6046 - val_accuracy: 0.6263\n",
            "Epoch 89/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6143 - accuracy: 0.6324 - val_loss: 0.5811 - val_accuracy: 0.6775\n",
            "Epoch 90/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6135 - accuracy: 0.6342 - val_loss: 0.5777 - val_accuracy: 0.6800\n",
            "Epoch 91/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6136 - accuracy: 0.6310 - val_loss: 0.5858 - val_accuracy: 0.6538\n",
            "Epoch 92/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6102 - accuracy: 0.6424 - val_loss: 0.5988 - val_accuracy: 0.6313\n",
            "Epoch 93/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6101 - accuracy: 0.6432 - val_loss: 0.5757 - val_accuracy: 0.6775\n",
            "Epoch 94/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6118 - accuracy: 0.6394 - val_loss: 0.6160 - val_accuracy: 0.6575\n",
            "Epoch 95/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6119 - accuracy: 0.6361 - val_loss: 0.5811 - val_accuracy: 0.6825\n",
            "Epoch 96/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6139 - accuracy: 0.6385 - val_loss: 0.6355 - val_accuracy: 0.6612\n",
            "Epoch 97/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6129 - accuracy: 0.6347 - val_loss: 0.5809 - val_accuracy: 0.6800\n",
            "Epoch 98/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6110 - accuracy: 0.6383 - val_loss: 0.5756 - val_accuracy: 0.6950\n",
            "Epoch 99/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6094 - accuracy: 0.6421 - val_loss: 0.5779 - val_accuracy: 0.6800\n",
            "Epoch 100/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6122 - accuracy: 0.6338 - val_loss: 0.5713 - val_accuracy: 0.6812\n",
            "Epoch 101/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6116 - accuracy: 0.6419 - val_loss: 0.5855 - val_accuracy: 0.6475\n",
            "Epoch 102/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6126 - accuracy: 0.6394 - val_loss: 0.5759 - val_accuracy: 0.6737\n",
            "Epoch 103/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6108 - accuracy: 0.6403 - val_loss: 0.5773 - val_accuracy: 0.6900\n",
            "Epoch 104/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6098 - accuracy: 0.6451 - val_loss: 0.5766 - val_accuracy: 0.6900\n",
            "Epoch 105/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6133 - accuracy: 0.6444 - val_loss: 0.5932 - val_accuracy: 0.6525\n",
            "Epoch 106/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6107 - accuracy: 0.6369 - val_loss: 0.5829 - val_accuracy: 0.6637\n",
            "Epoch 107/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6103 - accuracy: 0.6374 - val_loss: 0.5788 - val_accuracy: 0.6850\n",
            "Epoch 108/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6101 - accuracy: 0.6379 - val_loss: 0.5703 - val_accuracy: 0.6787\n",
            "Epoch 109/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6085 - accuracy: 0.6382 - val_loss: 0.5978 - val_accuracy: 0.6413\n",
            "Epoch 110/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6117 - accuracy: 0.6426 - val_loss: 0.5897 - val_accuracy: 0.6400\n",
            "Epoch 111/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6110 - accuracy: 0.6378 - val_loss: 0.5722 - val_accuracy: 0.6888\n",
            "Epoch 112/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6087 - accuracy: 0.6374 - val_loss: 0.5728 - val_accuracy: 0.6850\n",
            "Epoch 113/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6079 - accuracy: 0.6368 - val_loss: 0.5929 - val_accuracy: 0.6463\n",
            "Epoch 114/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6072 - accuracy: 0.6454 - val_loss: 0.5761 - val_accuracy: 0.6862\n",
            "Epoch 115/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6102 - accuracy: 0.6376 - val_loss: 0.5878 - val_accuracy: 0.6425\n",
            "Epoch 116/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6103 - accuracy: 0.6407 - val_loss: 0.5817 - val_accuracy: 0.6612\n",
            "Epoch 117/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6092 - accuracy: 0.6410 - val_loss: 0.5756 - val_accuracy: 0.6825\n",
            "Epoch 118/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6118 - accuracy: 0.6397 - val_loss: 0.5941 - val_accuracy: 0.6463\n",
            "Epoch 119/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6085 - accuracy: 0.6408 - val_loss: 0.5936 - val_accuracy: 0.6513\n",
            "Epoch 120/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6087 - accuracy: 0.6422 - val_loss: 0.5796 - val_accuracy: 0.6787\n",
            "Epoch 121/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6090 - accuracy: 0.6408 - val_loss: 0.5735 - val_accuracy: 0.6888\n",
            "Epoch 122/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6102 - accuracy: 0.6383 - val_loss: 0.5768 - val_accuracy: 0.6850\n",
            "Epoch 123/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6088 - accuracy: 0.6443 - val_loss: 0.5783 - val_accuracy: 0.6787\n",
            "Epoch 124/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6100 - accuracy: 0.6347 - val_loss: 0.5737 - val_accuracy: 0.6875\n",
            "Epoch 125/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6110 - accuracy: 0.6386 - val_loss: 0.5892 - val_accuracy: 0.6400\n",
            "Epoch 126/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6095 - accuracy: 0.6417 - val_loss: 0.5840 - val_accuracy: 0.6612\n",
            "Epoch 127/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6104 - accuracy: 0.6394 - val_loss: 0.5774 - val_accuracy: 0.6837\n",
            "Epoch 128/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6080 - accuracy: 0.6411 - val_loss: 0.5872 - val_accuracy: 0.6413\n",
            "Epoch 129/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6087 - accuracy: 0.6401 - val_loss: 0.5709 - val_accuracy: 0.6538\n",
            "Epoch 130/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6070 - accuracy: 0.6424 - val_loss: 0.6269 - val_accuracy: 0.6250\n",
            "Epoch 131/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6108 - accuracy: 0.6457 - val_loss: 0.5784 - val_accuracy: 0.6850\n",
            "Epoch 132/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6078 - accuracy: 0.6397 - val_loss: 0.6082 - val_accuracy: 0.6350\n",
            "Epoch 133/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6099 - accuracy: 0.6438 - val_loss: 0.5810 - val_accuracy: 0.6637\n",
            "Epoch 134/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6077 - accuracy: 0.6435 - val_loss: 0.5704 - val_accuracy: 0.6687\n",
            "Epoch 135/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6091 - accuracy: 0.6414 - val_loss: 0.6172 - val_accuracy: 0.6338\n",
            "Epoch 136/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6112 - accuracy: 0.6393 - val_loss: 0.6102 - val_accuracy: 0.6325\n",
            "Epoch 137/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.6117 - accuracy: 0.6415 - val_loss: 0.5719 - val_accuracy: 0.6712\n",
            "Epoch 138/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6087 - accuracy: 0.6401 - val_loss: 0.5764 - val_accuracy: 0.6875\n",
            "Epoch 139/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6099 - accuracy: 0.6440 - val_loss: 0.5745 - val_accuracy: 0.6162\n",
            "Epoch 140/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6114 - accuracy: 0.6425 - val_loss: 0.5738 - val_accuracy: 0.6900\n",
            "Epoch 141/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6081 - accuracy: 0.6432 - val_loss: 0.5902 - val_accuracy: 0.6363\n",
            "Epoch 142/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6074 - accuracy: 0.6429 - val_loss: 0.5681 - val_accuracy: 0.6837\n",
            "Epoch 143/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6106 - accuracy: 0.6394 - val_loss: 0.5723 - val_accuracy: 0.6700\n",
            "Epoch 144/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6104 - accuracy: 0.6414 - val_loss: 0.5806 - val_accuracy: 0.6662\n",
            "Epoch 145/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6072 - accuracy: 0.6440 - val_loss: 0.6059 - val_accuracy: 0.6700\n",
            "Epoch 146/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6116 - accuracy: 0.6414 - val_loss: 0.5828 - val_accuracy: 0.6587\n",
            "Epoch 147/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6100 - accuracy: 0.6469 - val_loss: 0.5718 - val_accuracy: 0.6875\n",
            "Epoch 148/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6069 - accuracy: 0.6432 - val_loss: 0.5805 - val_accuracy: 0.6737\n",
            "Epoch 149/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6097 - accuracy: 0.6438 - val_loss: 0.5646 - val_accuracy: 0.6750\n",
            "Epoch 150/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6071 - accuracy: 0.6444 - val_loss: 0.5802 - val_accuracy: 0.6637\n",
            "Epoch 151/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6079 - accuracy: 0.6428 - val_loss: 0.5842 - val_accuracy: 0.6475\n",
            "Epoch 152/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6054 - accuracy: 0.6450 - val_loss: 0.5713 - val_accuracy: 0.6938\n",
            "Epoch 153/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6068 - accuracy: 0.6418 - val_loss: 0.5852 - val_accuracy: 0.6375\n",
            "Epoch 154/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6052 - accuracy: 0.6478 - val_loss: 0.5696 - val_accuracy: 0.6812\n",
            "Epoch 155/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6072 - accuracy: 0.6458 - val_loss: 0.5695 - val_accuracy: 0.6700\n",
            "Epoch 156/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6078 - accuracy: 0.6394 - val_loss: 0.5939 - val_accuracy: 0.6562\n",
            "Epoch 157/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6112 - accuracy: 0.6368 - val_loss: 0.5761 - val_accuracy: 0.6850\n",
            "Epoch 158/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6081 - accuracy: 0.6431 - val_loss: 0.5916 - val_accuracy: 0.6438\n",
            "Epoch 159/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6076 - accuracy: 0.6433 - val_loss: 0.5837 - val_accuracy: 0.6500\n",
            "Epoch 160/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6077 - accuracy: 0.6454 - val_loss: 0.5699 - val_accuracy: 0.6463\n",
            "Epoch 161/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6091 - accuracy: 0.6421 - val_loss: 0.5724 - val_accuracy: 0.6850\n",
            "Epoch 162/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6148 - accuracy: 0.6418 - val_loss: 0.5719 - val_accuracy: 0.6925\n",
            "Epoch 163/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6076 - accuracy: 0.6428 - val_loss: 0.5701 - val_accuracy: 0.6850\n",
            "Epoch 164/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6079 - accuracy: 0.6453 - val_loss: 0.5816 - val_accuracy: 0.6575\n",
            "Epoch 165/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6083 - accuracy: 0.6451 - val_loss: 0.5668 - val_accuracy: 0.6812\n",
            "Epoch 166/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6094 - accuracy: 0.6369 - val_loss: 0.5942 - val_accuracy: 0.6450\n",
            "Epoch 167/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6087 - accuracy: 0.6406 - val_loss: 0.5803 - val_accuracy: 0.6662\n",
            "Epoch 168/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6082 - accuracy: 0.6432 - val_loss: 0.5698 - val_accuracy: 0.6425\n",
            "Epoch 169/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6091 - accuracy: 0.6392 - val_loss: 0.5731 - val_accuracy: 0.6888\n",
            "Epoch 170/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6068 - accuracy: 0.6435 - val_loss: 0.5860 - val_accuracy: 0.6438\n",
            "Epoch 171/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6058 - accuracy: 0.6457 - val_loss: 0.5736 - val_accuracy: 0.6875\n",
            "Epoch 172/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6061 - accuracy: 0.6497 - val_loss: 0.5717 - val_accuracy: 0.6900\n",
            "Epoch 173/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6109 - accuracy: 0.6475 - val_loss: 0.5949 - val_accuracy: 0.6400\n",
            "Epoch 174/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6066 - accuracy: 0.6433 - val_loss: 0.5774 - val_accuracy: 0.6812\n",
            "Epoch 175/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6076 - accuracy: 0.6417 - val_loss: 0.5799 - val_accuracy: 0.6687\n",
            "Epoch 176/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6060 - accuracy: 0.6419 - val_loss: 0.5812 - val_accuracy: 0.6662\n",
            "Epoch 177/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6074 - accuracy: 0.6464 - val_loss: 0.5747 - val_accuracy: 0.6750\n",
            "Epoch 178/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6092 - accuracy: 0.6375 - val_loss: 0.5822 - val_accuracy: 0.6525\n",
            "Epoch 179/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6096 - accuracy: 0.6438 - val_loss: 0.5674 - val_accuracy: 0.6862\n",
            "Epoch 180/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6110 - accuracy: 0.6482 - val_loss: 0.5728 - val_accuracy: 0.6750\n",
            "Epoch 181/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6069 - accuracy: 0.6465 - val_loss: 0.5690 - val_accuracy: 0.6762\n",
            "Epoch 182/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6082 - accuracy: 0.6419 - val_loss: 0.5654 - val_accuracy: 0.6737\n",
            "Epoch 183/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6072 - accuracy: 0.6465 - val_loss: 0.5767 - val_accuracy: 0.6812\n",
            "Epoch 184/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6054 - accuracy: 0.6451 - val_loss: 0.5802 - val_accuracy: 0.6575\n",
            "Epoch 185/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6075 - accuracy: 0.6424 - val_loss: 0.5652 - val_accuracy: 0.6850\n",
            "Epoch 186/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6068 - accuracy: 0.6443 - val_loss: 0.5676 - val_accuracy: 0.6850\n",
            "Epoch 187/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6070 - accuracy: 0.6440 - val_loss: 0.5782 - val_accuracy: 0.6700\n",
            "Epoch 188/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6065 - accuracy: 0.6468 - val_loss: 0.5782 - val_accuracy: 0.6737\n",
            "Epoch 189/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6051 - accuracy: 0.6465 - val_loss: 0.6141 - val_accuracy: 0.6300\n",
            "Epoch 190/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6123 - accuracy: 0.6392 - val_loss: 0.5676 - val_accuracy: 0.6825\n",
            "Epoch 191/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6036 - accuracy: 0.6488 - val_loss: 0.5933 - val_accuracy: 0.6375\n",
            "Epoch 192/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6071 - accuracy: 0.6454 - val_loss: 0.5743 - val_accuracy: 0.6888\n",
            "Epoch 193/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6061 - accuracy: 0.6474 - val_loss: 0.5689 - val_accuracy: 0.6975\n",
            "Epoch 194/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6072 - accuracy: 0.6419 - val_loss: 0.5757 - val_accuracy: 0.6812\n",
            "Epoch 195/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6062 - accuracy: 0.6435 - val_loss: 0.5725 - val_accuracy: 0.6850\n",
            "Epoch 196/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6084 - accuracy: 0.6403 - val_loss: 0.5708 - val_accuracy: 0.6913\n",
            "Epoch 197/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6084 - accuracy: 0.6397 - val_loss: 0.5809 - val_accuracy: 0.6538\n",
            "Epoch 198/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6070 - accuracy: 0.6422 - val_loss: 0.5814 - val_accuracy: 0.6637\n",
            "Epoch 199/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6055 - accuracy: 0.6468 - val_loss: 0.5836 - val_accuracy: 0.6388\n",
            "Epoch 200/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6093 - accuracy: 0.6390 - val_loss: 0.5689 - val_accuracy: 0.6737\n",
            "Epoch 201/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6072 - accuracy: 0.6418 - val_loss: 0.5683 - val_accuracy: 0.6212\n",
            "Epoch 202/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6077 - accuracy: 0.6449 - val_loss: 0.5690 - val_accuracy: 0.6900\n",
            "Epoch 203/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6050 - accuracy: 0.6458 - val_loss: 0.5747 - val_accuracy: 0.6975\n",
            "Epoch 204/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6053 - accuracy: 0.6458 - val_loss: 0.5679 - val_accuracy: 0.6862\n",
            "Epoch 205/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6063 - accuracy: 0.6414 - val_loss: 0.5628 - val_accuracy: 0.6787\n",
            "Epoch 206/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6088 - accuracy: 0.6419 - val_loss: 0.5790 - val_accuracy: 0.6712\n",
            "Epoch 207/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6070 - accuracy: 0.6431 - val_loss: 0.5660 - val_accuracy: 0.6787\n",
            "Epoch 208/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6074 - accuracy: 0.6424 - val_loss: 0.5685 - val_accuracy: 0.6812\n",
            "Epoch 209/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6071 - accuracy: 0.6435 - val_loss: 0.5705 - val_accuracy: 0.6750\n",
            "Epoch 210/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6073 - accuracy: 0.6415 - val_loss: 0.5700 - val_accuracy: 0.6875\n",
            "Epoch 211/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6080 - accuracy: 0.6504 - val_loss: 0.5852 - val_accuracy: 0.6463\n",
            "Epoch 212/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6072 - accuracy: 0.6457 - val_loss: 0.5993 - val_accuracy: 0.6400\n",
            "Epoch 213/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6059 - accuracy: 0.6443 - val_loss: 0.5915 - val_accuracy: 0.6413\n",
            "Epoch 214/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6049 - accuracy: 0.6444 - val_loss: 0.5678 - val_accuracy: 0.6913\n",
            "Epoch 215/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6067 - accuracy: 0.6411 - val_loss: 0.5659 - val_accuracy: 0.6787\n",
            "Epoch 216/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6082 - accuracy: 0.6442 - val_loss: 0.5700 - val_accuracy: 0.6587\n",
            "Epoch 217/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6093 - accuracy: 0.6403 - val_loss: 0.5708 - val_accuracy: 0.6950\n",
            "Epoch 218/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6066 - accuracy: 0.6425 - val_loss: 0.5667 - val_accuracy: 0.6888\n",
            "Epoch 219/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6064 - accuracy: 0.6468 - val_loss: 0.5831 - val_accuracy: 0.6650\n",
            "Epoch 220/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6043 - accuracy: 0.6542 - val_loss: 0.5715 - val_accuracy: 0.6913\n",
            "Epoch 221/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6041 - accuracy: 0.6428 - val_loss: 0.5715 - val_accuracy: 0.6888\n",
            "Epoch 222/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6076 - accuracy: 0.6476 - val_loss: 0.5642 - val_accuracy: 0.6825\n",
            "Epoch 223/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6122 - accuracy: 0.6401 - val_loss: 0.5898 - val_accuracy: 0.6400\n",
            "Epoch 224/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6066 - accuracy: 0.6396 - val_loss: 0.5721 - val_accuracy: 0.6888\n",
            "Epoch 225/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6052 - accuracy: 0.6488 - val_loss: 0.5790 - val_accuracy: 0.6625\n",
            "Epoch 226/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6079 - accuracy: 0.6400 - val_loss: 0.5954 - val_accuracy: 0.6438\n",
            "Epoch 227/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6043 - accuracy: 0.6436 - val_loss: 0.5727 - val_accuracy: 0.6862\n",
            "Epoch 228/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6071 - accuracy: 0.6454 - val_loss: 0.5718 - val_accuracy: 0.6925\n",
            "Epoch 229/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6044 - accuracy: 0.6443 - val_loss: 0.5907 - val_accuracy: 0.6425\n",
            "Epoch 230/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6088 - accuracy: 0.6429 - val_loss: 0.5670 - val_accuracy: 0.6862\n",
            "Epoch 231/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6080 - accuracy: 0.6429 - val_loss: 0.5730 - val_accuracy: 0.7000\n",
            "Epoch 232/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6040 - accuracy: 0.6428 - val_loss: 0.5812 - val_accuracy: 0.6488\n",
            "Epoch 233/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6088 - accuracy: 0.6378 - val_loss: 0.6098 - val_accuracy: 0.6350\n",
            "Epoch 234/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6100 - accuracy: 0.6411 - val_loss: 0.5675 - val_accuracy: 0.6900\n",
            "Epoch 235/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6047 - accuracy: 0.6506 - val_loss: 0.6004 - val_accuracy: 0.6438\n",
            "Epoch 236/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6054 - accuracy: 0.6469 - val_loss: 0.5798 - val_accuracy: 0.6575\n",
            "Epoch 237/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6046 - accuracy: 0.6514 - val_loss: 0.5796 - val_accuracy: 0.6575\n",
            "Epoch 238/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6082 - accuracy: 0.6375 - val_loss: 0.5688 - val_accuracy: 0.6950\n",
            "Epoch 239/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6048 - accuracy: 0.6458 - val_loss: 0.5625 - val_accuracy: 0.6950\n",
            "Epoch 240/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6029 - accuracy: 0.6507 - val_loss: 0.6210 - val_accuracy: 0.6675\n",
            "Epoch 241/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6023 - accuracy: 0.6513 - val_loss: 0.5785 - val_accuracy: 0.6737\n",
            "Epoch 242/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6049 - accuracy: 0.6476 - val_loss: 0.5647 - val_accuracy: 0.6587\n",
            "Epoch 243/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6067 - accuracy: 0.6440 - val_loss: 0.5698 - val_accuracy: 0.6913\n",
            "Epoch 244/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6054 - accuracy: 0.6493 - val_loss: 0.5682 - val_accuracy: 0.6725\n",
            "Epoch 245/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6063 - accuracy: 0.6436 - val_loss: 0.5692 - val_accuracy: 0.6925\n",
            "Epoch 246/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6054 - accuracy: 0.6540 - val_loss: 0.5819 - val_accuracy: 0.6425\n",
            "Epoch 247/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6044 - accuracy: 0.6500 - val_loss: 0.5936 - val_accuracy: 0.6400\n",
            "Epoch 248/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6038 - accuracy: 0.6494 - val_loss: 0.5642 - val_accuracy: 0.6762\n",
            "Epoch 249/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6058 - accuracy: 0.6432 - val_loss: 0.5692 - val_accuracy: 0.6888\n",
            "Epoch 250/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6040 - accuracy: 0.6542 - val_loss: 0.5951 - val_accuracy: 0.6400\n",
            "Epoch 251/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6025 - accuracy: 0.6458 - val_loss: 0.5866 - val_accuracy: 0.6562\n",
            "Epoch 252/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6047 - accuracy: 0.6517 - val_loss: 0.5777 - val_accuracy: 0.6775\n",
            "Epoch 253/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6042 - accuracy: 0.6485 - val_loss: 0.5938 - val_accuracy: 0.6450\n",
            "Epoch 254/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6044 - accuracy: 0.6457 - val_loss: 0.5840 - val_accuracy: 0.6550\n",
            "Epoch 255/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6049 - accuracy: 0.6483 - val_loss: 0.5800 - val_accuracy: 0.6737\n",
            "Epoch 256/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6056 - accuracy: 0.6479 - val_loss: 0.5760 - val_accuracy: 0.6812\n",
            "Epoch 257/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6050 - accuracy: 0.6457 - val_loss: 0.5657 - val_accuracy: 0.6900\n",
            "Epoch 258/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6038 - accuracy: 0.6453 - val_loss: 0.5678 - val_accuracy: 0.6888\n",
            "Epoch 259/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6035 - accuracy: 0.6507 - val_loss: 0.5845 - val_accuracy: 0.6413\n",
            "Epoch 260/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6043 - accuracy: 0.6444 - val_loss: 0.5814 - val_accuracy: 0.6450\n",
            "Epoch 261/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6037 - accuracy: 0.6475 - val_loss: 0.6793 - val_accuracy: 0.6212\n",
            "Epoch 262/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6070 - accuracy: 0.6442 - val_loss: 0.5679 - val_accuracy: 0.6938\n",
            "Epoch 263/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6093 - accuracy: 0.6381 - val_loss: 0.5748 - val_accuracy: 0.6750\n",
            "Epoch 264/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6038 - accuracy: 0.6479 - val_loss: 0.5606 - val_accuracy: 0.6350\n",
            "Epoch 265/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6053 - accuracy: 0.6494 - val_loss: 0.5874 - val_accuracy: 0.6687\n",
            "Epoch 266/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6063 - accuracy: 0.6465 - val_loss: 0.5722 - val_accuracy: 0.6938\n",
            "Epoch 267/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6054 - accuracy: 0.6464 - val_loss: 0.5703 - val_accuracy: 0.6913\n",
            "Epoch 268/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6041 - accuracy: 0.6446 - val_loss: 0.5635 - val_accuracy: 0.6913\n",
            "Epoch 269/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6059 - accuracy: 0.6496 - val_loss: 0.5655 - val_accuracy: 0.6862\n",
            "Epoch 270/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6027 - accuracy: 0.6531 - val_loss: 0.5609 - val_accuracy: 0.6888\n",
            "Epoch 271/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6051 - accuracy: 0.6529 - val_loss: 0.5629 - val_accuracy: 0.6875\n",
            "Epoch 272/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6037 - accuracy: 0.6456 - val_loss: 0.6005 - val_accuracy: 0.6775\n",
            "Epoch 273/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6078 - accuracy: 0.6415 - val_loss: 0.5650 - val_accuracy: 0.6875\n",
            "Epoch 274/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6053 - accuracy: 0.6453 - val_loss: 0.5650 - val_accuracy: 0.6862\n",
            "Epoch 275/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6028 - accuracy: 0.6488 - val_loss: 0.5593 - val_accuracy: 0.6850\n",
            "Epoch 276/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6043 - accuracy: 0.6490 - val_loss: 0.5667 - val_accuracy: 0.7025\n",
            "Epoch 277/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6016 - accuracy: 0.6521 - val_loss: 0.5895 - val_accuracy: 0.6463\n",
            "Epoch 278/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6030 - accuracy: 0.6503 - val_loss: 0.5711 - val_accuracy: 0.6988\n",
            "Epoch 279/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6022 - accuracy: 0.6507 - val_loss: 0.6049 - val_accuracy: 0.6662\n",
            "Epoch 280/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.6025 - accuracy: 0.6467 - val_loss: 0.6134 - val_accuracy: 0.6625\n",
            "Epoch 281/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6057 - accuracy: 0.6503 - val_loss: 0.5772 - val_accuracy: 0.6637\n",
            "Epoch 282/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6030 - accuracy: 0.6496 - val_loss: 0.5729 - val_accuracy: 0.6875\n",
            "Epoch 283/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6037 - accuracy: 0.6468 - val_loss: 0.5709 - val_accuracy: 0.6950\n",
            "Epoch 284/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6047 - accuracy: 0.6486 - val_loss: 0.5789 - val_accuracy: 0.6675\n",
            "Epoch 285/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6047 - accuracy: 0.6513 - val_loss: 0.5695 - val_accuracy: 0.6913\n",
            "Epoch 286/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6044 - accuracy: 0.6513 - val_loss: 0.6434 - val_accuracy: 0.6550\n",
            "Epoch 287/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6032 - accuracy: 0.6481 - val_loss: 0.5626 - val_accuracy: 0.6787\n",
            "Epoch 288/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6039 - accuracy: 0.6510 - val_loss: 0.5670 - val_accuracy: 0.6963\n",
            "Epoch 289/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6040 - accuracy: 0.6456 - val_loss: 0.5923 - val_accuracy: 0.6488\n",
            "Epoch 290/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6060 - accuracy: 0.6485 - val_loss: 0.5967 - val_accuracy: 0.6587\n",
            "Epoch 291/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6019 - accuracy: 0.6478 - val_loss: 0.5700 - val_accuracy: 0.6938\n",
            "Epoch 292/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6043 - accuracy: 0.6496 - val_loss: 0.5858 - val_accuracy: 0.6513\n",
            "Epoch 293/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6019 - accuracy: 0.6518 - val_loss: 0.5685 - val_accuracy: 0.6338\n",
            "Epoch 294/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6023 - accuracy: 0.6574 - val_loss: 0.5758 - val_accuracy: 0.6612\n",
            "Epoch 295/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6048 - accuracy: 0.6490 - val_loss: 0.5624 - val_accuracy: 0.6888\n",
            "Epoch 296/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6033 - accuracy: 0.6483 - val_loss: 0.5677 - val_accuracy: 0.6900\n",
            "Epoch 297/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6003 - accuracy: 0.6556 - val_loss: 0.5622 - val_accuracy: 0.6812\n",
            "Epoch 298/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6010 - accuracy: 0.6544 - val_loss: 0.5771 - val_accuracy: 0.6538\n",
            "Epoch 299/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6053 - accuracy: 0.6471 - val_loss: 0.5631 - val_accuracy: 0.6812\n",
            "Epoch 300/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6068 - accuracy: 0.6493 - val_loss: 0.5648 - val_accuracy: 0.6900\n",
            "Epoch 301/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6025 - accuracy: 0.6460 - val_loss: 0.5697 - val_accuracy: 0.6963\n",
            "Epoch 302/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6027 - accuracy: 0.6543 - val_loss: 0.5675 - val_accuracy: 0.6925\n",
            "Epoch 303/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6013 - accuracy: 0.6524 - val_loss: 0.5724 - val_accuracy: 0.6900\n",
            "Epoch 304/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6027 - accuracy: 0.6496 - val_loss: 0.5599 - val_accuracy: 0.6288\n",
            "Epoch 305/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6056 - accuracy: 0.6478 - val_loss: 0.5630 - val_accuracy: 0.6288\n",
            "Epoch 306/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6049 - accuracy: 0.6443 - val_loss: 0.5908 - val_accuracy: 0.6737\n",
            "Epoch 307/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.6010 - accuracy: 0.6569 - val_loss: 0.5750 - val_accuracy: 0.6637\n",
            "Epoch 308/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6021 - accuracy: 0.6494 - val_loss: 0.5776 - val_accuracy: 0.6612\n",
            "Epoch 309/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6040 - accuracy: 0.6492 - val_loss: 0.6046 - val_accuracy: 0.6812\n",
            "Epoch 310/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6019 - accuracy: 0.6551 - val_loss: 0.5658 - val_accuracy: 0.6900\n",
            "Epoch 311/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6006 - accuracy: 0.6522 - val_loss: 0.5753 - val_accuracy: 0.6662\n",
            "Epoch 312/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6014 - accuracy: 0.6514 - val_loss: 0.5710 - val_accuracy: 0.6975\n",
            "Epoch 313/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6020 - accuracy: 0.6499 - val_loss: 0.5619 - val_accuracy: 0.6225\n",
            "Epoch 314/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6031 - accuracy: 0.6469 - val_loss: 0.5617 - val_accuracy: 0.6888\n",
            "Epoch 315/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6025 - accuracy: 0.6472 - val_loss: 0.5647 - val_accuracy: 0.6850\n",
            "Epoch 316/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6022 - accuracy: 0.6506 - val_loss: 0.5634 - val_accuracy: 0.6913\n",
            "Epoch 317/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6004 - accuracy: 0.6556 - val_loss: 0.5895 - val_accuracy: 0.6500\n",
            "Epoch 318/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6055 - accuracy: 0.6489 - val_loss: 0.5862 - val_accuracy: 0.6725\n",
            "Epoch 319/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6023 - accuracy: 0.6561 - val_loss: 0.5617 - val_accuracy: 0.6925\n",
            "Epoch 320/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6023 - accuracy: 0.6515 - val_loss: 0.5626 - val_accuracy: 0.7025\n",
            "Epoch 321/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5999 - accuracy: 0.6554 - val_loss: 0.5711 - val_accuracy: 0.6812\n",
            "Epoch 322/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6003 - accuracy: 0.6510 - val_loss: 0.5723 - val_accuracy: 0.6875\n",
            "Epoch 323/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6014 - accuracy: 0.6508 - val_loss: 0.5612 - val_accuracy: 0.6413\n",
            "Epoch 324/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6016 - accuracy: 0.6478 - val_loss: 0.5690 - val_accuracy: 0.6963\n",
            "Epoch 325/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6004 - accuracy: 0.6501 - val_loss: 0.5751 - val_accuracy: 0.6650\n",
            "Epoch 326/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6017 - accuracy: 0.6521 - val_loss: 0.5722 - val_accuracy: 0.6762\n",
            "Epoch 327/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6005 - accuracy: 0.6547 - val_loss: 0.5651 - val_accuracy: 0.6975\n",
            "Epoch 328/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6025 - accuracy: 0.6467 - val_loss: 0.5637 - val_accuracy: 0.6925\n",
            "Epoch 329/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6043 - accuracy: 0.6458 - val_loss: 0.5649 - val_accuracy: 0.6925\n",
            "Epoch 330/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6033 - accuracy: 0.6492 - val_loss: 0.5619 - val_accuracy: 0.6925\n",
            "Epoch 331/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6021 - accuracy: 0.6499 - val_loss: 0.5548 - val_accuracy: 0.6862\n",
            "Epoch 332/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6027 - accuracy: 0.6528 - val_loss: 0.5810 - val_accuracy: 0.6488\n",
            "Epoch 333/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6011 - accuracy: 0.6490 - val_loss: 0.5596 - val_accuracy: 0.6825\n",
            "Epoch 334/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6012 - accuracy: 0.6556 - val_loss: 0.5795 - val_accuracy: 0.6625\n",
            "Epoch 335/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6006 - accuracy: 0.6518 - val_loss: 0.5713 - val_accuracy: 0.6775\n",
            "Epoch 336/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6010 - accuracy: 0.6529 - val_loss: 0.5615 - val_accuracy: 0.6925\n",
            "Epoch 337/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6012 - accuracy: 0.6486 - val_loss: 0.5712 - val_accuracy: 0.6750\n",
            "Epoch 338/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6030 - accuracy: 0.6485 - val_loss: 0.5708 - val_accuracy: 0.6687\n",
            "Epoch 339/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6057 - accuracy: 0.6514 - val_loss: 0.5748 - val_accuracy: 0.6800\n",
            "Epoch 340/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6075 - accuracy: 0.6479 - val_loss: 0.5886 - val_accuracy: 0.6438\n",
            "Epoch 341/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6003 - accuracy: 0.6515 - val_loss: 0.5634 - val_accuracy: 0.6812\n",
            "Epoch 342/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5992 - accuracy: 0.6547 - val_loss: 0.5625 - val_accuracy: 0.6950\n",
            "Epoch 343/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6003 - accuracy: 0.6561 - val_loss: 0.5578 - val_accuracy: 0.6737\n",
            "Epoch 344/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6060 - accuracy: 0.6451 - val_loss: 0.5657 - val_accuracy: 0.6925\n",
            "Epoch 345/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.6015 - accuracy: 0.6524 - val_loss: 0.5586 - val_accuracy: 0.6900\n",
            "Epoch 346/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6036 - accuracy: 0.6554 - val_loss: 0.5587 - val_accuracy: 0.6862\n",
            "Epoch 347/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6013 - accuracy: 0.6501 - val_loss: 0.5980 - val_accuracy: 0.6762\n",
            "Epoch 348/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6020 - accuracy: 0.6526 - val_loss: 0.5819 - val_accuracy: 0.6600\n",
            "Epoch 349/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5984 - accuracy: 0.6540 - val_loss: 0.5619 - val_accuracy: 0.6975\n",
            "Epoch 350/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5997 - accuracy: 0.6536 - val_loss: 0.5990 - val_accuracy: 0.6725\n",
            "Epoch 351/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6035 - accuracy: 0.6535 - val_loss: 0.5634 - val_accuracy: 0.6950\n",
            "Epoch 352/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6001 - accuracy: 0.6481 - val_loss: 0.5631 - val_accuracy: 0.6975\n",
            "Epoch 353/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6014 - accuracy: 0.6461 - val_loss: 0.5942 - val_accuracy: 0.6775\n",
            "Epoch 354/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6020 - accuracy: 0.6528 - val_loss: 0.5746 - val_accuracy: 0.6612\n",
            "Epoch 355/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5992 - accuracy: 0.6529 - val_loss: 0.5603 - val_accuracy: 0.6913\n",
            "Epoch 356/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5991 - accuracy: 0.6531 - val_loss: 0.5638 - val_accuracy: 0.7075\n",
            "Epoch 357/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6053 - accuracy: 0.6460 - val_loss: 0.5644 - val_accuracy: 0.7050\n",
            "Epoch 358/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6006 - accuracy: 0.6510 - val_loss: 0.5600 - val_accuracy: 0.6950\n",
            "Epoch 359/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6004 - accuracy: 0.6524 - val_loss: 0.5614 - val_accuracy: 0.6950\n",
            "Epoch 360/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6002 - accuracy: 0.6547 - val_loss: 0.5864 - val_accuracy: 0.6787\n",
            "Epoch 361/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5997 - accuracy: 0.6578 - val_loss: 0.5876 - val_accuracy: 0.6475\n",
            "Epoch 362/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6046 - accuracy: 0.6550 - val_loss: 0.5551 - val_accuracy: 0.6900\n",
            "Epoch 363/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6066 - accuracy: 0.6492 - val_loss: 0.5582 - val_accuracy: 0.6825\n",
            "Epoch 364/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5997 - accuracy: 0.6583 - val_loss: 0.5700 - val_accuracy: 0.6725\n",
            "Epoch 365/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5993 - accuracy: 0.6497 - val_loss: 0.5839 - val_accuracy: 0.6550\n",
            "Epoch 366/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6000 - accuracy: 0.6538 - val_loss: 0.5615 - val_accuracy: 0.6812\n",
            "Epoch 367/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5980 - accuracy: 0.6558 - val_loss: 0.5578 - val_accuracy: 0.6888\n",
            "Epoch 368/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5988 - accuracy: 0.6486 - val_loss: 0.5606 - val_accuracy: 0.6975\n",
            "Epoch 369/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6018 - accuracy: 0.6493 - val_loss: 0.5662 - val_accuracy: 0.7088\n",
            "Epoch 370/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6034 - accuracy: 0.6501 - val_loss: 0.5824 - val_accuracy: 0.6600\n",
            "Epoch 371/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6060 - accuracy: 0.6472 - val_loss: 0.5574 - val_accuracy: 0.6875\n",
            "Epoch 372/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6000 - accuracy: 0.6501 - val_loss: 0.5626 - val_accuracy: 0.6963\n",
            "Epoch 373/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5996 - accuracy: 0.6540 - val_loss: 0.5609 - val_accuracy: 0.6938\n",
            "Epoch 374/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5984 - accuracy: 0.6499 - val_loss: 0.5572 - val_accuracy: 0.6850\n",
            "Epoch 375/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5989 - accuracy: 0.6528 - val_loss: 0.5614 - val_accuracy: 0.7063\n",
            "Epoch 376/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6010 - accuracy: 0.6542 - val_loss: 0.5616 - val_accuracy: 0.6363\n",
            "Epoch 377/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5990 - accuracy: 0.6549 - val_loss: 0.5680 - val_accuracy: 0.6837\n",
            "Epoch 378/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5996 - accuracy: 0.6517 - val_loss: 0.5669 - val_accuracy: 0.6988\n",
            "Epoch 379/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6012 - accuracy: 0.6521 - val_loss: 0.5849 - val_accuracy: 0.6538\n",
            "Epoch 380/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6005 - accuracy: 0.6531 - val_loss: 0.6006 - val_accuracy: 0.6463\n",
            "Epoch 381/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6016 - accuracy: 0.6496 - val_loss: 0.5973 - val_accuracy: 0.6800\n",
            "Epoch 382/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5981 - accuracy: 0.6549 - val_loss: 0.5692 - val_accuracy: 0.6750\n",
            "Epoch 383/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6005 - accuracy: 0.6506 - val_loss: 0.5625 - val_accuracy: 0.6975\n",
            "Epoch 384/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5988 - accuracy: 0.6572 - val_loss: 0.5599 - val_accuracy: 0.6975\n",
            "Epoch 385/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6013 - accuracy: 0.6528 - val_loss: 0.5857 - val_accuracy: 0.6513\n",
            "Epoch 386/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5985 - accuracy: 0.6571 - val_loss: 0.5526 - val_accuracy: 0.6837\n",
            "Epoch 387/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5980 - accuracy: 0.6550 - val_loss: 0.5662 - val_accuracy: 0.7125\n",
            "Epoch 388/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6029 - accuracy: 0.6536 - val_loss: 0.5554 - val_accuracy: 0.6862\n",
            "Epoch 389/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6000 - accuracy: 0.6569 - val_loss: 0.5786 - val_accuracy: 0.6575\n",
            "Epoch 390/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6008 - accuracy: 0.6539 - val_loss: 0.5640 - val_accuracy: 0.6938\n",
            "Epoch 391/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6013 - accuracy: 0.6496 - val_loss: 0.5637 - val_accuracy: 0.7038\n",
            "Epoch 392/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6005 - accuracy: 0.6560 - val_loss: 0.5766 - val_accuracy: 0.6712\n",
            "Epoch 393/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5970 - accuracy: 0.6582 - val_loss: 0.5579 - val_accuracy: 0.6913\n",
            "Epoch 394/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5982 - accuracy: 0.6550 - val_loss: 0.5649 - val_accuracy: 0.6963\n",
            "Epoch 395/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5967 - accuracy: 0.6592 - val_loss: 0.5831 - val_accuracy: 0.6475\n",
            "Epoch 396/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5997 - accuracy: 0.6528 - val_loss: 0.5621 - val_accuracy: 0.6237\n",
            "Epoch 397/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6010 - accuracy: 0.6547 - val_loss: 0.5709 - val_accuracy: 0.6700\n",
            "Epoch 398/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6017 - accuracy: 0.6558 - val_loss: 0.5613 - val_accuracy: 0.7063\n",
            "Epoch 399/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5993 - accuracy: 0.6499 - val_loss: 0.5589 - val_accuracy: 0.6950\n",
            "Epoch 400/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5966 - accuracy: 0.6564 - val_loss: 0.5961 - val_accuracy: 0.6762\n",
            "Epoch 401/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5980 - accuracy: 0.6526 - val_loss: 0.5578 - val_accuracy: 0.6988\n",
            "Epoch 402/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6001 - accuracy: 0.6536 - val_loss: 0.5645 - val_accuracy: 0.7000\n",
            "Epoch 403/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6010 - accuracy: 0.6532 - val_loss: 0.5719 - val_accuracy: 0.6687\n",
            "Epoch 404/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5984 - accuracy: 0.6564 - val_loss: 0.5531 - val_accuracy: 0.6775\n",
            "Epoch 405/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6004 - accuracy: 0.6510 - val_loss: 0.5575 - val_accuracy: 0.6700\n",
            "Epoch 406/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5993 - accuracy: 0.6547 - val_loss: 0.5597 - val_accuracy: 0.6938\n",
            "Epoch 407/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5999 - accuracy: 0.6544 - val_loss: 0.5528 - val_accuracy: 0.6875\n",
            "Epoch 408/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5982 - accuracy: 0.6583 - val_loss: 0.5898 - val_accuracy: 0.6625\n",
            "Epoch 409/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5987 - accuracy: 0.6536 - val_loss: 0.6204 - val_accuracy: 0.6687\n",
            "Epoch 410/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5977 - accuracy: 0.6590 - val_loss: 0.5693 - val_accuracy: 0.6750\n",
            "Epoch 411/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5968 - accuracy: 0.6581 - val_loss: 0.5631 - val_accuracy: 0.7050\n",
            "Epoch 412/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6014 - accuracy: 0.6507 - val_loss: 0.5507 - val_accuracy: 0.6712\n",
            "Epoch 413/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5989 - accuracy: 0.6538 - val_loss: 0.5602 - val_accuracy: 0.6938\n",
            "Epoch 414/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5981 - accuracy: 0.6564 - val_loss: 0.5598 - val_accuracy: 0.6975\n",
            "Epoch 415/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5969 - accuracy: 0.6549 - val_loss: 0.6062 - val_accuracy: 0.6750\n",
            "Epoch 416/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6000 - accuracy: 0.6601 - val_loss: 0.5564 - val_accuracy: 0.6963\n",
            "Epoch 417/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5979 - accuracy: 0.6540 - val_loss: 0.5658 - val_accuracy: 0.6862\n",
            "Epoch 418/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5967 - accuracy: 0.6565 - val_loss: 0.5672 - val_accuracy: 0.6762\n",
            "Epoch 419/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5969 - accuracy: 0.6579 - val_loss: 0.5752 - val_accuracy: 0.6625\n",
            "Epoch 420/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5987 - accuracy: 0.6558 - val_loss: 0.5712 - val_accuracy: 0.6750\n",
            "Epoch 421/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6021 - accuracy: 0.6529 - val_loss: 0.5542 - val_accuracy: 0.6712\n",
            "Epoch 422/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5974 - accuracy: 0.6562 - val_loss: 0.6059 - val_accuracy: 0.6725\n",
            "Epoch 423/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5998 - accuracy: 0.6524 - val_loss: 0.5757 - val_accuracy: 0.6575\n",
            "Epoch 424/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5964 - accuracy: 0.6569 - val_loss: 0.5597 - val_accuracy: 0.6975\n",
            "Epoch 425/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5966 - accuracy: 0.6624 - val_loss: 0.5590 - val_accuracy: 0.6950\n",
            "Epoch 426/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5976 - accuracy: 0.6639 - val_loss: 0.5890 - val_accuracy: 0.6488\n",
            "Epoch 427/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5966 - accuracy: 0.6572 - val_loss: 0.5569 - val_accuracy: 0.6900\n",
            "Epoch 428/1000\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5980 - accuracy: 0.6594 - val_loss: 0.5733 - val_accuracy: 0.6712\n",
            "Epoch 429/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5993 - accuracy: 0.6518 - val_loss: 0.5549 - val_accuracy: 0.6900\n",
            "Epoch 430/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5973 - accuracy: 0.6576 - val_loss: 0.5589 - val_accuracy: 0.7050\n",
            "Epoch 431/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5986 - accuracy: 0.6535 - val_loss: 0.5812 - val_accuracy: 0.6988\n",
            "Epoch 432/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5982 - accuracy: 0.6587 - val_loss: 0.5647 - val_accuracy: 0.6888\n",
            "Epoch 433/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5989 - accuracy: 0.6572 - val_loss: 0.5621 - val_accuracy: 0.7038\n",
            "Epoch 434/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5991 - accuracy: 0.6578 - val_loss: 0.5594 - val_accuracy: 0.6913\n",
            "Epoch 435/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5979 - accuracy: 0.6562 - val_loss: 0.5536 - val_accuracy: 0.6825\n",
            "Epoch 436/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6011 - accuracy: 0.6532 - val_loss: 0.5548 - val_accuracy: 0.6938\n",
            "Epoch 437/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6009 - accuracy: 0.6560 - val_loss: 0.5804 - val_accuracy: 0.6575\n",
            "Epoch 438/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5972 - accuracy: 0.6617 - val_loss: 0.5505 - val_accuracy: 0.6825\n",
            "Epoch 439/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5984 - accuracy: 0.6558 - val_loss: 0.5728 - val_accuracy: 0.6687\n",
            "Epoch 440/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6010 - accuracy: 0.6567 - val_loss: 0.5530 - val_accuracy: 0.6900\n",
            "Epoch 441/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5953 - accuracy: 0.6600 - val_loss: 0.5609 - val_accuracy: 0.7088\n",
            "Epoch 442/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5981 - accuracy: 0.6517 - val_loss: 0.5628 - val_accuracy: 0.7125\n",
            "Epoch 443/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6009 - accuracy: 0.6576 - val_loss: 0.5551 - val_accuracy: 0.6862\n",
            "Epoch 444/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5984 - accuracy: 0.6587 - val_loss: 0.6090 - val_accuracy: 0.6750\n",
            "Epoch 445/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5952 - accuracy: 0.6593 - val_loss: 0.5589 - val_accuracy: 0.7100\n",
            "Epoch 446/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5970 - accuracy: 0.6554 - val_loss: 0.5565 - val_accuracy: 0.6925\n",
            "Epoch 447/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5983 - accuracy: 0.6551 - val_loss: 0.5799 - val_accuracy: 0.6600\n",
            "Epoch 448/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5964 - accuracy: 0.6619 - val_loss: 0.5550 - val_accuracy: 0.6925\n",
            "Epoch 449/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6009 - accuracy: 0.6538 - val_loss: 0.5531 - val_accuracy: 0.6750\n",
            "Epoch 450/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5989 - accuracy: 0.6593 - val_loss: 0.5494 - val_accuracy: 0.6862\n",
            "Epoch 451/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5979 - accuracy: 0.6564 - val_loss: 0.5590 - val_accuracy: 0.6800\n",
            "Epoch 452/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5949 - accuracy: 0.6574 - val_loss: 0.5653 - val_accuracy: 0.6762\n",
            "Epoch 453/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5968 - accuracy: 0.6606 - val_loss: 0.5724 - val_accuracy: 0.6712\n",
            "Epoch 454/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5948 - accuracy: 0.6639 - val_loss: 0.5535 - val_accuracy: 0.6925\n",
            "Epoch 455/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5959 - accuracy: 0.6601 - val_loss: 0.5492 - val_accuracy: 0.6888\n",
            "Epoch 456/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5982 - accuracy: 0.6608 - val_loss: 0.5573 - val_accuracy: 0.7075\n",
            "Epoch 457/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5973 - accuracy: 0.6547 - val_loss: 0.5563 - val_accuracy: 0.7075\n",
            "Epoch 458/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5957 - accuracy: 0.6583 - val_loss: 0.5640 - val_accuracy: 0.6225\n",
            "Epoch 459/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5975 - accuracy: 0.6587 - val_loss: 0.5657 - val_accuracy: 0.6700\n",
            "Epoch 460/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5965 - accuracy: 0.6553 - val_loss: 0.5978 - val_accuracy: 0.6837\n",
            "Epoch 461/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6020 - accuracy: 0.6496 - val_loss: 0.5695 - val_accuracy: 0.6675\n",
            "Epoch 462/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5974 - accuracy: 0.6539 - val_loss: 0.5564 - val_accuracy: 0.6925\n",
            "Epoch 463/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5964 - accuracy: 0.6587 - val_loss: 0.5546 - val_accuracy: 0.6725\n",
            "Epoch 464/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5972 - accuracy: 0.6511 - val_loss: 0.5662 - val_accuracy: 0.6787\n",
            "Epoch 465/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5960 - accuracy: 0.6599 - val_loss: 0.5585 - val_accuracy: 0.7100\n",
            "Epoch 466/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5947 - accuracy: 0.6582 - val_loss: 0.5537 - val_accuracy: 0.6925\n",
            "Epoch 467/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5963 - accuracy: 0.6543 - val_loss: 0.5684 - val_accuracy: 0.6712\n",
            "Epoch 468/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5977 - accuracy: 0.6575 - val_loss: 0.5551 - val_accuracy: 0.6975\n",
            "Epoch 469/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6019 - accuracy: 0.6528 - val_loss: 0.5528 - val_accuracy: 0.6888\n",
            "Epoch 470/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5959 - accuracy: 0.6560 - val_loss: 0.5787 - val_accuracy: 0.6963\n",
            "Epoch 471/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5988 - accuracy: 0.6553 - val_loss: 0.5555 - val_accuracy: 0.7075\n",
            "Epoch 472/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5958 - accuracy: 0.6610 - val_loss: 0.5772 - val_accuracy: 0.6625\n",
            "Epoch 473/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5935 - accuracy: 0.6614 - val_loss: 0.5624 - val_accuracy: 0.6963\n",
            "Epoch 474/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5973 - accuracy: 0.6560 - val_loss: 0.5723 - val_accuracy: 0.6837\n",
            "Epoch 475/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5994 - accuracy: 0.6513 - val_loss: 0.5906 - val_accuracy: 0.6862\n",
            "Epoch 476/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5999 - accuracy: 0.6583 - val_loss: 0.5545 - val_accuracy: 0.6938\n",
            "Epoch 477/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5953 - accuracy: 0.6575 - val_loss: 0.5616 - val_accuracy: 0.6988\n",
            "Epoch 478/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5957 - accuracy: 0.6599 - val_loss: 0.5700 - val_accuracy: 0.6775\n",
            "Epoch 479/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5984 - accuracy: 0.6582 - val_loss: 0.5864 - val_accuracy: 0.6450\n",
            "Epoch 480/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6000 - accuracy: 0.6544 - val_loss: 0.5601 - val_accuracy: 0.6988\n",
            "Epoch 481/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5990 - accuracy: 0.6572 - val_loss: 0.5685 - val_accuracy: 0.6750\n",
            "Epoch 482/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6017 - accuracy: 0.6532 - val_loss: 0.5810 - val_accuracy: 0.6650\n",
            "Epoch 483/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5944 - accuracy: 0.6599 - val_loss: 0.5605 - val_accuracy: 0.6950\n",
            "Epoch 484/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5935 - accuracy: 0.6612 - val_loss: 0.5571 - val_accuracy: 0.7025\n",
            "Epoch 485/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5939 - accuracy: 0.6610 - val_loss: 0.5477 - val_accuracy: 0.6913\n",
            "Epoch 486/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5974 - accuracy: 0.6569 - val_loss: 0.5913 - val_accuracy: 0.6750\n",
            "Epoch 487/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5966 - accuracy: 0.6564 - val_loss: 0.5662 - val_accuracy: 0.6862\n",
            "Epoch 488/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5946 - accuracy: 0.6626 - val_loss: 0.5678 - val_accuracy: 0.7038\n",
            "Epoch 489/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5974 - accuracy: 0.6550 - val_loss: 0.5586 - val_accuracy: 0.7013\n",
            "Epoch 490/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5975 - accuracy: 0.6569 - val_loss: 0.5830 - val_accuracy: 0.6575\n",
            "Epoch 491/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5946 - accuracy: 0.6575 - val_loss: 0.5532 - val_accuracy: 0.6737\n",
            "Epoch 492/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5935 - accuracy: 0.6592 - val_loss: 0.5672 - val_accuracy: 0.6862\n",
            "Epoch 493/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5929 - accuracy: 0.6622 - val_loss: 0.5912 - val_accuracy: 0.6825\n",
            "Epoch 494/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5950 - accuracy: 0.6617 - val_loss: 0.5625 - val_accuracy: 0.6800\n",
            "Epoch 495/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5961 - accuracy: 0.6612 - val_loss: 0.5552 - val_accuracy: 0.6737\n",
            "Epoch 496/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5992 - accuracy: 0.6592 - val_loss: 0.5700 - val_accuracy: 0.6825\n",
            "Epoch 497/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5967 - accuracy: 0.6626 - val_loss: 0.5541 - val_accuracy: 0.6900\n",
            "Epoch 498/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5928 - accuracy: 0.6604 - val_loss: 0.5605 - val_accuracy: 0.7038\n",
            "Epoch 499/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5955 - accuracy: 0.6583 - val_loss: 0.5616 - val_accuracy: 0.6888\n",
            "Epoch 500/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5934 - accuracy: 0.6619 - val_loss: 0.5623 - val_accuracy: 0.6775\n",
            "Epoch 501/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5994 - accuracy: 0.6561 - val_loss: 0.5512 - val_accuracy: 0.6988\n",
            "Epoch 502/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6003 - accuracy: 0.6557 - val_loss: 0.5501 - val_accuracy: 0.6913\n",
            "Epoch 503/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5951 - accuracy: 0.6565 - val_loss: 0.5531 - val_accuracy: 0.6950\n",
            "Epoch 504/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5973 - accuracy: 0.6543 - val_loss: 0.5477 - val_accuracy: 0.6900\n",
            "Epoch 505/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5957 - accuracy: 0.6583 - val_loss: 0.5566 - val_accuracy: 0.7138\n",
            "Epoch 506/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5971 - accuracy: 0.6575 - val_loss: 0.5581 - val_accuracy: 0.6975\n",
            "Epoch 507/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5946 - accuracy: 0.6576 - val_loss: 0.5642 - val_accuracy: 0.6800\n",
            "Epoch 508/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5959 - accuracy: 0.6532 - val_loss: 0.5552 - val_accuracy: 0.6988\n",
            "Epoch 509/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5960 - accuracy: 0.6590 - val_loss: 0.5746 - val_accuracy: 0.6762\n",
            "Epoch 510/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5933 - accuracy: 0.6640 - val_loss: 0.6107 - val_accuracy: 0.6687\n",
            "Epoch 511/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5936 - accuracy: 0.6633 - val_loss: 0.5605 - val_accuracy: 0.6900\n",
            "Epoch 512/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5958 - accuracy: 0.6599 - val_loss: 0.5690 - val_accuracy: 0.6800\n",
            "Epoch 513/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5945 - accuracy: 0.6601 - val_loss: 0.5483 - val_accuracy: 0.6913\n",
            "Epoch 514/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5951 - accuracy: 0.6633 - val_loss: 0.5594 - val_accuracy: 0.6900\n",
            "Epoch 515/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5936 - accuracy: 0.6594 - val_loss: 0.5729 - val_accuracy: 0.6712\n",
            "Epoch 516/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5934 - accuracy: 0.6567 - val_loss: 0.5752 - val_accuracy: 0.6675\n",
            "Epoch 517/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5916 - accuracy: 0.6610 - val_loss: 0.5688 - val_accuracy: 0.6875\n",
            "Epoch 518/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5944 - accuracy: 0.6594 - val_loss: 0.5562 - val_accuracy: 0.6988\n",
            "Epoch 519/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5956 - accuracy: 0.6596 - val_loss: 0.5520 - val_accuracy: 0.6900\n",
            "Epoch 520/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5944 - accuracy: 0.6600 - val_loss: 0.5815 - val_accuracy: 0.6913\n",
            "Epoch 521/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5919 - accuracy: 0.6633 - val_loss: 0.6044 - val_accuracy: 0.6800\n",
            "Epoch 522/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5960 - accuracy: 0.6624 - val_loss: 0.5548 - val_accuracy: 0.6900\n",
            "Epoch 523/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5953 - accuracy: 0.6567 - val_loss: 0.5603 - val_accuracy: 0.6938\n",
            "Epoch 524/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5926 - accuracy: 0.6631 - val_loss: 0.5533 - val_accuracy: 0.7138\n",
            "Epoch 525/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5969 - accuracy: 0.6546 - val_loss: 0.5866 - val_accuracy: 0.6850\n",
            "Epoch 526/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5937 - accuracy: 0.6569 - val_loss: 0.5565 - val_accuracy: 0.7000\n",
            "Epoch 527/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5960 - accuracy: 0.6585 - val_loss: 0.6310 - val_accuracy: 0.6637\n",
            "Epoch 528/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5996 - accuracy: 0.6585 - val_loss: 0.5885 - val_accuracy: 0.6463\n",
            "Epoch 529/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5955 - accuracy: 0.6594 - val_loss: 0.5623 - val_accuracy: 0.6837\n",
            "Epoch 530/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5928 - accuracy: 0.6583 - val_loss: 0.5558 - val_accuracy: 0.7138\n",
            "Epoch 531/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5956 - accuracy: 0.6622 - val_loss: 0.5678 - val_accuracy: 0.6812\n",
            "Epoch 532/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5914 - accuracy: 0.6646 - val_loss: 0.5513 - val_accuracy: 0.6938\n",
            "Epoch 533/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5966 - accuracy: 0.6594 - val_loss: 0.5962 - val_accuracy: 0.6825\n",
            "Epoch 534/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5954 - accuracy: 0.6647 - val_loss: 0.5574 - val_accuracy: 0.6963\n",
            "Epoch 535/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5956 - accuracy: 0.6635 - val_loss: 0.5684 - val_accuracy: 0.7175\n",
            "Epoch 536/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5936 - accuracy: 0.6600 - val_loss: 0.5633 - val_accuracy: 0.6762\n",
            "Epoch 537/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5948 - accuracy: 0.6607 - val_loss: 0.5967 - val_accuracy: 0.6888\n",
            "Epoch 538/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5939 - accuracy: 0.6622 - val_loss: 0.5795 - val_accuracy: 0.6712\n",
            "Epoch 539/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5943 - accuracy: 0.6636 - val_loss: 0.5653 - val_accuracy: 0.6837\n",
            "Epoch 540/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5946 - accuracy: 0.6617 - val_loss: 0.5505 - val_accuracy: 0.6862\n",
            "Epoch 541/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5955 - accuracy: 0.6535 - val_loss: 0.5721 - val_accuracy: 0.6750\n",
            "Epoch 542/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5912 - accuracy: 0.6644 - val_loss: 0.5865 - val_accuracy: 0.6625\n",
            "Epoch 543/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5940 - accuracy: 0.6579 - val_loss: 0.5652 - val_accuracy: 0.6888\n",
            "Epoch 544/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5954 - accuracy: 0.6558 - val_loss: 0.6177 - val_accuracy: 0.6637\n",
            "Epoch 545/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5969 - accuracy: 0.6590 - val_loss: 0.5594 - val_accuracy: 0.6975\n",
            "Epoch 546/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5970 - accuracy: 0.6604 - val_loss: 0.6052 - val_accuracy: 0.6787\n",
            "Epoch 547/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5957 - accuracy: 0.6611 - val_loss: 0.5904 - val_accuracy: 0.6525\n",
            "Epoch 548/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5957 - accuracy: 0.6587 - val_loss: 0.5539 - val_accuracy: 0.7050\n",
            "Epoch 549/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5936 - accuracy: 0.6586 - val_loss: 0.5666 - val_accuracy: 0.6725\n",
            "Epoch 550/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5928 - accuracy: 0.6596 - val_loss: 0.6149 - val_accuracy: 0.6612\n",
            "Epoch 551/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5955 - accuracy: 0.6640 - val_loss: 0.5442 - val_accuracy: 0.6913\n",
            "Epoch 552/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5922 - accuracy: 0.6617 - val_loss: 0.6104 - val_accuracy: 0.6725\n",
            "Epoch 553/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5946 - accuracy: 0.6600 - val_loss: 0.5487 - val_accuracy: 0.6913\n",
            "Epoch 554/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5902 - accuracy: 0.6622 - val_loss: 0.5505 - val_accuracy: 0.7075\n",
            "Epoch 555/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5933 - accuracy: 0.6600 - val_loss: 0.5783 - val_accuracy: 0.6938\n",
            "Epoch 556/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5925 - accuracy: 0.6607 - val_loss: 0.5464 - val_accuracy: 0.6988\n",
            "Epoch 557/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5940 - accuracy: 0.6629 - val_loss: 0.5984 - val_accuracy: 0.6862\n",
            "Epoch 558/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5923 - accuracy: 0.6596 - val_loss: 0.5637 - val_accuracy: 0.6800\n",
            "Epoch 559/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5938 - accuracy: 0.6604 - val_loss: 0.5834 - val_accuracy: 0.6875\n",
            "Epoch 560/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5937 - accuracy: 0.6619 - val_loss: 0.5565 - val_accuracy: 0.6375\n",
            "Epoch 561/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5948 - accuracy: 0.6675 - val_loss: 0.5470 - val_accuracy: 0.6938\n",
            "Epoch 562/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5917 - accuracy: 0.6628 - val_loss: 0.5597 - val_accuracy: 0.6825\n",
            "Epoch 563/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5943 - accuracy: 0.6601 - val_loss: 0.5488 - val_accuracy: 0.6925\n",
            "Epoch 564/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5941 - accuracy: 0.6581 - val_loss: 0.5795 - val_accuracy: 0.6700\n",
            "Epoch 565/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5939 - accuracy: 0.6631 - val_loss: 0.5590 - val_accuracy: 0.6812\n",
            "Epoch 566/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5906 - accuracy: 0.6683 - val_loss: 0.5862 - val_accuracy: 0.6675\n",
            "Epoch 567/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5963 - accuracy: 0.6603 - val_loss: 0.5688 - val_accuracy: 0.6762\n",
            "Epoch 568/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5925 - accuracy: 0.6644 - val_loss: 0.5818 - val_accuracy: 0.6637\n",
            "Epoch 569/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5918 - accuracy: 0.6625 - val_loss: 0.5868 - val_accuracy: 0.6475\n",
            "Epoch 570/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5926 - accuracy: 0.6656 - val_loss: 0.5476 - val_accuracy: 0.7038\n",
            "Epoch 571/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5951 - accuracy: 0.6587 - val_loss: 0.5769 - val_accuracy: 0.6637\n",
            "Epoch 572/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5908 - accuracy: 0.6589 - val_loss: 0.5532 - val_accuracy: 0.7063\n",
            "Epoch 573/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5941 - accuracy: 0.6619 - val_loss: 0.5467 - val_accuracy: 0.6925\n",
            "Epoch 574/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5940 - accuracy: 0.6679 - val_loss: 0.5488 - val_accuracy: 0.6913\n",
            "Epoch 575/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5920 - accuracy: 0.6618 - val_loss: 0.5723 - val_accuracy: 0.7088\n",
            "Epoch 576/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5944 - accuracy: 0.6636 - val_loss: 0.5756 - val_accuracy: 0.6662\n",
            "Epoch 577/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5937 - accuracy: 0.6610 - val_loss: 0.5643 - val_accuracy: 0.6812\n",
            "Epoch 578/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5945 - accuracy: 0.6571 - val_loss: 0.5543 - val_accuracy: 0.6500\n",
            "Epoch 579/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5890 - accuracy: 0.6703 - val_loss: 0.5486 - val_accuracy: 0.6950\n",
            "Epoch 580/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5941 - accuracy: 0.6590 - val_loss: 0.5512 - val_accuracy: 0.6988\n",
            "Epoch 581/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5968 - accuracy: 0.6621 - val_loss: 0.5569 - val_accuracy: 0.6375\n",
            "Epoch 582/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5940 - accuracy: 0.6679 - val_loss: 0.5502 - val_accuracy: 0.6925\n",
            "Epoch 583/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5962 - accuracy: 0.6581 - val_loss: 0.5506 - val_accuracy: 0.7125\n",
            "Epoch 584/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5922 - accuracy: 0.6664 - val_loss: 0.5518 - val_accuracy: 0.7025\n",
            "Epoch 585/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5906 - accuracy: 0.6649 - val_loss: 0.5648 - val_accuracy: 0.6787\n",
            "Epoch 586/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5912 - accuracy: 0.6643 - val_loss: 0.5619 - val_accuracy: 0.6775\n",
            "Epoch 587/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5929 - accuracy: 0.6607 - val_loss: 0.5692 - val_accuracy: 0.6950\n",
            "Epoch 588/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5929 - accuracy: 0.6621 - val_loss: 0.5940 - val_accuracy: 0.6888\n",
            "Epoch 589/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5937 - accuracy: 0.6619 - val_loss: 0.5520 - val_accuracy: 0.6463\n",
            "Epoch 590/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5909 - accuracy: 0.6682 - val_loss: 0.5686 - val_accuracy: 0.6812\n",
            "Epoch 591/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5947 - accuracy: 0.6640 - val_loss: 0.5822 - val_accuracy: 0.6913\n",
            "Epoch 592/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5924 - accuracy: 0.6657 - val_loss: 0.5566 - val_accuracy: 0.7100\n",
            "Epoch 593/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5922 - accuracy: 0.6647 - val_loss: 0.5480 - val_accuracy: 0.6762\n",
            "Epoch 594/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5922 - accuracy: 0.6629 - val_loss: 0.5520 - val_accuracy: 0.7013\n",
            "Epoch 595/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5918 - accuracy: 0.6625 - val_loss: 0.5538 - val_accuracy: 0.7150\n",
            "Epoch 596/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5961 - accuracy: 0.6532 - val_loss: 0.5481 - val_accuracy: 0.7075\n",
            "Epoch 597/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5963 - accuracy: 0.6560 - val_loss: 0.5440 - val_accuracy: 0.7000\n",
            "Epoch 598/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5920 - accuracy: 0.6614 - val_loss: 0.5509 - val_accuracy: 0.7100\n",
            "Epoch 599/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5907 - accuracy: 0.6668 - val_loss: 0.5537 - val_accuracy: 0.6988\n",
            "Epoch 600/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5922 - accuracy: 0.6642 - val_loss: 0.5693 - val_accuracy: 0.6787\n",
            "Epoch 601/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5903 - accuracy: 0.6662 - val_loss: 0.5800 - val_accuracy: 0.6687\n",
            "Epoch 602/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5930 - accuracy: 0.6660 - val_loss: 0.5609 - val_accuracy: 0.6925\n",
            "Epoch 603/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5906 - accuracy: 0.6650 - val_loss: 0.5685 - val_accuracy: 0.6900\n",
            "Epoch 604/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5909 - accuracy: 0.6693 - val_loss: 0.5477 - val_accuracy: 0.6963\n",
            "Epoch 605/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5913 - accuracy: 0.6643 - val_loss: 0.5555 - val_accuracy: 0.6988\n",
            "Epoch 606/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5956 - accuracy: 0.6565 - val_loss: 0.5518 - val_accuracy: 0.7163\n",
            "Epoch 607/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5907 - accuracy: 0.6649 - val_loss: 0.5533 - val_accuracy: 0.7138\n",
            "Epoch 608/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5947 - accuracy: 0.6664 - val_loss: 0.5445 - val_accuracy: 0.7050\n",
            "Epoch 609/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5964 - accuracy: 0.6600 - val_loss: 0.5640 - val_accuracy: 0.6750\n",
            "Epoch 610/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5902 - accuracy: 0.6654 - val_loss: 0.5447 - val_accuracy: 0.6925\n",
            "Epoch 611/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5943 - accuracy: 0.6656 - val_loss: 0.5468 - val_accuracy: 0.6900\n",
            "Epoch 612/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5922 - accuracy: 0.6614 - val_loss: 0.5512 - val_accuracy: 0.7113\n",
            "Epoch 613/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5918 - accuracy: 0.6644 - val_loss: 0.5482 - val_accuracy: 0.6975\n",
            "Epoch 614/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5931 - accuracy: 0.6660 - val_loss: 0.5482 - val_accuracy: 0.7000\n",
            "Epoch 615/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5918 - accuracy: 0.6644 - val_loss: 0.5600 - val_accuracy: 0.6725\n",
            "Epoch 616/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5893 - accuracy: 0.6694 - val_loss: 0.5692 - val_accuracy: 0.6975\n",
            "Epoch 617/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5899 - accuracy: 0.6669 - val_loss: 0.5716 - val_accuracy: 0.6725\n",
            "Epoch 618/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5941 - accuracy: 0.6669 - val_loss: 0.5474 - val_accuracy: 0.6938\n",
            "Epoch 619/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5946 - accuracy: 0.6611 - val_loss: 0.5445 - val_accuracy: 0.7088\n",
            "Epoch 620/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5917 - accuracy: 0.6628 - val_loss: 0.5493 - val_accuracy: 0.7038\n",
            "Epoch 621/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5898 - accuracy: 0.6689 - val_loss: 0.5577 - val_accuracy: 0.6837\n",
            "Epoch 622/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5934 - accuracy: 0.6610 - val_loss: 0.5636 - val_accuracy: 0.6762\n",
            "Epoch 623/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5934 - accuracy: 0.6611 - val_loss: 0.5491 - val_accuracy: 0.7075\n",
            "Epoch 624/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5901 - accuracy: 0.6671 - val_loss: 0.6275 - val_accuracy: 0.6612\n",
            "Epoch 625/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5919 - accuracy: 0.6669 - val_loss: 0.5792 - val_accuracy: 0.6900\n",
            "Epoch 626/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5930 - accuracy: 0.6594 - val_loss: 0.5536 - val_accuracy: 0.6187\n",
            "Epoch 627/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5966 - accuracy: 0.6592 - val_loss: 0.5654 - val_accuracy: 0.7200\n",
            "Epoch 628/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5912 - accuracy: 0.6679 - val_loss: 0.5503 - val_accuracy: 0.7063\n",
            "Epoch 629/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5929 - accuracy: 0.6589 - val_loss: 0.5523 - val_accuracy: 0.6975\n",
            "Epoch 630/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5943 - accuracy: 0.6678 - val_loss: 0.5593 - val_accuracy: 0.7000\n",
            "Epoch 631/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5920 - accuracy: 0.6639 - val_loss: 0.5573 - val_accuracy: 0.6825\n",
            "Epoch 632/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5910 - accuracy: 0.6644 - val_loss: 0.5407 - val_accuracy: 0.6963\n",
            "Epoch 633/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5905 - accuracy: 0.6724 - val_loss: 0.5487 - val_accuracy: 0.7000\n",
            "Epoch 634/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5918 - accuracy: 0.6606 - val_loss: 0.5472 - val_accuracy: 0.6963\n",
            "Epoch 635/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5942 - accuracy: 0.6612 - val_loss: 0.5736 - val_accuracy: 0.7125\n",
            "Epoch 636/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5942 - accuracy: 0.6667 - val_loss: 0.5642 - val_accuracy: 0.6762\n",
            "Epoch 637/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5929 - accuracy: 0.6610 - val_loss: 0.5676 - val_accuracy: 0.6862\n",
            "Epoch 638/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5921 - accuracy: 0.6664 - val_loss: 0.5624 - val_accuracy: 0.7000\n",
            "Epoch 639/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5891 - accuracy: 0.6697 - val_loss: 0.5721 - val_accuracy: 0.7063\n",
            "Epoch 640/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5873 - accuracy: 0.6687 - val_loss: 0.5526 - val_accuracy: 0.7013\n",
            "Epoch 641/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5965 - accuracy: 0.6626 - val_loss: 0.5456 - val_accuracy: 0.6975\n",
            "Epoch 642/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5889 - accuracy: 0.6665 - val_loss: 0.6048 - val_accuracy: 0.6812\n",
            "Epoch 643/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5883 - accuracy: 0.6665 - val_loss: 0.5484 - val_accuracy: 0.7075\n",
            "Epoch 644/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5902 - accuracy: 0.6642 - val_loss: 0.5459 - val_accuracy: 0.6950\n",
            "Epoch 645/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5903 - accuracy: 0.6710 - val_loss: 0.5450 - val_accuracy: 0.7088\n",
            "Epoch 646/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5880 - accuracy: 0.6707 - val_loss: 0.5522 - val_accuracy: 0.7013\n",
            "Epoch 647/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5944 - accuracy: 0.6649 - val_loss: 0.5640 - val_accuracy: 0.6787\n",
            "Epoch 648/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5942 - accuracy: 0.6618 - val_loss: 0.5443 - val_accuracy: 0.6938\n",
            "Epoch 649/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5905 - accuracy: 0.6717 - val_loss: 0.5512 - val_accuracy: 0.7538\n",
            "Epoch 650/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5926 - accuracy: 0.6690 - val_loss: 0.5480 - val_accuracy: 0.7125\n",
            "Epoch 651/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5900 - accuracy: 0.6615 - val_loss: 0.5775 - val_accuracy: 0.7000\n",
            "Epoch 652/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5922 - accuracy: 0.6660 - val_loss: 0.5446 - val_accuracy: 0.6988\n",
            "Epoch 653/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5898 - accuracy: 0.6658 - val_loss: 0.5629 - val_accuracy: 0.7212\n",
            "Epoch 654/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5917 - accuracy: 0.6606 - val_loss: 0.5532 - val_accuracy: 0.6888\n",
            "Epoch 655/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5915 - accuracy: 0.6590 - val_loss: 0.5571 - val_accuracy: 0.6963\n",
            "Epoch 656/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5896 - accuracy: 0.6662 - val_loss: 0.5554 - val_accuracy: 0.6850\n",
            "Epoch 657/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5889 - accuracy: 0.6662 - val_loss: 0.5652 - val_accuracy: 0.7175\n",
            "Epoch 658/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5895 - accuracy: 0.6694 - val_loss: 0.5427 - val_accuracy: 0.6925\n",
            "Epoch 659/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5934 - accuracy: 0.6618 - val_loss: 0.5517 - val_accuracy: 0.7063\n",
            "Epoch 660/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5874 - accuracy: 0.6697 - val_loss: 0.5602 - val_accuracy: 0.6837\n",
            "Epoch 661/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5926 - accuracy: 0.6622 - val_loss: 0.5714 - val_accuracy: 0.6625\n",
            "Epoch 662/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5967 - accuracy: 0.6547 - val_loss: 0.5440 - val_accuracy: 0.6925\n",
            "Epoch 663/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5876 - accuracy: 0.6647 - val_loss: 0.5424 - val_accuracy: 0.6938\n",
            "Epoch 664/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5911 - accuracy: 0.6636 - val_loss: 0.5643 - val_accuracy: 0.6850\n",
            "Epoch 665/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5875 - accuracy: 0.6685 - val_loss: 0.5824 - val_accuracy: 0.6837\n",
            "Epoch 666/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5904 - accuracy: 0.6697 - val_loss: 0.5410 - val_accuracy: 0.7000\n",
            "Epoch 667/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5901 - accuracy: 0.6619 - val_loss: 0.5423 - val_accuracy: 0.7063\n",
            "Epoch 668/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5924 - accuracy: 0.6637 - val_loss: 0.5744 - val_accuracy: 0.6625\n",
            "Epoch 669/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5888 - accuracy: 0.6642 - val_loss: 0.5636 - val_accuracy: 0.7163\n",
            "Epoch 670/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5914 - accuracy: 0.6621 - val_loss: 0.5568 - val_accuracy: 0.7125\n",
            "Epoch 671/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5901 - accuracy: 0.6632 - val_loss: 0.6022 - val_accuracy: 0.6787\n",
            "Epoch 672/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5915 - accuracy: 0.6664 - val_loss: 0.5456 - val_accuracy: 0.7075\n",
            "Epoch 673/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5917 - accuracy: 0.6642 - val_loss: 0.5458 - val_accuracy: 0.6862\n",
            "Epoch 674/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5921 - accuracy: 0.6597 - val_loss: 0.5586 - val_accuracy: 0.6837\n",
            "Epoch 675/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5920 - accuracy: 0.6643 - val_loss: 0.5623 - val_accuracy: 0.6837\n",
            "Epoch 676/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5894 - accuracy: 0.6629 - val_loss: 0.5714 - val_accuracy: 0.7138\n",
            "Epoch 677/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5887 - accuracy: 0.6690 - val_loss: 0.5414 - val_accuracy: 0.6963\n",
            "Epoch 678/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5954 - accuracy: 0.6649 - val_loss: 0.5519 - val_accuracy: 0.6950\n",
            "Epoch 679/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5892 - accuracy: 0.6651 - val_loss: 0.5431 - val_accuracy: 0.6950\n",
            "Epoch 680/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5895 - accuracy: 0.6667 - val_loss: 0.5441 - val_accuracy: 0.7038\n",
            "Epoch 681/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5915 - accuracy: 0.6683 - val_loss: 0.5622 - val_accuracy: 0.7025\n",
            "Epoch 682/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5972 - accuracy: 0.6611 - val_loss: 0.5474 - val_accuracy: 0.7000\n",
            "Epoch 683/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5880 - accuracy: 0.6689 - val_loss: 0.5525 - val_accuracy: 0.7000\n",
            "Epoch 684/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5881 - accuracy: 0.6715 - val_loss: 0.5614 - val_accuracy: 0.6825\n",
            "Epoch 685/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5915 - accuracy: 0.6654 - val_loss: 0.5499 - val_accuracy: 0.7025\n",
            "Epoch 686/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5867 - accuracy: 0.6719 - val_loss: 0.5931 - val_accuracy: 0.6862\n",
            "Epoch 687/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5894 - accuracy: 0.6635 - val_loss: 0.5694 - val_accuracy: 0.6737\n",
            "Epoch 688/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5912 - accuracy: 0.6671 - val_loss: 0.6104 - val_accuracy: 0.6737\n",
            "Epoch 689/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5931 - accuracy: 0.6607 - val_loss: 0.5420 - val_accuracy: 0.6938\n",
            "Epoch 690/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5893 - accuracy: 0.6657 - val_loss: 0.5556 - val_accuracy: 0.6950\n",
            "Epoch 691/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5902 - accuracy: 0.6671 - val_loss: 0.5633 - val_accuracy: 0.6725\n",
            "Epoch 692/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5863 - accuracy: 0.6710 - val_loss: 0.5684 - val_accuracy: 0.6888\n",
            "Epoch 693/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5907 - accuracy: 0.6662 - val_loss: 0.5457 - val_accuracy: 0.7075\n",
            "Epoch 694/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5895 - accuracy: 0.6639 - val_loss: 0.5426 - val_accuracy: 0.6950\n",
            "Epoch 695/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5913 - accuracy: 0.6650 - val_loss: 0.5539 - val_accuracy: 0.6925\n",
            "Epoch 696/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5910 - accuracy: 0.6610 - val_loss: 0.5592 - val_accuracy: 0.6888\n",
            "Epoch 697/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5930 - accuracy: 0.6633 - val_loss: 0.5382 - val_accuracy: 0.7063\n",
            "Epoch 698/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5869 - accuracy: 0.6696 - val_loss: 0.5443 - val_accuracy: 0.7050\n",
            "Epoch 699/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5871 - accuracy: 0.6715 - val_loss: 0.5507 - val_accuracy: 0.6963\n",
            "Epoch 700/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5897 - accuracy: 0.6669 - val_loss: 0.5605 - val_accuracy: 0.6787\n",
            "Epoch 701/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5916 - accuracy: 0.6643 - val_loss: 0.5779 - val_accuracy: 0.6988\n",
            "Epoch 702/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5901 - accuracy: 0.6646 - val_loss: 0.5386 - val_accuracy: 0.7013\n",
            "Epoch 703/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5963 - accuracy: 0.6612 - val_loss: 0.5575 - val_accuracy: 0.6850\n",
            "Epoch 704/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5919 - accuracy: 0.6671 - val_loss: 0.5549 - val_accuracy: 0.6875\n",
            "Epoch 705/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5889 - accuracy: 0.6656 - val_loss: 0.5414 - val_accuracy: 0.7000\n",
            "Epoch 706/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5904 - accuracy: 0.6631 - val_loss: 0.5447 - val_accuracy: 0.6950\n",
            "Epoch 707/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5893 - accuracy: 0.6676 - val_loss: 0.5624 - val_accuracy: 0.6800\n",
            "Epoch 708/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5857 - accuracy: 0.6712 - val_loss: 0.5496 - val_accuracy: 0.6963\n",
            "Epoch 709/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5890 - accuracy: 0.6700 - val_loss: 0.5758 - val_accuracy: 0.6938\n",
            "Epoch 710/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5874 - accuracy: 0.6644 - val_loss: 0.5429 - val_accuracy: 0.6988\n",
            "Epoch 711/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5887 - accuracy: 0.6692 - val_loss: 0.5387 - val_accuracy: 0.6988\n",
            "Epoch 712/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5939 - accuracy: 0.6629 - val_loss: 0.5809 - val_accuracy: 0.6900\n",
            "Epoch 713/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5896 - accuracy: 0.6647 - val_loss: 0.5709 - val_accuracy: 0.7038\n",
            "Epoch 714/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5895 - accuracy: 0.6650 - val_loss: 0.5428 - val_accuracy: 0.7050\n",
            "Epoch 715/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5897 - accuracy: 0.6715 - val_loss: 0.5413 - val_accuracy: 0.6963\n",
            "Epoch 716/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5906 - accuracy: 0.6660 - val_loss: 0.5506 - val_accuracy: 0.6938\n",
            "Epoch 717/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5880 - accuracy: 0.6689 - val_loss: 0.5510 - val_accuracy: 0.6963\n",
            "Epoch 718/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5891 - accuracy: 0.6665 - val_loss: 0.5463 - val_accuracy: 0.7038\n",
            "Epoch 719/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5901 - accuracy: 0.6664 - val_loss: 0.5502 - val_accuracy: 0.6975\n",
            "Epoch 720/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5856 - accuracy: 0.6712 - val_loss: 0.5722 - val_accuracy: 0.7050\n",
            "Epoch 721/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5924 - accuracy: 0.6597 - val_loss: 0.5449 - val_accuracy: 0.6800\n",
            "Epoch 722/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5950 - accuracy: 0.6621 - val_loss: 0.5418 - val_accuracy: 0.6975\n",
            "Epoch 723/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5892 - accuracy: 0.6686 - val_loss: 0.5451 - val_accuracy: 0.7100\n",
            "Epoch 724/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5891 - accuracy: 0.6681 - val_loss: 0.5602 - val_accuracy: 0.6825\n",
            "Epoch 725/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5914 - accuracy: 0.6636 - val_loss: 0.5423 - val_accuracy: 0.7075\n",
            "Epoch 726/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5890 - accuracy: 0.6664 - val_loss: 0.5481 - val_accuracy: 0.6438\n",
            "Epoch 727/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5890 - accuracy: 0.6683 - val_loss: 0.5548 - val_accuracy: 0.6837\n",
            "Epoch 728/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5892 - accuracy: 0.6647 - val_loss: 0.5432 - val_accuracy: 0.7138\n",
            "Epoch 729/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5854 - accuracy: 0.6682 - val_loss: 0.5600 - val_accuracy: 0.7025\n",
            "Epoch 730/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5921 - accuracy: 0.6644 - val_loss: 0.5477 - val_accuracy: 0.7013\n",
            "Epoch 731/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5892 - accuracy: 0.6729 - val_loss: 0.5495 - val_accuracy: 0.6963\n",
            "Epoch 732/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5911 - accuracy: 0.6629 - val_loss: 0.5524 - val_accuracy: 0.6975\n",
            "Epoch 733/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5893 - accuracy: 0.6635 - val_loss: 0.5511 - val_accuracy: 0.7000\n",
            "Epoch 734/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5867 - accuracy: 0.6667 - val_loss: 0.5426 - val_accuracy: 0.7150\n",
            "Epoch 735/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5857 - accuracy: 0.6694 - val_loss: 0.5426 - val_accuracy: 0.7000\n",
            "Epoch 736/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5873 - accuracy: 0.6683 - val_loss: 0.5583 - val_accuracy: 0.6812\n",
            "Epoch 737/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5902 - accuracy: 0.6542 - val_loss: 0.5558 - val_accuracy: 0.6875\n",
            "Epoch 738/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5892 - accuracy: 0.6710 - val_loss: 0.5585 - val_accuracy: 0.6837\n",
            "Epoch 739/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5914 - accuracy: 0.6654 - val_loss: 0.5762 - val_accuracy: 0.6975\n",
            "Epoch 740/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5869 - accuracy: 0.6724 - val_loss: 0.5593 - val_accuracy: 0.6837\n",
            "Epoch 741/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5898 - accuracy: 0.6660 - val_loss: 0.5681 - val_accuracy: 0.7100\n",
            "Epoch 742/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5882 - accuracy: 0.6722 - val_loss: 0.5817 - val_accuracy: 0.6950\n",
            "Epoch 743/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5892 - accuracy: 0.6711 - val_loss: 0.5405 - val_accuracy: 0.7000\n",
            "Epoch 744/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5847 - accuracy: 0.6728 - val_loss: 0.5393 - val_accuracy: 0.7113\n",
            "Epoch 745/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5886 - accuracy: 0.6642 - val_loss: 0.5461 - val_accuracy: 0.7100\n",
            "Epoch 746/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5915 - accuracy: 0.6664 - val_loss: 0.5624 - val_accuracy: 0.6762\n",
            "Epoch 747/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5863 - accuracy: 0.6701 - val_loss: 0.5604 - val_accuracy: 0.6787\n",
            "Epoch 748/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5869 - accuracy: 0.6668 - val_loss: 0.5423 - val_accuracy: 0.7000\n",
            "Epoch 749/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5884 - accuracy: 0.6682 - val_loss: 0.5604 - val_accuracy: 0.6812\n",
            "Epoch 750/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5889 - accuracy: 0.6675 - val_loss: 0.5457 - val_accuracy: 0.7038\n",
            "Epoch 751/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5881 - accuracy: 0.6665 - val_loss: 0.5527 - val_accuracy: 0.6900\n",
            "Epoch 752/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5887 - accuracy: 0.6714 - val_loss: 0.5818 - val_accuracy: 0.6950\n",
            "Epoch 753/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5902 - accuracy: 0.6617 - val_loss: 0.5422 - val_accuracy: 0.7113\n",
            "Epoch 754/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5880 - accuracy: 0.6672 - val_loss: 0.5446 - val_accuracy: 0.7013\n",
            "Epoch 755/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5909 - accuracy: 0.6708 - val_loss: 0.5402 - val_accuracy: 0.7025\n",
            "Epoch 756/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5846 - accuracy: 0.6724 - val_loss: 0.5461 - val_accuracy: 0.7150\n",
            "Epoch 757/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5893 - accuracy: 0.6674 - val_loss: 0.5446 - val_accuracy: 0.7175\n",
            "Epoch 758/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5887 - accuracy: 0.6692 - val_loss: 0.5797 - val_accuracy: 0.7000\n",
            "Epoch 759/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5862 - accuracy: 0.6667 - val_loss: 0.5390 - val_accuracy: 0.7125\n",
            "Epoch 760/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5867 - accuracy: 0.6676 - val_loss: 0.5492 - val_accuracy: 0.6963\n",
            "Epoch 761/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5876 - accuracy: 0.6664 - val_loss: 0.5505 - val_accuracy: 0.6988\n",
            "Epoch 762/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5889 - accuracy: 0.6724 - val_loss: 0.5437 - val_accuracy: 0.7075\n",
            "Epoch 763/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5876 - accuracy: 0.6690 - val_loss: 0.5878 - val_accuracy: 0.6850\n",
            "Epoch 764/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5916 - accuracy: 0.6651 - val_loss: 0.5455 - val_accuracy: 0.7138\n",
            "Epoch 765/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5867 - accuracy: 0.6676 - val_loss: 0.5373 - val_accuracy: 0.7013\n",
            "Epoch 766/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5899 - accuracy: 0.6685 - val_loss: 0.5373 - val_accuracy: 0.7038\n",
            "Epoch 767/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5897 - accuracy: 0.6622 - val_loss: 0.5421 - val_accuracy: 0.6888\n",
            "Epoch 768/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5890 - accuracy: 0.6622 - val_loss: 0.5464 - val_accuracy: 0.7100\n",
            "Epoch 769/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5920 - accuracy: 0.6601 - val_loss: 0.5451 - val_accuracy: 0.7038\n",
            "Epoch 770/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5896 - accuracy: 0.6701 - val_loss: 0.5446 - val_accuracy: 0.7113\n",
            "Epoch 771/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5857 - accuracy: 0.6711 - val_loss: 0.5384 - val_accuracy: 0.6988\n",
            "Epoch 772/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5876 - accuracy: 0.6678 - val_loss: 0.5450 - val_accuracy: 0.7138\n",
            "Epoch 773/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5860 - accuracy: 0.6707 - val_loss: 0.5385 - val_accuracy: 0.6938\n",
            "Epoch 774/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5875 - accuracy: 0.6719 - val_loss: 0.5579 - val_accuracy: 0.6913\n",
            "Epoch 775/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5888 - accuracy: 0.6726 - val_loss: 0.5587 - val_accuracy: 0.6888\n",
            "Epoch 776/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5881 - accuracy: 0.6733 - val_loss: 0.5606 - val_accuracy: 0.7312\n",
            "Epoch 777/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5871 - accuracy: 0.6676 - val_loss: 0.5870 - val_accuracy: 0.6875\n",
            "Epoch 778/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5885 - accuracy: 0.6669 - val_loss: 0.5410 - val_accuracy: 0.7025\n",
            "Epoch 779/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5924 - accuracy: 0.6599 - val_loss: 0.6493 - val_accuracy: 0.6513\n",
            "Epoch 780/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5882 - accuracy: 0.6697 - val_loss: 0.5362 - val_accuracy: 0.6963\n",
            "Epoch 781/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5896 - accuracy: 0.6747 - val_loss: 0.5506 - val_accuracy: 0.6900\n",
            "Epoch 782/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5870 - accuracy: 0.6711 - val_loss: 0.5632 - val_accuracy: 0.6800\n",
            "Epoch 783/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5903 - accuracy: 0.6635 - val_loss: 0.5540 - val_accuracy: 0.6862\n",
            "Epoch 784/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5864 - accuracy: 0.6692 - val_loss: 0.5401 - val_accuracy: 0.7063\n",
            "Epoch 785/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5873 - accuracy: 0.6744 - val_loss: 0.5544 - val_accuracy: 0.6850\n",
            "Epoch 786/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5915 - accuracy: 0.6629 - val_loss: 0.5581 - val_accuracy: 0.6913\n",
            "Epoch 787/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5871 - accuracy: 0.6693 - val_loss: 0.5688 - val_accuracy: 0.7125\n",
            "Epoch 788/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5861 - accuracy: 0.6739 - val_loss: 0.5403 - val_accuracy: 0.7000\n",
            "Epoch 789/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5885 - accuracy: 0.6669 - val_loss: 0.5362 - val_accuracy: 0.6975\n",
            "Epoch 790/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5853 - accuracy: 0.6726 - val_loss: 0.5542 - val_accuracy: 0.6900\n",
            "Epoch 791/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5890 - accuracy: 0.6646 - val_loss: 0.5374 - val_accuracy: 0.7025\n",
            "Epoch 792/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5954 - accuracy: 0.6568 - val_loss: 0.5855 - val_accuracy: 0.6862\n",
            "Epoch 793/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5901 - accuracy: 0.6661 - val_loss: 0.5446 - val_accuracy: 0.7025\n",
            "Epoch 794/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5873 - accuracy: 0.6697 - val_loss: 0.5504 - val_accuracy: 0.6938\n",
            "Epoch 795/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5890 - accuracy: 0.6725 - val_loss: 0.5514 - val_accuracy: 0.6950\n",
            "Epoch 796/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5910 - accuracy: 0.6654 - val_loss: 0.5495 - val_accuracy: 0.6938\n",
            "Epoch 797/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5889 - accuracy: 0.6656 - val_loss: 0.5472 - val_accuracy: 0.6237\n",
            "Epoch 798/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5882 - accuracy: 0.6674 - val_loss: 0.5428 - val_accuracy: 0.7075\n",
            "Epoch 799/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5850 - accuracy: 0.6714 - val_loss: 0.5655 - val_accuracy: 0.7013\n",
            "Epoch 800/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5877 - accuracy: 0.6707 - val_loss: 0.5755 - val_accuracy: 0.6988\n",
            "Epoch 801/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5869 - accuracy: 0.6653 - val_loss: 0.5452 - val_accuracy: 0.7088\n",
            "Epoch 802/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5862 - accuracy: 0.6750 - val_loss: 0.5455 - val_accuracy: 0.7100\n",
            "Epoch 803/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5904 - accuracy: 0.6653 - val_loss: 0.5387 - val_accuracy: 0.7050\n",
            "Epoch 804/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5854 - accuracy: 0.6750 - val_loss: 0.5629 - val_accuracy: 0.6787\n",
            "Epoch 805/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5848 - accuracy: 0.6718 - val_loss: 0.5863 - val_accuracy: 0.6862\n",
            "Epoch 806/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5926 - accuracy: 0.6619 - val_loss: 0.5657 - val_accuracy: 0.6687\n",
            "Epoch 807/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5866 - accuracy: 0.6690 - val_loss: 0.5459 - val_accuracy: 0.7025\n",
            "Epoch 808/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5871 - accuracy: 0.6711 - val_loss: 0.5394 - val_accuracy: 0.7038\n",
            "Epoch 809/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5870 - accuracy: 0.6728 - val_loss: 0.5361 - val_accuracy: 0.7013\n",
            "Epoch 810/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5863 - accuracy: 0.6743 - val_loss: 0.5505 - val_accuracy: 0.6975\n",
            "Epoch 811/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5838 - accuracy: 0.6749 - val_loss: 0.5361 - val_accuracy: 0.7000\n",
            "Epoch 812/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5901 - accuracy: 0.6696 - val_loss: 0.5447 - val_accuracy: 0.6988\n",
            "Epoch 813/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5867 - accuracy: 0.6718 - val_loss: 0.5522 - val_accuracy: 0.6888\n",
            "Epoch 814/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5861 - accuracy: 0.6679 - val_loss: 0.5770 - val_accuracy: 0.6862\n",
            "Epoch 815/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5861 - accuracy: 0.6692 - val_loss: 0.5378 - val_accuracy: 0.7038\n",
            "Epoch 816/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5832 - accuracy: 0.6769 - val_loss: 0.5389 - val_accuracy: 0.6888\n",
            "Epoch 817/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5834 - accuracy: 0.6761 - val_loss: 0.5530 - val_accuracy: 0.6913\n",
            "Epoch 818/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5859 - accuracy: 0.6753 - val_loss: 0.5711 - val_accuracy: 0.6862\n",
            "Epoch 819/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5870 - accuracy: 0.6719 - val_loss: 0.5479 - val_accuracy: 0.6963\n",
            "Epoch 820/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5860 - accuracy: 0.6711 - val_loss: 0.5504 - val_accuracy: 0.6938\n",
            "Epoch 821/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5854 - accuracy: 0.6725 - val_loss: 0.5366 - val_accuracy: 0.7038\n",
            "Epoch 822/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5867 - accuracy: 0.6694 - val_loss: 0.5397 - val_accuracy: 0.7113\n",
            "Epoch 823/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5861 - accuracy: 0.6689 - val_loss: 0.5419 - val_accuracy: 0.6988\n",
            "Epoch 824/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5916 - accuracy: 0.6697 - val_loss: 0.5401 - val_accuracy: 0.7088\n",
            "Epoch 825/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5885 - accuracy: 0.6668 - val_loss: 0.5630 - val_accuracy: 0.7225\n",
            "Epoch 826/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5837 - accuracy: 0.6744 - val_loss: 0.5485 - val_accuracy: 0.6900\n",
            "Epoch 827/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5894 - accuracy: 0.6700 - val_loss: 0.5414 - val_accuracy: 0.7050\n",
            "Epoch 828/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5861 - accuracy: 0.6714 - val_loss: 0.5666 - val_accuracy: 0.7088\n",
            "Epoch 829/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5876 - accuracy: 0.6724 - val_loss: 0.5590 - val_accuracy: 0.6762\n",
            "Epoch 830/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5860 - accuracy: 0.6699 - val_loss: 0.5670 - val_accuracy: 0.7225\n",
            "Epoch 831/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5855 - accuracy: 0.6729 - val_loss: 0.5520 - val_accuracy: 0.6925\n",
            "Epoch 832/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5917 - accuracy: 0.6672 - val_loss: 0.5490 - val_accuracy: 0.6913\n",
            "Epoch 833/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5865 - accuracy: 0.6731 - val_loss: 0.5434 - val_accuracy: 0.7050\n",
            "Epoch 834/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5852 - accuracy: 0.6744 - val_loss: 0.5378 - val_accuracy: 0.7100\n",
            "Epoch 835/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5858 - accuracy: 0.6700 - val_loss: 0.5405 - val_accuracy: 0.6913\n",
            "Epoch 836/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5850 - accuracy: 0.6708 - val_loss: 0.5402 - val_accuracy: 0.6925\n",
            "Epoch 837/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5881 - accuracy: 0.6719 - val_loss: 0.5407 - val_accuracy: 0.6950\n",
            "Epoch 838/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5886 - accuracy: 0.6682 - val_loss: 0.5848 - val_accuracy: 0.6888\n",
            "Epoch 839/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5840 - accuracy: 0.6726 - val_loss: 0.5398 - val_accuracy: 0.7013\n",
            "Epoch 840/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5872 - accuracy: 0.6679 - val_loss: 0.5497 - val_accuracy: 0.6900\n",
            "Epoch 841/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5850 - accuracy: 0.6719 - val_loss: 0.5366 - val_accuracy: 0.6938\n",
            "Epoch 842/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5843 - accuracy: 0.6725 - val_loss: 0.5634 - val_accuracy: 0.7075\n",
            "Epoch 843/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5879 - accuracy: 0.6664 - val_loss: 0.5456 - val_accuracy: 0.7000\n",
            "Epoch 844/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5879 - accuracy: 0.6675 - val_loss: 0.5359 - val_accuracy: 0.7025\n",
            "Epoch 845/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5842 - accuracy: 0.6740 - val_loss: 0.5481 - val_accuracy: 0.6913\n",
            "Epoch 846/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5859 - accuracy: 0.6668 - val_loss: 0.5442 - val_accuracy: 0.7075\n",
            "Epoch 847/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5893 - accuracy: 0.6667 - val_loss: 0.5350 - val_accuracy: 0.6963\n",
            "Epoch 848/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5849 - accuracy: 0.6783 - val_loss: 0.5381 - val_accuracy: 0.7088\n",
            "Epoch 849/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5873 - accuracy: 0.6737 - val_loss: 0.5384 - val_accuracy: 0.7113\n",
            "Epoch 850/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5872 - accuracy: 0.6667 - val_loss: 0.5745 - val_accuracy: 0.7100\n",
            "Epoch 851/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5878 - accuracy: 0.6661 - val_loss: 0.5418 - val_accuracy: 0.7075\n",
            "Epoch 852/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5855 - accuracy: 0.6737 - val_loss: 0.5598 - val_accuracy: 0.6938\n",
            "Epoch 853/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5858 - accuracy: 0.6701 - val_loss: 0.5784 - val_accuracy: 0.6975\n",
            "Epoch 854/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5859 - accuracy: 0.6754 - val_loss: 0.5369 - val_accuracy: 0.7050\n",
            "Epoch 855/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5877 - accuracy: 0.6686 - val_loss: 0.5997 - val_accuracy: 0.6862\n",
            "Epoch 856/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5923 - accuracy: 0.6628 - val_loss: 0.5467 - val_accuracy: 0.6975\n",
            "Epoch 857/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5861 - accuracy: 0.6744 - val_loss: 0.5402 - val_accuracy: 0.7075\n",
            "Epoch 858/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5843 - accuracy: 0.6760 - val_loss: 0.5876 - val_accuracy: 0.6862\n",
            "Epoch 859/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5867 - accuracy: 0.6706 - val_loss: 0.5571 - val_accuracy: 0.7262\n",
            "Epoch 860/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5877 - accuracy: 0.6685 - val_loss: 0.6000 - val_accuracy: 0.6837\n",
            "Epoch 861/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5844 - accuracy: 0.6724 - val_loss: 0.5419 - val_accuracy: 0.7563\n",
            "Epoch 862/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5829 - accuracy: 0.6721 - val_loss: 0.5419 - val_accuracy: 0.7025\n",
            "Epoch 863/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5846 - accuracy: 0.6732 - val_loss: 0.5601 - val_accuracy: 0.7300\n",
            "Epoch 864/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5842 - accuracy: 0.6728 - val_loss: 0.5588 - val_accuracy: 0.7250\n",
            "Epoch 865/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5872 - accuracy: 0.6686 - val_loss: 0.5896 - val_accuracy: 0.6850\n",
            "Epoch 866/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5853 - accuracy: 0.6715 - val_loss: 0.5430 - val_accuracy: 0.7150\n",
            "Epoch 867/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5929 - accuracy: 0.6653 - val_loss: 0.5425 - val_accuracy: 0.6488\n",
            "Epoch 868/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5845 - accuracy: 0.6712 - val_loss: 0.5396 - val_accuracy: 0.7075\n",
            "Epoch 869/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5868 - accuracy: 0.6719 - val_loss: 0.5443 - val_accuracy: 0.7063\n",
            "Epoch 870/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5874 - accuracy: 0.6678 - val_loss: 0.5343 - val_accuracy: 0.7025\n",
            "Epoch 871/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5846 - accuracy: 0.6757 - val_loss: 0.5383 - val_accuracy: 0.6900\n",
            "Epoch 872/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5835 - accuracy: 0.6708 - val_loss: 0.5542 - val_accuracy: 0.6850\n",
            "Epoch 873/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5876 - accuracy: 0.6692 - val_loss: 0.5489 - val_accuracy: 0.7237\n",
            "Epoch 874/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5851 - accuracy: 0.6733 - val_loss: 0.5503 - val_accuracy: 0.6900\n",
            "Epoch 875/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5878 - accuracy: 0.6718 - val_loss: 0.5478 - val_accuracy: 0.6925\n",
            "Epoch 876/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5858 - accuracy: 0.6751 - val_loss: 0.5361 - val_accuracy: 0.7063\n",
            "Epoch 877/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5851 - accuracy: 0.6676 - val_loss: 0.5403 - val_accuracy: 0.7063\n",
            "Epoch 878/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5834 - accuracy: 0.6762 - val_loss: 0.5405 - val_accuracy: 0.7250\n",
            "Epoch 879/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5842 - accuracy: 0.6756 - val_loss: 0.5765 - val_accuracy: 0.6988\n",
            "Epoch 880/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5873 - accuracy: 0.6672 - val_loss: 0.5680 - val_accuracy: 0.7138\n",
            "Epoch 881/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5879 - accuracy: 0.6718 - val_loss: 0.5425 - val_accuracy: 0.7075\n",
            "Epoch 882/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5834 - accuracy: 0.6767 - val_loss: 0.5441 - val_accuracy: 0.6625\n",
            "Epoch 883/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5852 - accuracy: 0.6676 - val_loss: 0.5852 - val_accuracy: 0.6900\n",
            "Epoch 884/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5842 - accuracy: 0.6718 - val_loss: 0.5737 - val_accuracy: 0.7100\n",
            "Epoch 885/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5861 - accuracy: 0.6756 - val_loss: 0.5396 - val_accuracy: 0.7188\n",
            "Epoch 886/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5838 - accuracy: 0.6739 - val_loss: 0.6055 - val_accuracy: 0.6787\n",
            "Epoch 887/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5899 - accuracy: 0.6654 - val_loss: 0.5456 - val_accuracy: 0.6975\n",
            "Epoch 888/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5851 - accuracy: 0.6683 - val_loss: 0.5369 - val_accuracy: 0.7025\n",
            "Epoch 889/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5866 - accuracy: 0.6733 - val_loss: 0.5410 - val_accuracy: 0.7050\n",
            "Epoch 890/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5859 - accuracy: 0.6743 - val_loss: 0.5392 - val_accuracy: 0.7038\n",
            "Epoch 891/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5849 - accuracy: 0.6743 - val_loss: 0.5712 - val_accuracy: 0.7200\n",
            "Epoch 892/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5869 - accuracy: 0.6744 - val_loss: 0.5438 - val_accuracy: 0.7000\n",
            "Epoch 893/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5893 - accuracy: 0.6675 - val_loss: 0.5366 - val_accuracy: 0.7038\n",
            "Epoch 894/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5843 - accuracy: 0.6731 - val_loss: 0.5420 - val_accuracy: 0.7075\n",
            "Epoch 895/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5856 - accuracy: 0.6746 - val_loss: 0.6284 - val_accuracy: 0.6550\n",
            "Epoch 896/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5860 - accuracy: 0.6753 - val_loss: 0.5330 - val_accuracy: 0.7075\n",
            "Epoch 897/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5870 - accuracy: 0.6676 - val_loss: 0.5374 - val_accuracy: 0.7038\n",
            "Epoch 898/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5892 - accuracy: 0.6649 - val_loss: 0.5564 - val_accuracy: 0.7225\n",
            "Epoch 899/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5836 - accuracy: 0.6786 - val_loss: 0.5470 - val_accuracy: 0.6913\n",
            "Epoch 900/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5862 - accuracy: 0.6717 - val_loss: 0.5383 - val_accuracy: 0.7063\n",
            "Epoch 901/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5843 - accuracy: 0.6717 - val_loss: 0.5629 - val_accuracy: 0.7113\n",
            "Epoch 902/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5824 - accuracy: 0.6783 - val_loss: 0.5494 - val_accuracy: 0.6938\n",
            "Epoch 903/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5836 - accuracy: 0.6753 - val_loss: 0.5667 - val_accuracy: 0.7100\n",
            "Epoch 904/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5854 - accuracy: 0.6708 - val_loss: 0.5740 - val_accuracy: 0.7138\n",
            "Epoch 905/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5852 - accuracy: 0.6683 - val_loss: 0.5706 - val_accuracy: 0.7125\n",
            "Epoch 906/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5847 - accuracy: 0.6676 - val_loss: 0.5853 - val_accuracy: 0.6800\n",
            "Epoch 907/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5852 - accuracy: 0.6722 - val_loss: 0.5475 - val_accuracy: 0.6950\n",
            "Epoch 908/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5844 - accuracy: 0.6737 - val_loss: 0.5333 - val_accuracy: 0.6988\n",
            "Epoch 909/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5829 - accuracy: 0.6722 - val_loss: 0.5671 - val_accuracy: 0.6837\n",
            "Epoch 910/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5865 - accuracy: 0.6682 - val_loss: 0.5784 - val_accuracy: 0.6975\n",
            "Epoch 911/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5877 - accuracy: 0.6667 - val_loss: 0.5619 - val_accuracy: 0.6963\n",
            "Epoch 912/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5860 - accuracy: 0.6729 - val_loss: 0.6144 - val_accuracy: 0.6675\n",
            "Epoch 913/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5856 - accuracy: 0.6731 - val_loss: 0.5366 - val_accuracy: 0.7163\n",
            "Epoch 914/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5815 - accuracy: 0.6792 - val_loss: 0.5360 - val_accuracy: 0.6913\n",
            "Epoch 915/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5880 - accuracy: 0.6700 - val_loss: 0.5360 - val_accuracy: 0.6988\n",
            "Epoch 916/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5843 - accuracy: 0.6764 - val_loss: 0.5444 - val_accuracy: 0.7000\n",
            "Epoch 917/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5847 - accuracy: 0.6704 - val_loss: 0.5431 - val_accuracy: 0.7325\n",
            "Epoch 918/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5815 - accuracy: 0.6782 - val_loss: 0.5436 - val_accuracy: 0.6988\n",
            "Epoch 919/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5867 - accuracy: 0.6696 - val_loss: 0.5385 - val_accuracy: 0.7100\n",
            "Epoch 920/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5837 - accuracy: 0.6785 - val_loss: 0.5411 - val_accuracy: 0.7063\n",
            "Epoch 921/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5851 - accuracy: 0.6704 - val_loss: 0.5611 - val_accuracy: 0.7175\n",
            "Epoch 922/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5841 - accuracy: 0.6746 - val_loss: 0.5936 - val_accuracy: 0.6812\n",
            "Epoch 923/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5838 - accuracy: 0.6747 - val_loss: 0.5449 - val_accuracy: 0.7362\n",
            "Epoch 924/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5828 - accuracy: 0.6776 - val_loss: 0.5403 - val_accuracy: 0.7088\n",
            "Epoch 925/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5839 - accuracy: 0.6724 - val_loss: 0.5611 - val_accuracy: 0.6800\n",
            "Epoch 926/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5840 - accuracy: 0.6731 - val_loss: 0.5668 - val_accuracy: 0.7262\n",
            "Epoch 927/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5831 - accuracy: 0.6746 - val_loss: 0.5871 - val_accuracy: 0.6837\n",
            "Epoch 928/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5843 - accuracy: 0.6728 - val_loss: 0.5407 - val_accuracy: 0.7125\n",
            "Epoch 929/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5836 - accuracy: 0.6747 - val_loss: 0.5701 - val_accuracy: 0.7125\n",
            "Epoch 930/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5849 - accuracy: 0.6732 - val_loss: 0.5366 - val_accuracy: 0.7000\n",
            "Epoch 931/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5827 - accuracy: 0.6724 - val_loss: 0.5359 - val_accuracy: 0.7100\n",
            "Epoch 932/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5838 - accuracy: 0.6715 - val_loss: 0.5418 - val_accuracy: 0.7163\n",
            "Epoch 933/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5837 - accuracy: 0.6761 - val_loss: 0.5366 - val_accuracy: 0.6938\n",
            "Epoch 934/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5866 - accuracy: 0.6735 - val_loss: 0.5356 - val_accuracy: 0.7075\n",
            "Epoch 935/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5821 - accuracy: 0.6732 - val_loss: 0.5441 - val_accuracy: 0.7025\n",
            "Epoch 936/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5830 - accuracy: 0.6742 - val_loss: 0.5409 - val_accuracy: 0.7163\n",
            "Epoch 937/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5856 - accuracy: 0.6751 - val_loss: 0.5961 - val_accuracy: 0.6888\n",
            "Epoch 938/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5850 - accuracy: 0.6694 - val_loss: 0.5338 - val_accuracy: 0.7088\n",
            "Epoch 939/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5883 - accuracy: 0.6696 - val_loss: 0.5837 - val_accuracy: 0.6938\n",
            "Epoch 940/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5841 - accuracy: 0.6715 - val_loss: 0.5480 - val_accuracy: 0.6938\n",
            "Epoch 941/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5823 - accuracy: 0.6732 - val_loss: 0.5370 - val_accuracy: 0.7163\n",
            "Epoch 942/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5894 - accuracy: 0.6683 - val_loss: 0.5394 - val_accuracy: 0.6925\n",
            "Epoch 943/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5829 - accuracy: 0.6722 - val_loss: 0.5348 - val_accuracy: 0.7075\n",
            "Epoch 944/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5851 - accuracy: 0.6749 - val_loss: 0.5788 - val_accuracy: 0.7000\n",
            "Epoch 945/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5848 - accuracy: 0.6717 - val_loss: 0.5362 - val_accuracy: 0.7125\n",
            "Epoch 946/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5836 - accuracy: 0.6729 - val_loss: 0.5974 - val_accuracy: 0.6850\n",
            "Epoch 947/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5843 - accuracy: 0.6721 - val_loss: 0.5400 - val_accuracy: 0.7000\n",
            "Epoch 948/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5816 - accuracy: 0.6779 - val_loss: 0.5450 - val_accuracy: 0.6988\n",
            "Epoch 949/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5867 - accuracy: 0.6685 - val_loss: 0.5799 - val_accuracy: 0.6950\n",
            "Epoch 950/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5840 - accuracy: 0.6737 - val_loss: 0.5695 - val_accuracy: 0.7175\n",
            "Epoch 951/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5855 - accuracy: 0.6726 - val_loss: 0.5365 - val_accuracy: 0.7100\n",
            "Epoch 952/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5817 - accuracy: 0.6774 - val_loss: 0.5661 - val_accuracy: 0.7188\n",
            "Epoch 953/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5836 - accuracy: 0.6796 - val_loss: 0.5344 - val_accuracy: 0.7063\n",
            "Epoch 954/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5869 - accuracy: 0.6654 - val_loss: 0.5367 - val_accuracy: 0.7125\n",
            "Epoch 955/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5802 - accuracy: 0.6758 - val_loss: 0.5382 - val_accuracy: 0.6888\n",
            "Epoch 956/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5841 - accuracy: 0.6747 - val_loss: 0.5482 - val_accuracy: 0.7513\n",
            "Epoch 957/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5865 - accuracy: 0.6675 - val_loss: 0.5436 - val_accuracy: 0.7025\n",
            "Epoch 958/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5823 - accuracy: 0.6774 - val_loss: 0.5486 - val_accuracy: 0.6963\n",
            "Epoch 959/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5845 - accuracy: 0.6774 - val_loss: 0.5552 - val_accuracy: 0.7375\n",
            "Epoch 960/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5842 - accuracy: 0.6781 - val_loss: 0.5484 - val_accuracy: 0.6925\n",
            "Epoch 961/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5852 - accuracy: 0.6678 - val_loss: 0.5449 - val_accuracy: 0.6950\n",
            "Epoch 962/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5835 - accuracy: 0.6700 - val_loss: 0.5546 - val_accuracy: 0.7387\n",
            "Epoch 963/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5826 - accuracy: 0.6778 - val_loss: 0.5328 - val_accuracy: 0.7175\n",
            "Epoch 964/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5817 - accuracy: 0.6737 - val_loss: 0.5560 - val_accuracy: 0.7300\n",
            "Epoch 965/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5889 - accuracy: 0.6772 - val_loss: 0.5375 - val_accuracy: 0.6900\n",
            "Epoch 966/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5848 - accuracy: 0.6728 - val_loss: 0.6086 - val_accuracy: 0.6775\n",
            "Epoch 967/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5854 - accuracy: 0.6746 - val_loss: 0.5573 - val_accuracy: 0.6837\n",
            "Epoch 968/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5817 - accuracy: 0.6775 - val_loss: 0.5348 - val_accuracy: 0.7038\n",
            "Epoch 969/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5811 - accuracy: 0.6786 - val_loss: 0.5344 - val_accuracy: 0.7075\n",
            "Epoch 970/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5825 - accuracy: 0.6767 - val_loss: 0.5542 - val_accuracy: 0.7188\n",
            "Epoch 971/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5818 - accuracy: 0.6793 - val_loss: 0.5664 - val_accuracy: 0.6812\n",
            "Epoch 972/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5852 - accuracy: 0.6681 - val_loss: 0.5486 - val_accuracy: 0.6975\n",
            "Epoch 973/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5834 - accuracy: 0.6728 - val_loss: 0.5617 - val_accuracy: 0.7150\n",
            "Epoch 974/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5828 - accuracy: 0.6806 - val_loss: 0.5579 - val_accuracy: 0.7212\n",
            "Epoch 975/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5811 - accuracy: 0.6797 - val_loss: 0.5386 - val_accuracy: 0.7125\n",
            "Epoch 976/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5834 - accuracy: 0.6744 - val_loss: 0.5536 - val_accuracy: 0.6963\n",
            "Epoch 977/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5830 - accuracy: 0.6765 - val_loss: 0.5597 - val_accuracy: 0.7325\n",
            "Epoch 978/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5826 - accuracy: 0.6746 - val_loss: 0.5650 - val_accuracy: 0.6925\n",
            "Epoch 979/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5847 - accuracy: 0.6700 - val_loss: 0.5797 - val_accuracy: 0.6975\n",
            "Epoch 980/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5871 - accuracy: 0.6712 - val_loss: 0.5458 - val_accuracy: 0.6975\n",
            "Epoch 981/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5832 - accuracy: 0.6774 - val_loss: 0.5418 - val_accuracy: 0.7063\n",
            "Epoch 982/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5805 - accuracy: 0.6735 - val_loss: 0.5314 - val_accuracy: 0.7025\n",
            "Epoch 983/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5802 - accuracy: 0.6849 - val_loss: 0.5407 - val_accuracy: 0.7138\n",
            "Epoch 984/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5824 - accuracy: 0.6762 - val_loss: 0.5420 - val_accuracy: 0.7038\n",
            "Epoch 985/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5853 - accuracy: 0.6749 - val_loss: 0.5477 - val_accuracy: 0.7188\n",
            "Epoch 986/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5847 - accuracy: 0.6740 - val_loss: 0.5433 - val_accuracy: 0.7013\n",
            "Epoch 987/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5832 - accuracy: 0.6710 - val_loss: 0.5565 - val_accuracy: 0.7325\n",
            "Epoch 988/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5807 - accuracy: 0.6760 - val_loss: 0.5594 - val_accuracy: 0.7200\n",
            "Epoch 989/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5849 - accuracy: 0.6758 - val_loss: 0.5463 - val_accuracy: 0.6938\n",
            "Epoch 990/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5849 - accuracy: 0.6747 - val_loss: 0.5362 - val_accuracy: 0.7100\n",
            "Epoch 991/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5880 - accuracy: 0.6646 - val_loss: 0.5444 - val_accuracy: 0.7138\n",
            "Epoch 992/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5820 - accuracy: 0.6771 - val_loss: 0.5539 - val_accuracy: 0.7188\n",
            "Epoch 993/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5836 - accuracy: 0.6774 - val_loss: 0.5447 - val_accuracy: 0.7000\n",
            "Epoch 994/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5808 - accuracy: 0.6807 - val_loss: 0.5332 - val_accuracy: 0.7000\n",
            "Epoch 995/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5825 - accuracy: 0.6771 - val_loss: 0.5450 - val_accuracy: 0.7525\n",
            "Epoch 996/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5813 - accuracy: 0.6786 - val_loss: 0.5360 - val_accuracy: 0.7025\n",
            "Epoch 997/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5836 - accuracy: 0.6737 - val_loss: 0.5393 - val_accuracy: 0.7163\n",
            "Epoch 998/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5877 - accuracy: 0.6768 - val_loss: 0.5407 - val_accuracy: 0.7050\n",
            "Epoch 999/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5832 - accuracy: 0.6740 - val_loss: 0.5782 - val_accuracy: 0.6950\n",
            "Epoch 1000/1000\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5831 - accuracy: 0.6733 - val_loss: 0.5908 - val_accuracy: 0.6825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQj8ibAOlHxG",
        "outputId": "4c1b54b2-8741-48d3-fcbb-7cf0f6bfb8a8"
      },
      "source": [
        "history = model_lstm.fit(train_x, train_y, batch_size=32, epochs=500, validation_split=0.1, verbose=1)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "225/225 [==============================] - 2s 4ms/step - loss: 0.3793 - accuracy: 0.9551 - val_loss: 0.2192 - val_accuracy: 0.9525\n",
            "Epoch 2/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9800 - val_loss: 0.2126 - val_accuracy: 0.9525\n",
            "Epoch 3/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9807 - val_loss: 0.2141 - val_accuracy: 0.9525\n",
            "Epoch 4/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1082 - accuracy: 0.9783 - val_loss: 0.2132 - val_accuracy: 0.9525\n",
            "Epoch 5/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9806 - val_loss: 0.2101 - val_accuracy: 0.9525\n",
            "Epoch 6/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0988 - accuracy: 0.9796 - val_loss: 0.2141 - val_accuracy: 0.9525\n",
            "Epoch 7/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1040 - accuracy: 0.9776 - val_loss: 0.2088 - val_accuracy: 0.9525\n",
            "Epoch 8/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9793 - val_loss: 0.2115 - val_accuracy: 0.9525\n",
            "Epoch 9/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9797 - val_loss: 0.2101 - val_accuracy: 0.9525\n",
            "Epoch 10/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9787 - val_loss: 0.2184 - val_accuracy: 0.9525\n",
            "Epoch 11/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0998 - accuracy: 0.9789 - val_loss: 0.2069 - val_accuracy: 0.9525\n",
            "Epoch 12/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.9790 - val_loss: 0.2024 - val_accuracy: 0.9525\n",
            "Epoch 13/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1136 - accuracy: 0.9748 - val_loss: 0.2176 - val_accuracy: 0.9525\n",
            "Epoch 14/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1029 - accuracy: 0.9779 - val_loss: 0.2077 - val_accuracy: 0.9525\n",
            "Epoch 15/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1020 - accuracy: 0.9782 - val_loss: 0.2163 - val_accuracy: 0.9525\n",
            "Epoch 16/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1010 - accuracy: 0.9780 - val_loss: 0.2097 - val_accuracy: 0.9525\n",
            "Epoch 17/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0960 - accuracy: 0.9793 - val_loss: 0.2106 - val_accuracy: 0.9525\n",
            "Epoch 18/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9791 - val_loss: 0.2049 - val_accuracy: 0.9525\n",
            "Epoch 19/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1156 - accuracy: 0.9738 - val_loss: 0.2082 - val_accuracy: 0.9525\n",
            "Epoch 20/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1006 - accuracy: 0.9791 - val_loss: 0.2106 - val_accuracy: 0.9525\n",
            "Epoch 21/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9784 - val_loss: 0.2082 - val_accuracy: 0.9525\n",
            "Epoch 22/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9781 - val_loss: 0.2098 - val_accuracy: 0.9525\n",
            "Epoch 23/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1019 - accuracy: 0.9777 - val_loss: 0.2152 - val_accuracy: 0.9525\n",
            "Epoch 24/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1168 - accuracy: 0.9738 - val_loss: 0.2151 - val_accuracy: 0.9525\n",
            "Epoch 25/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9789 - val_loss: 0.2065 - val_accuracy: 0.9525\n",
            "Epoch 26/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1130 - accuracy: 0.9746 - val_loss: 0.2100 - val_accuracy: 0.9525\n",
            "Epoch 27/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9798 - val_loss: 0.2113 - val_accuracy: 0.9525\n",
            "Epoch 28/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1075 - accuracy: 0.9767 - val_loss: 0.2145 - val_accuracy: 0.9525\n",
            "Epoch 29/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1018 - accuracy: 0.9777 - val_loss: 0.2109 - val_accuracy: 0.9525\n",
            "Epoch 30/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1043 - accuracy: 0.9765 - val_loss: 0.2174 - val_accuracy: 0.9525\n",
            "Epoch 31/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1001 - accuracy: 0.9773 - val_loss: 0.2074 - val_accuracy: 0.9525\n",
            "Epoch 32/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0989 - accuracy: 0.9788 - val_loss: 0.2124 - val_accuracy: 0.9525\n",
            "Epoch 33/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9792 - val_loss: 0.2140 - val_accuracy: 0.9525\n",
            "Epoch 34/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1104 - accuracy: 0.9750 - val_loss: 0.2124 - val_accuracy: 0.9525\n",
            "Epoch 35/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0985 - accuracy: 0.9785 - val_loss: 0.2160 - val_accuracy: 0.9525\n",
            "Epoch 36/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1080 - accuracy: 0.9767 - val_loss: 0.2190 - val_accuracy: 0.9525\n",
            "Epoch 37/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.9787 - val_loss: 0.2096 - val_accuracy: 0.9525\n",
            "Epoch 38/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0915 - accuracy: 0.9805 - val_loss: 0.2167 - val_accuracy: 0.9525\n",
            "Epoch 39/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1042 - accuracy: 0.9776 - val_loss: 0.2208 - val_accuracy: 0.9525\n",
            "Epoch 40/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.9801 - val_loss: 0.2167 - val_accuracy: 0.9525\n",
            "Epoch 41/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1066 - accuracy: 0.9767 - val_loss: 0.2174 - val_accuracy: 0.9525\n",
            "Epoch 42/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1060 - accuracy: 0.9760 - val_loss: 0.2126 - val_accuracy: 0.9525\n",
            "Epoch 43/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0978 - accuracy: 0.9788 - val_loss: 0.2131 - val_accuracy: 0.9525\n",
            "Epoch 44/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1120 - accuracy: 0.9743 - val_loss: 0.2210 - val_accuracy: 0.9525\n",
            "Epoch 45/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0950 - accuracy: 0.9800 - val_loss: 0.2084 - val_accuracy: 0.9525\n",
            "Epoch 46/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0964 - accuracy: 0.9791 - val_loss: 0.2274 - val_accuracy: 0.9525\n",
            "Epoch 47/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0977 - accuracy: 0.9793 - val_loss: 0.2160 - val_accuracy: 0.9525\n",
            "Epoch 48/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1034 - accuracy: 0.9773 - val_loss: 0.2125 - val_accuracy: 0.9525\n",
            "Epoch 49/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9795 - val_loss: 0.2023 - val_accuracy: 0.9525\n",
            "Epoch 50/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1068 - accuracy: 0.9758 - val_loss: 0.2202 - val_accuracy: 0.9525\n",
            "Epoch 51/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1022 - accuracy: 0.9776 - val_loss: 0.2197 - val_accuracy: 0.9525\n",
            "Epoch 52/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9799 - val_loss: 0.2129 - val_accuracy: 0.9525\n",
            "Epoch 53/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1018 - accuracy: 0.9775 - val_loss: 0.2192 - val_accuracy: 0.9525\n",
            "Epoch 54/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1033 - accuracy: 0.9773 - val_loss: 0.2118 - val_accuracy: 0.9525\n",
            "Epoch 55/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9783 - val_loss: 0.2128 - val_accuracy: 0.9525\n",
            "Epoch 56/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0957 - accuracy: 0.9794 - val_loss: 0.2118 - val_accuracy: 0.9525\n",
            "Epoch 57/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1028 - accuracy: 0.9776 - val_loss: 0.2119 - val_accuracy: 0.9525\n",
            "Epoch 58/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0936 - accuracy: 0.9800 - val_loss: 0.2108 - val_accuracy: 0.9525\n",
            "Epoch 59/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9783 - val_loss: 0.2126 - val_accuracy: 0.9525\n",
            "Epoch 60/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0974 - accuracy: 0.9789 - val_loss: 0.2110 - val_accuracy: 0.9525\n",
            "Epoch 61/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1036 - accuracy: 0.9774 - val_loss: 0.2095 - val_accuracy: 0.9525\n",
            "Epoch 62/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0939 - accuracy: 0.9799 - val_loss: 0.2120 - val_accuracy: 0.9525\n",
            "Epoch 63/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1021 - accuracy: 0.9772 - val_loss: 0.2147 - val_accuracy: 0.9525\n",
            "Epoch 64/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.9793 - val_loss: 0.2183 - val_accuracy: 0.9525\n",
            "Epoch 65/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0953 - accuracy: 0.9794 - val_loss: 0.2106 - val_accuracy: 0.9525\n",
            "Epoch 66/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1068 - accuracy: 0.9766 - val_loss: 0.2288 - val_accuracy: 0.9525\n",
            "Epoch 67/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1038 - accuracy: 0.9777 - val_loss: 0.2101 - val_accuracy: 0.9525\n",
            "Epoch 68/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1048 - accuracy: 0.9772 - val_loss: 0.2258 - val_accuracy: 0.9525\n",
            "Epoch 69/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.9777 - val_loss: 0.2130 - val_accuracy: 0.9525\n",
            "Epoch 70/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0979 - accuracy: 0.9787 - val_loss: 0.2183 - val_accuracy: 0.9525\n",
            "Epoch 71/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0977 - accuracy: 0.9781 - val_loss: 0.2137 - val_accuracy: 0.9525\n",
            "Epoch 72/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0917 - accuracy: 0.9796 - val_loss: 0.2135 - val_accuracy: 0.9525\n",
            "Epoch 73/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1041 - accuracy: 0.9767 - val_loss: 0.2168 - val_accuracy: 0.9525\n",
            "Epoch 74/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1024 - accuracy: 0.9771 - val_loss: 0.2169 - val_accuracy: 0.9525\n",
            "Epoch 75/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0985 - accuracy: 0.9783 - val_loss: 0.2140 - val_accuracy: 0.9525\n",
            "Epoch 76/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9782 - val_loss: 0.2094 - val_accuracy: 0.9525\n",
            "Epoch 77/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1003 - accuracy: 0.9775 - val_loss: 0.2079 - val_accuracy: 0.9525\n",
            "Epoch 78/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0928 - accuracy: 0.9797 - val_loss: 0.2070 - val_accuracy: 0.9525\n",
            "Epoch 79/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9802 - val_loss: 0.2081 - val_accuracy: 0.9525\n",
            "Epoch 80/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1052 - accuracy: 0.9771 - val_loss: 0.2176 - val_accuracy: 0.9525\n",
            "Epoch 81/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1104 - accuracy: 0.9754 - val_loss: 0.2107 - val_accuracy: 0.9525\n",
            "Epoch 82/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9791 - val_loss: 0.2123 - val_accuracy: 0.9525\n",
            "Epoch 83/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1134 - accuracy: 0.9747 - val_loss: 0.2253 - val_accuracy: 0.9525\n",
            "Epoch 84/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1121 - accuracy: 0.9755 - val_loss: 0.2178 - val_accuracy: 0.9525\n",
            "Epoch 85/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.9783 - val_loss: 0.2107 - val_accuracy: 0.9525\n",
            "Epoch 86/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1040 - accuracy: 0.9766 - val_loss: 0.2153 - val_accuracy: 0.9525\n",
            "Epoch 87/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1126 - accuracy: 0.9744 - val_loss: 0.2118 - val_accuracy: 0.9525\n",
            "Epoch 88/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9787 - val_loss: 0.2214 - val_accuracy: 0.9525\n",
            "Epoch 89/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0968 - accuracy: 0.9785 - val_loss: 0.2124 - val_accuracy: 0.9525\n",
            "Epoch 90/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0918 - accuracy: 0.9801 - val_loss: 0.2083 - val_accuracy: 0.9525\n",
            "Epoch 91/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0970 - accuracy: 0.9788 - val_loss: 0.2255 - val_accuracy: 0.9525\n",
            "Epoch 92/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1003 - accuracy: 0.9779 - val_loss: 0.2151 - val_accuracy: 0.9525\n",
            "Epoch 93/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.9788 - val_loss: 0.2091 - val_accuracy: 0.9525\n",
            "Epoch 94/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9786 - val_loss: 0.2164 - val_accuracy: 0.9525\n",
            "Epoch 95/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1008 - accuracy: 0.9778 - val_loss: 0.1999 - val_accuracy: 0.9525\n",
            "Epoch 96/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0926 - accuracy: 0.9806 - val_loss: 0.2143 - val_accuracy: 0.9525\n",
            "Epoch 97/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0983 - accuracy: 0.9783 - val_loss: 0.2165 - val_accuracy: 0.9525\n",
            "Epoch 98/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0952 - accuracy: 0.9795 - val_loss: 0.2152 - val_accuracy: 0.9525\n",
            "Epoch 99/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1038 - accuracy: 0.9766 - val_loss: 0.2150 - val_accuracy: 0.9525\n",
            "Epoch 100/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0888 - accuracy: 0.9809 - val_loss: 0.2175 - val_accuracy: 0.9525\n",
            "Epoch 101/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0861 - accuracy: 0.9815 - val_loss: 0.2117 - val_accuracy: 0.9525\n",
            "Epoch 102/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1126 - accuracy: 0.9741 - val_loss: 0.2179 - val_accuracy: 0.9525\n",
            "Epoch 103/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0915 - accuracy: 0.9804 - val_loss: 0.2069 - val_accuracy: 0.9525\n",
            "Epoch 104/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9795 - val_loss: 0.2161 - val_accuracy: 0.9525\n",
            "Epoch 105/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1110 - accuracy: 0.9753 - val_loss: 0.2099 - val_accuracy: 0.9525\n",
            "Epoch 106/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0987 - accuracy: 0.9788 - val_loss: 0.2112 - val_accuracy: 0.9525\n",
            "Epoch 107/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1076 - accuracy: 0.9757 - val_loss: 0.2109 - val_accuracy: 0.9525\n",
            "Epoch 108/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1162 - accuracy: 0.9734 - val_loss: 0.2185 - val_accuracy: 0.9525\n",
            "Epoch 109/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0910 - accuracy: 0.9802 - val_loss: 0.2087 - val_accuracy: 0.9525\n",
            "Epoch 110/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0990 - accuracy: 0.9784 - val_loss: 0.2172 - val_accuracy: 0.9525\n",
            "Epoch 111/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.9791 - val_loss: 0.2091 - val_accuracy: 0.9525\n",
            "Epoch 112/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1018 - accuracy: 0.9769 - val_loss: 0.2063 - val_accuracy: 0.9525\n",
            "Epoch 113/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1014 - accuracy: 0.9769 - val_loss: 0.2144 - val_accuracy: 0.9525\n",
            "Epoch 114/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0975 - accuracy: 0.9787 - val_loss: 0.2088 - val_accuracy: 0.9525\n",
            "Epoch 115/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.9794 - val_loss: 0.2026 - val_accuracy: 0.9525\n",
            "Epoch 116/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0950 - accuracy: 0.9795 - val_loss: 0.2079 - val_accuracy: 0.9525\n",
            "Epoch 117/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0995 - accuracy: 0.9777 - val_loss: 0.2152 - val_accuracy: 0.9525\n",
            "Epoch 118/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1040 - accuracy: 0.9772 - val_loss: 0.2172 - val_accuracy: 0.9525\n",
            "Epoch 119/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0912 - accuracy: 0.9801 - val_loss: 0.2106 - val_accuracy: 0.9525\n",
            "Epoch 120/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9780 - val_loss: 0.2201 - val_accuracy: 0.9525\n",
            "Epoch 121/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1151 - accuracy: 0.9735 - val_loss: 0.2203 - val_accuracy: 0.9525\n",
            "Epoch 122/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0969 - accuracy: 0.9785 - val_loss: 0.2024 - val_accuracy: 0.9525\n",
            "Epoch 123/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0969 - accuracy: 0.9783 - val_loss: 0.2087 - val_accuracy: 0.9525\n",
            "Epoch 124/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1001 - accuracy: 0.9773 - val_loss: 0.2192 - val_accuracy: 0.9525\n",
            "Epoch 125/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1051 - accuracy: 0.9769 - val_loss: 0.1993 - val_accuracy: 0.9525\n",
            "Epoch 126/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0898 - accuracy: 0.9809 - val_loss: 0.2057 - val_accuracy: 0.9525\n",
            "Epoch 127/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0959 - accuracy: 0.9791 - val_loss: 0.2010 - val_accuracy: 0.9525\n",
            "Epoch 128/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0901 - accuracy: 0.9803 - val_loss: 0.2016 - val_accuracy: 0.9525\n",
            "Epoch 129/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0982 - accuracy: 0.9784 - val_loss: 0.2035 - val_accuracy: 0.9525\n",
            "Epoch 130/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9786 - val_loss: 0.2034 - val_accuracy: 0.9525\n",
            "Epoch 131/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.9777 - val_loss: 0.2040 - val_accuracy: 0.9525\n",
            "Epoch 132/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0982 - accuracy: 0.9783 - val_loss: 0.2045 - val_accuracy: 0.9525\n",
            "Epoch 133/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1031 - accuracy: 0.9771 - val_loss: 0.2099 - val_accuracy: 0.9525\n",
            "Epoch 134/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1085 - accuracy: 0.9757 - val_loss: 0.2188 - val_accuracy: 0.9525\n",
            "Epoch 135/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0879 - accuracy: 0.9810 - val_loss: 0.1999 - val_accuracy: 0.9525\n",
            "Epoch 136/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1050 - accuracy: 0.9762 - val_loss: 0.2018 - val_accuracy: 0.9525\n",
            "Epoch 137/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9784 - val_loss: 0.1988 - val_accuracy: 0.9525\n",
            "Epoch 138/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.9800 - val_loss: 0.2028 - val_accuracy: 0.9525\n",
            "Epoch 139/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0990 - accuracy: 0.9777 - val_loss: 0.2137 - val_accuracy: 0.9525\n",
            "Epoch 140/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0992 - accuracy: 0.9776 - val_loss: 0.2032 - val_accuracy: 0.9525\n",
            "Epoch 141/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1015 - accuracy: 0.9776 - val_loss: 0.2187 - val_accuracy: 0.9525\n",
            "Epoch 142/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0939 - accuracy: 0.9794 - val_loss: 0.2159 - val_accuracy: 0.9525\n",
            "Epoch 143/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0968 - accuracy: 0.9794 - val_loss: 0.2113 - val_accuracy: 0.9525\n",
            "Epoch 144/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0965 - accuracy: 0.9790 - val_loss: 0.2106 - val_accuracy: 0.9525\n",
            "Epoch 145/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0973 - accuracy: 0.9787 - val_loss: 0.2082 - val_accuracy: 0.9525\n",
            "Epoch 146/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.9782 - val_loss: 0.2032 - val_accuracy: 0.9525\n",
            "Epoch 147/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0953 - accuracy: 0.9794 - val_loss: 0.2017 - val_accuracy: 0.9525\n",
            "Epoch 148/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9801 - val_loss: 0.2087 - val_accuracy: 0.9525\n",
            "Epoch 149/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0933 - accuracy: 0.9786 - val_loss: 0.2071 - val_accuracy: 0.9525\n",
            "Epoch 150/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0848 - accuracy: 0.9816 - val_loss: 0.1907 - val_accuracy: 0.9525\n",
            "Epoch 151/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0983 - accuracy: 0.9777 - val_loss: 0.1997 - val_accuracy: 0.9525\n",
            "Epoch 152/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1027 - accuracy: 0.9770 - val_loss: 0.2150 - val_accuracy: 0.9525\n",
            "Epoch 153/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0932 - accuracy: 0.9796 - val_loss: 0.2066 - val_accuracy: 0.9525\n",
            "Epoch 154/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.9798 - val_loss: 0.2009 - val_accuracy: 0.9525\n",
            "Epoch 155/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9787 - val_loss: 0.2051 - val_accuracy: 0.9525\n",
            "Epoch 156/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0948 - accuracy: 0.9784 - val_loss: 0.2037 - val_accuracy: 0.9525\n",
            "Epoch 157/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0964 - accuracy: 0.9791 - val_loss: 0.1973 - val_accuracy: 0.9525\n",
            "Epoch 158/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1084 - accuracy: 0.9755 - val_loss: 0.2017 - val_accuracy: 0.9525\n",
            "Epoch 159/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0977 - accuracy: 0.9788 - val_loss: 0.1952 - val_accuracy: 0.9525\n",
            "Epoch 160/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1016 - accuracy: 0.9772 - val_loss: 0.1997 - val_accuracy: 0.9525\n",
            "Epoch 161/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0946 - accuracy: 0.9786 - val_loss: 0.1879 - val_accuracy: 0.9525\n",
            "Epoch 162/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1085 - accuracy: 0.9753 - val_loss: 0.2011 - val_accuracy: 0.9525\n",
            "Epoch 163/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1108 - accuracy: 0.9742 - val_loss: 0.2091 - val_accuracy: 0.9525\n",
            "Epoch 164/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0884 - accuracy: 0.9799 - val_loss: 0.1873 - val_accuracy: 0.9525\n",
            "Epoch 165/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0931 - accuracy: 0.9797 - val_loss: 0.1923 - val_accuracy: 0.9525\n",
            "Epoch 166/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0909 - accuracy: 0.9793 - val_loss: 0.1943 - val_accuracy: 0.9525\n",
            "Epoch 167/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0917 - accuracy: 0.9805 - val_loss: 0.1920 - val_accuracy: 0.9525\n",
            "Epoch 168/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0981 - accuracy: 0.9776 - val_loss: 0.2035 - val_accuracy: 0.9525\n",
            "Epoch 169/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.9795 - val_loss: 0.2090 - val_accuracy: 0.9525\n",
            "Epoch 170/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9788 - val_loss: 0.1930 - val_accuracy: 0.9525\n",
            "Epoch 171/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0984 - accuracy: 0.9782 - val_loss: 0.2114 - val_accuracy: 0.9525\n",
            "Epoch 172/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0896 - accuracy: 0.9798 - val_loss: 0.1875 - val_accuracy: 0.9525\n",
            "Epoch 173/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0936 - accuracy: 0.9790 - val_loss: 0.2009 - val_accuracy: 0.9525\n",
            "Epoch 174/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1161 - accuracy: 0.9727 - val_loss: 0.2102 - val_accuracy: 0.9525\n",
            "Epoch 175/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0974 - accuracy: 0.9778 - val_loss: 0.2082 - val_accuracy: 0.9525\n",
            "Epoch 176/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0845 - accuracy: 0.9815 - val_loss: 0.2017 - val_accuracy: 0.9525\n",
            "Epoch 177/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1125 - accuracy: 0.9740 - val_loss: 0.2056 - val_accuracy: 0.9525\n",
            "Epoch 178/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0870 - accuracy: 0.9806 - val_loss: 0.1904 - val_accuracy: 0.9525\n",
            "Epoch 179/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1017 - accuracy: 0.9769 - val_loss: 0.1970 - val_accuracy: 0.9525\n",
            "Epoch 180/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0969 - accuracy: 0.9777 - val_loss: 0.1973 - val_accuracy: 0.9525\n",
            "Epoch 181/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0944 - accuracy: 0.9792 - val_loss: 0.1933 - val_accuracy: 0.9525\n",
            "Epoch 182/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0885 - accuracy: 0.9807 - val_loss: 0.1973 - val_accuracy: 0.9525\n",
            "Epoch 183/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.9781 - val_loss: 0.2095 - val_accuracy: 0.9525\n",
            "Epoch 184/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0936 - accuracy: 0.9794 - val_loss: 0.2100 - val_accuracy: 0.9525\n",
            "Epoch 185/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9776 - val_loss: 0.1958 - val_accuracy: 0.9525\n",
            "Epoch 186/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0933 - accuracy: 0.9783 - val_loss: 0.1918 - val_accuracy: 0.9525\n",
            "Epoch 187/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0919 - accuracy: 0.9793 - val_loss: 0.1870 - val_accuracy: 0.9525\n",
            "Epoch 188/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9798 - val_loss: 0.1840 - val_accuracy: 0.9525\n",
            "Epoch 189/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0952 - accuracy: 0.9793 - val_loss: 0.1772 - val_accuracy: 0.9525\n",
            "Epoch 190/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0944 - accuracy: 0.9783 - val_loss: 0.1844 - val_accuracy: 0.9525\n",
            "Epoch 191/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0979 - accuracy: 0.9784 - val_loss: 0.2079 - val_accuracy: 0.9525\n",
            "Epoch 192/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0947 - accuracy: 0.9785 - val_loss: 0.1859 - val_accuracy: 0.9525\n",
            "Epoch 193/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0946 - accuracy: 0.9782 - val_loss: 0.1821 - val_accuracy: 0.9525\n",
            "Epoch 194/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0914 - accuracy: 0.9790 - val_loss: 0.1844 - val_accuracy: 0.9525\n",
            "Epoch 195/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0891 - accuracy: 0.9801 - val_loss: 0.1873 - val_accuracy: 0.9525\n",
            "Epoch 196/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1015 - accuracy: 0.9771 - val_loss: 0.1940 - val_accuracy: 0.9525\n",
            "Epoch 197/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1018 - accuracy: 0.9771 - val_loss: 0.1916 - val_accuracy: 0.9525\n",
            "Epoch 198/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1010 - accuracy: 0.9766 - val_loss: 0.1956 - val_accuracy: 0.9525\n",
            "Epoch 199/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0919 - accuracy: 0.9788 - val_loss: 0.1924 - val_accuracy: 0.9525\n",
            "Epoch 200/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0897 - accuracy: 0.9797 - val_loss: 0.1980 - val_accuracy: 0.9525\n",
            "Epoch 201/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0946 - accuracy: 0.9795 - val_loss: 0.1962 - val_accuracy: 0.9525\n",
            "Epoch 202/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0910 - accuracy: 0.9786 - val_loss: 0.1969 - val_accuracy: 0.9525\n",
            "Epoch 203/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1026 - accuracy: 0.9751 - val_loss: 0.2128 - val_accuracy: 0.9525\n",
            "Epoch 204/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0965 - accuracy: 0.9787 - val_loss: 0.1942 - val_accuracy: 0.9525\n",
            "Epoch 205/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.9767 - val_loss: 0.2013 - val_accuracy: 0.9525\n",
            "Epoch 206/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0871 - accuracy: 0.9807 - val_loss: 0.1984 - val_accuracy: 0.9525\n",
            "Epoch 207/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1052 - accuracy: 0.9763 - val_loss: 0.1907 - val_accuracy: 0.9525\n",
            "Epoch 208/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0977 - accuracy: 0.9780 - val_loss: 0.1859 - val_accuracy: 0.9525\n",
            "Epoch 209/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1058 - accuracy: 0.9761 - val_loss: 0.1910 - val_accuracy: 0.9525\n",
            "Epoch 210/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0949 - accuracy: 0.9784 - val_loss: 0.1993 - val_accuracy: 0.9525\n",
            "Epoch 211/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0892 - accuracy: 0.9795 - val_loss: 0.1870 - val_accuracy: 0.9525\n",
            "Epoch 212/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0886 - accuracy: 0.9810 - val_loss: 0.1785 - val_accuracy: 0.9525\n",
            "Epoch 213/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0933 - accuracy: 0.9779 - val_loss: 0.1906 - val_accuracy: 0.9525\n",
            "Epoch 214/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0959 - accuracy: 0.9782 - val_loss: 0.1895 - val_accuracy: 0.9525\n",
            "Epoch 215/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9783 - val_loss: 0.1820 - val_accuracy: 0.9525\n",
            "Epoch 216/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1071 - accuracy: 0.9748 - val_loss: 0.2199 - val_accuracy: 0.9525\n",
            "Epoch 217/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1041 - accuracy: 0.9765 - val_loss: 0.1943 - val_accuracy: 0.9525\n",
            "Epoch 218/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0945 - accuracy: 0.9785 - val_loss: 0.1917 - val_accuracy: 0.9525\n",
            "Epoch 219/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.9794 - val_loss: 0.1746 - val_accuracy: 0.9525\n",
            "Epoch 220/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0965 - accuracy: 0.9783 - val_loss: 0.1892 - val_accuracy: 0.9525\n",
            "Epoch 221/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9799 - val_loss: 0.1989 - val_accuracy: 0.9525\n",
            "Epoch 222/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0948 - accuracy: 0.9786 - val_loss: 0.1983 - val_accuracy: 0.9525\n",
            "Epoch 223/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0936 - accuracy: 0.9785 - val_loss: 0.1896 - val_accuracy: 0.9525\n",
            "Epoch 224/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0923 - accuracy: 0.9792 - val_loss: 0.2107 - val_accuracy: 0.9525\n",
            "Epoch 225/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1140 - accuracy: 0.9739 - val_loss: 0.2226 - val_accuracy: 0.9525\n",
            "Epoch 226/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0976 - accuracy: 0.9788 - val_loss: 0.1802 - val_accuracy: 0.9525\n",
            "Epoch 227/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0943 - accuracy: 0.9801 - val_loss: 0.1915 - val_accuracy: 0.9525\n",
            "Epoch 228/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0949 - accuracy: 0.9783 - val_loss: 0.1977 - val_accuracy: 0.9525\n",
            "Epoch 229/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0963 - accuracy: 0.9791 - val_loss: 0.1848 - val_accuracy: 0.9525\n",
            "Epoch 230/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0857 - accuracy: 0.9809 - val_loss: 0.1809 - val_accuracy: 0.9525\n",
            "Epoch 231/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0946 - accuracy: 0.9792 - val_loss: 0.1871 - val_accuracy: 0.9525\n",
            "Epoch 232/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0810 - accuracy: 0.9823 - val_loss: 0.1849 - val_accuracy: 0.9525\n",
            "Epoch 233/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0898 - accuracy: 0.9798 - val_loss: 0.1829 - val_accuracy: 0.9525\n",
            "Epoch 234/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.1043 - accuracy: 0.9754 - val_loss: 0.2014 - val_accuracy: 0.9525\n",
            "Epoch 235/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0947 - accuracy: 0.9792 - val_loss: 0.1792 - val_accuracy: 0.9525\n",
            "Epoch 236/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1033 - accuracy: 0.9770 - val_loss: 0.1918 - val_accuracy: 0.9525\n",
            "Epoch 237/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1015 - accuracy: 0.9770 - val_loss: 0.1883 - val_accuracy: 0.9525\n",
            "Epoch 238/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1013 - accuracy: 0.9767 - val_loss: 0.2077 - val_accuracy: 0.9525\n",
            "Epoch 239/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0978 - accuracy: 0.9783 - val_loss: 0.1892 - val_accuracy: 0.9525\n",
            "Epoch 240/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0931 - accuracy: 0.9799 - val_loss: 0.1800 - val_accuracy: 0.9525\n",
            "Epoch 241/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1005 - accuracy: 0.9768 - val_loss: 0.2032 - val_accuracy: 0.9525\n",
            "Epoch 242/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0890 - accuracy: 0.9803 - val_loss: 0.1898 - val_accuracy: 0.9525\n",
            "Epoch 243/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0969 - accuracy: 0.9778 - val_loss: 0.1852 - val_accuracy: 0.9525\n",
            "Epoch 244/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0930 - accuracy: 0.9787 - val_loss: 0.1786 - val_accuracy: 0.9525\n",
            "Epoch 245/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0981 - accuracy: 0.9777 - val_loss: 0.2028 - val_accuracy: 0.9525\n",
            "Epoch 246/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0844 - accuracy: 0.9813 - val_loss: 0.1891 - val_accuracy: 0.9525\n",
            "Epoch 247/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0964 - accuracy: 0.9782 - val_loss: 0.2060 - val_accuracy: 0.9525\n",
            "Epoch 248/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0940 - accuracy: 0.9794 - val_loss: 0.1920 - val_accuracy: 0.9525\n",
            "Epoch 249/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0852 - accuracy: 0.9817 - val_loss: 0.1755 - val_accuracy: 0.9525\n",
            "Epoch 250/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1010 - accuracy: 0.9757 - val_loss: 0.2027 - val_accuracy: 0.9525\n",
            "Epoch 251/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0942 - accuracy: 0.9787 - val_loss: 0.1931 - val_accuracy: 0.9525\n",
            "Epoch 252/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1049 - accuracy: 0.9765 - val_loss: 0.1947 - val_accuracy: 0.9525\n",
            "Epoch 253/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0899 - accuracy: 0.9800 - val_loss: 0.1911 - val_accuracy: 0.9525\n",
            "Epoch 254/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0926 - accuracy: 0.9801 - val_loss: 0.2058 - val_accuracy: 0.9525\n",
            "Epoch 255/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0910 - accuracy: 0.9803 - val_loss: 0.1984 - val_accuracy: 0.9525\n",
            "Epoch 256/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1005 - accuracy: 0.9788 - val_loss: 0.1829 - val_accuracy: 0.9525\n",
            "Epoch 257/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1000 - accuracy: 0.9779 - val_loss: 0.2050 - val_accuracy: 0.9525\n",
            "Epoch 258/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0950 - accuracy: 0.9789 - val_loss: 0.1977 - val_accuracy: 0.9525\n",
            "Epoch 259/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0863 - accuracy: 0.9812 - val_loss: 0.1822 - val_accuracy: 0.9525\n",
            "Epoch 260/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0971 - accuracy: 0.9785 - val_loss: 0.1962 - val_accuracy: 0.9525\n",
            "Epoch 261/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0960 - accuracy: 0.9781 - val_loss: 0.1950 - val_accuracy: 0.9525\n",
            "Epoch 262/500\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0918 - accuracy: 0.9791 - val_loss: 0.2045 - val_accuracy: 0.9525\n",
            "Epoch 263/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0826 - accuracy: 0.9817 - val_loss: 0.1891 - val_accuracy: 0.9525\n",
            "Epoch 264/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0972 - accuracy: 0.9781 - val_loss: 0.1943 - val_accuracy: 0.9525\n",
            "Epoch 265/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1088 - accuracy: 0.9739 - val_loss: 0.2022 - val_accuracy: 0.9525\n",
            "Epoch 266/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0933 - accuracy: 0.9789 - val_loss: 0.1967 - val_accuracy: 0.9525\n",
            "Epoch 267/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1033 - accuracy: 0.9764 - val_loss: 0.1748 - val_accuracy: 0.9525\n",
            "Epoch 268/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0884 - accuracy: 0.9815 - val_loss: 0.1862 - val_accuracy: 0.9525\n",
            "Epoch 269/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1004 - accuracy: 0.9775 - val_loss: 0.1952 - val_accuracy: 0.9525\n",
            "Epoch 270/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0877 - accuracy: 0.9797 - val_loss: 0.1881 - val_accuracy: 0.9525\n",
            "Epoch 271/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0867 - accuracy: 0.9799 - val_loss: 0.1989 - val_accuracy: 0.9525\n",
            "Epoch 272/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1012 - accuracy: 0.9783 - val_loss: 0.1922 - val_accuracy: 0.9525\n",
            "Epoch 273/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0870 - accuracy: 0.9804 - val_loss: 0.1935 - val_accuracy: 0.9525\n",
            "Epoch 274/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0838 - accuracy: 0.9812 - val_loss: 0.1889 - val_accuracy: 0.9525\n",
            "Epoch 275/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0918 - accuracy: 0.9793 - val_loss: 0.1956 - val_accuracy: 0.9525\n",
            "Epoch 276/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1091 - accuracy: 0.9744 - val_loss: 0.1886 - val_accuracy: 0.9525\n",
            "Epoch 277/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1018 - accuracy: 0.9762 - val_loss: 0.1812 - val_accuracy: 0.9525\n",
            "Epoch 278/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0927 - accuracy: 0.9791 - val_loss: 0.1887 - val_accuracy: 0.9525\n",
            "Epoch 279/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0902 - accuracy: 0.9790 - val_loss: 0.2005 - val_accuracy: 0.9525\n",
            "Epoch 280/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0958 - accuracy: 0.9782 - val_loss: 0.1984 - val_accuracy: 0.9525\n",
            "Epoch 281/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0787 - accuracy: 0.9833 - val_loss: 0.1930 - val_accuracy: 0.9525\n",
            "Epoch 282/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0924 - accuracy: 0.9796 - val_loss: 0.1873 - val_accuracy: 0.9525\n",
            "Epoch 283/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1006 - accuracy: 0.9775 - val_loss: 0.1820 - val_accuracy: 0.9525\n",
            "Epoch 284/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0870 - accuracy: 0.9807 - val_loss: 0.2016 - val_accuracy: 0.9525\n",
            "Epoch 285/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0959 - accuracy: 0.9792 - val_loss: 0.1787 - val_accuracy: 0.9525\n",
            "Epoch 286/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0934 - accuracy: 0.9777 - val_loss: 0.1986 - val_accuracy: 0.9525\n",
            "Epoch 287/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0928 - accuracy: 0.9793 - val_loss: 0.1779 - val_accuracy: 0.9525\n",
            "Epoch 288/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0880 - accuracy: 0.9793 - val_loss: 0.1868 - val_accuracy: 0.9525\n",
            "Epoch 289/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1023 - accuracy: 0.9758 - val_loss: 0.1885 - val_accuracy: 0.9525\n",
            "Epoch 290/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1083 - accuracy: 0.9752 - val_loss: 0.2022 - val_accuracy: 0.9525\n",
            "Epoch 291/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0892 - accuracy: 0.9805 - val_loss: 0.1807 - val_accuracy: 0.9525\n",
            "Epoch 292/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0957 - accuracy: 0.9779 - val_loss: 0.1764 - val_accuracy: 0.9525\n",
            "Epoch 293/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0920 - accuracy: 0.9801 - val_loss: 0.1880 - val_accuracy: 0.9525\n",
            "Epoch 294/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0934 - accuracy: 0.9789 - val_loss: 0.1896 - val_accuracy: 0.9525\n",
            "Epoch 295/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0972 - accuracy: 0.9777 - val_loss: 0.1841 - val_accuracy: 0.9525\n",
            "Epoch 296/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0923 - accuracy: 0.9797 - val_loss: 0.1829 - val_accuracy: 0.9525\n",
            "Epoch 297/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0889 - accuracy: 0.9807 - val_loss: 0.1766 - val_accuracy: 0.9525\n",
            "Epoch 298/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0906 - accuracy: 0.9797 - val_loss: 0.1874 - val_accuracy: 0.9525\n",
            "Epoch 299/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0912 - accuracy: 0.9791 - val_loss: 0.1965 - val_accuracy: 0.9525\n",
            "Epoch 300/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0963 - accuracy: 0.9785 - val_loss: 0.1838 - val_accuracy: 0.9525\n",
            "Epoch 301/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1010 - accuracy: 0.9772 - val_loss: 0.1792 - val_accuracy: 0.9525\n",
            "Epoch 302/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0872 - accuracy: 0.9805 - val_loss: 0.1828 - val_accuracy: 0.9525\n",
            "Epoch 303/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0922 - accuracy: 0.9804 - val_loss: 0.1869 - val_accuracy: 0.9525\n",
            "Epoch 304/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0906 - accuracy: 0.9794 - val_loss: 0.2056 - val_accuracy: 0.9525\n",
            "Epoch 305/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0915 - accuracy: 0.9791 - val_loss: 0.1884 - val_accuracy: 0.9525\n",
            "Epoch 306/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0963 - accuracy: 0.9777 - val_loss: 0.1976 - val_accuracy: 0.9525\n",
            "Epoch 307/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0957 - accuracy: 0.9780 - val_loss: 0.1810 - val_accuracy: 0.9525\n",
            "Epoch 308/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0891 - accuracy: 0.9801 - val_loss: 0.1840 - val_accuracy: 0.9525\n",
            "Epoch 309/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1038 - accuracy: 0.9764 - val_loss: 0.2098 - val_accuracy: 0.9525\n",
            "Epoch 310/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0844 - accuracy: 0.9809 - val_loss: 0.1819 - val_accuracy: 0.9525\n",
            "Epoch 311/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0923 - accuracy: 0.9777 - val_loss: 0.1971 - val_accuracy: 0.9525\n",
            "Epoch 312/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1057 - accuracy: 0.9759 - val_loss: 0.1869 - val_accuracy: 0.9525\n",
            "Epoch 313/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0889 - accuracy: 0.9811 - val_loss: 0.1804 - val_accuracy: 0.9525\n",
            "Epoch 314/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0937 - accuracy: 0.9791 - val_loss: 0.1826 - val_accuracy: 0.9525\n",
            "Epoch 315/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0947 - accuracy: 0.9792 - val_loss: 0.1835 - val_accuracy: 0.9525\n",
            "Epoch 316/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0913 - accuracy: 0.9802 - val_loss: 0.1764 - val_accuracy: 0.9525\n",
            "Epoch 317/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0956 - accuracy: 0.9788 - val_loss: 0.1951 - val_accuracy: 0.9525\n",
            "Epoch 318/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0916 - accuracy: 0.9797 - val_loss: 0.1812 - val_accuracy: 0.9525\n",
            "Epoch 319/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0999 - accuracy: 0.9773 - val_loss: 0.1826 - val_accuracy: 0.9525\n",
            "Epoch 320/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0932 - accuracy: 0.9787 - val_loss: 0.1799 - val_accuracy: 0.9525\n",
            "Epoch 321/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0978 - accuracy: 0.9785 - val_loss: 0.1899 - val_accuracy: 0.9525\n",
            "Epoch 322/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0921 - accuracy: 0.9792 - val_loss: 0.1800 - val_accuracy: 0.9525\n",
            "Epoch 323/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1025 - accuracy: 0.9766 - val_loss: 0.1896 - val_accuracy: 0.9525\n",
            "Epoch 324/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0871 - accuracy: 0.9806 - val_loss: 0.1759 - val_accuracy: 0.9525\n",
            "Epoch 325/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0924 - accuracy: 0.9800 - val_loss: 0.1822 - val_accuracy: 0.9525\n",
            "Epoch 326/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0976 - accuracy: 0.9779 - val_loss: 0.1767 - val_accuracy: 0.9525\n",
            "Epoch 327/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0966 - accuracy: 0.9788 - val_loss: 0.1783 - val_accuracy: 0.9525\n",
            "Epoch 328/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1048 - accuracy: 0.9756 - val_loss: 0.1862 - val_accuracy: 0.9525\n",
            "Epoch 329/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0882 - accuracy: 0.9800 - val_loss: 0.2126 - val_accuracy: 0.9525\n",
            "Epoch 330/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0922 - accuracy: 0.9796 - val_loss: 0.1892 - val_accuracy: 0.9525\n",
            "Epoch 331/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0956 - accuracy: 0.9781 - val_loss: 0.1939 - val_accuracy: 0.9525\n",
            "Epoch 332/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0861 - accuracy: 0.9796 - val_loss: 0.1910 - val_accuracy: 0.9525\n",
            "Epoch 333/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0909 - accuracy: 0.9789 - val_loss: 0.1849 - val_accuracy: 0.9525\n",
            "Epoch 334/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0866 - accuracy: 0.9807 - val_loss: 0.1916 - val_accuracy: 0.9525\n",
            "Epoch 335/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0959 - accuracy: 0.9779 - val_loss: 0.1906 - val_accuracy: 0.9525\n",
            "Epoch 336/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0841 - accuracy: 0.9804 - val_loss: 0.1757 - val_accuracy: 0.9525\n",
            "Epoch 337/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0920 - accuracy: 0.9794 - val_loss: 0.1877 - val_accuracy: 0.9525\n",
            "Epoch 338/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1051 - accuracy: 0.9759 - val_loss: 0.1985 - val_accuracy: 0.9525\n",
            "Epoch 339/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0914 - accuracy: 0.9791 - val_loss: 0.2023 - val_accuracy: 0.9525\n",
            "Epoch 340/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0906 - accuracy: 0.9792 - val_loss: 0.1874 - val_accuracy: 0.9525\n",
            "Epoch 341/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0969 - accuracy: 0.9775 - val_loss: 0.1886 - val_accuracy: 0.9525\n",
            "Epoch 342/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0848 - accuracy: 0.9808 - val_loss: 0.1840 - val_accuracy: 0.9525\n",
            "Epoch 343/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0852 - accuracy: 0.9816 - val_loss: 0.1788 - val_accuracy: 0.9525\n",
            "Epoch 344/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0793 - accuracy: 0.9828 - val_loss: 0.1811 - val_accuracy: 0.9525\n",
            "Epoch 345/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0977 - accuracy: 0.9780 - val_loss: 0.1947 - val_accuracy: 0.9525\n",
            "Epoch 346/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0844 - accuracy: 0.9814 - val_loss: 0.1859 - val_accuracy: 0.9525\n",
            "Epoch 347/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0917 - accuracy: 0.9790 - val_loss: 0.1926 - val_accuracy: 0.9525\n",
            "Epoch 348/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0922 - accuracy: 0.9786 - val_loss: 0.1919 - val_accuracy: 0.9525\n",
            "Epoch 349/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0894 - accuracy: 0.9791 - val_loss: 0.1781 - val_accuracy: 0.9525\n",
            "Epoch 350/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1003 - accuracy: 0.9773 - val_loss: 0.1899 - val_accuracy: 0.9525\n",
            "Epoch 351/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0954 - accuracy: 0.9778 - val_loss: 0.1934 - val_accuracy: 0.9525\n",
            "Epoch 352/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0832 - accuracy: 0.9818 - val_loss: 0.1834 - val_accuracy: 0.9525\n",
            "Epoch 353/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0986 - accuracy: 0.9777 - val_loss: 0.1780 - val_accuracy: 0.9525\n",
            "Epoch 354/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0900 - accuracy: 0.9799 - val_loss: 0.1867 - val_accuracy: 0.9525\n",
            "Epoch 355/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0960 - accuracy: 0.9777 - val_loss: 0.1780 - val_accuracy: 0.9525\n",
            "Epoch 356/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0934 - accuracy: 0.9790 - val_loss: 0.1930 - val_accuracy: 0.9525\n",
            "Epoch 357/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0881 - accuracy: 0.9811 - val_loss: 0.1748 - val_accuracy: 0.9525\n",
            "Epoch 358/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1042 - accuracy: 0.9756 - val_loss: 0.1876 - val_accuracy: 0.9525\n",
            "Epoch 359/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0931 - accuracy: 0.9798 - val_loss: 0.1877 - val_accuracy: 0.9525\n",
            "Epoch 360/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0997 - accuracy: 0.9768 - val_loss: 0.1826 - val_accuracy: 0.9525\n",
            "Epoch 361/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0953 - accuracy: 0.9785 - val_loss: 0.1884 - val_accuracy: 0.9525\n",
            "Epoch 362/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0958 - accuracy: 0.9790 - val_loss: 0.1928 - val_accuracy: 0.9525\n",
            "Epoch 363/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0943 - accuracy: 0.9779 - val_loss: 0.1957 - val_accuracy: 0.9525\n",
            "Epoch 364/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0877 - accuracy: 0.9801 - val_loss: 0.1874 - val_accuracy: 0.9525\n",
            "Epoch 365/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0857 - accuracy: 0.9812 - val_loss: 0.1813 - val_accuracy: 0.9525\n",
            "Epoch 366/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0895 - accuracy: 0.9793 - val_loss: 0.1964 - val_accuracy: 0.9525\n",
            "Epoch 367/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0876 - accuracy: 0.9801 - val_loss: 0.1763 - val_accuracy: 0.9525\n",
            "Epoch 368/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1031 - accuracy: 0.9765 - val_loss: 0.1978 - val_accuracy: 0.9525\n",
            "Epoch 369/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0897 - accuracy: 0.9806 - val_loss: 0.1922 - val_accuracy: 0.9525\n",
            "Epoch 370/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1028 - accuracy: 0.9758 - val_loss: 0.1947 - val_accuracy: 0.9525\n",
            "Epoch 371/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0854 - accuracy: 0.9815 - val_loss: 0.1866 - val_accuracy: 0.9525\n",
            "Epoch 372/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0995 - accuracy: 0.9778 - val_loss: 0.1845 - val_accuracy: 0.9525\n",
            "Epoch 373/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0889 - accuracy: 0.9800 - val_loss: 0.2014 - val_accuracy: 0.9525\n",
            "Epoch 374/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0921 - accuracy: 0.9790 - val_loss: 0.1837 - val_accuracy: 0.9525\n",
            "Epoch 375/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0999 - accuracy: 0.9772 - val_loss: 0.1761 - val_accuracy: 0.9525\n",
            "Epoch 376/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0826 - accuracy: 0.9817 - val_loss: 0.1900 - val_accuracy: 0.9525\n",
            "Epoch 377/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0813 - accuracy: 0.9805 - val_loss: 0.1830 - val_accuracy: 0.9525\n",
            "Epoch 378/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0890 - accuracy: 0.9805 - val_loss: 0.1832 - val_accuracy: 0.9525\n",
            "Epoch 379/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0921 - accuracy: 0.9786 - val_loss: 0.1727 - val_accuracy: 0.9525\n",
            "Epoch 380/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0903 - accuracy: 0.9789 - val_loss: 0.1788 - val_accuracy: 0.9525\n",
            "Epoch 381/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0889 - accuracy: 0.9796 - val_loss: 0.1784 - val_accuracy: 0.9525\n",
            "Epoch 382/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0965 - accuracy: 0.9785 - val_loss: 0.2032 - val_accuracy: 0.9525\n",
            "Epoch 383/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0992 - accuracy: 0.9771 - val_loss: 0.1964 - val_accuracy: 0.9525\n",
            "Epoch 384/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0954 - accuracy: 0.9769 - val_loss: 0.1956 - val_accuracy: 0.9525\n",
            "Epoch 385/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0979 - accuracy: 0.9755 - val_loss: 0.1885 - val_accuracy: 0.9525\n",
            "Epoch 386/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0904 - accuracy: 0.9796 - val_loss: 0.1769 - val_accuracy: 0.9525\n",
            "Epoch 387/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0949 - accuracy: 0.9790 - val_loss: 0.1934 - val_accuracy: 0.9525\n",
            "Epoch 388/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0929 - accuracy: 0.9786 - val_loss: 0.1909 - val_accuracy: 0.9525\n",
            "Epoch 389/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0845 - accuracy: 0.9815 - val_loss: 0.1927 - val_accuracy: 0.9525\n",
            "Epoch 390/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0914 - accuracy: 0.9781 - val_loss: 0.2190 - val_accuracy: 0.9525\n",
            "Epoch 391/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0827 - accuracy: 0.9812 - val_loss: 0.1760 - val_accuracy: 0.9525\n",
            "Epoch 392/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0883 - accuracy: 0.9807 - val_loss: 0.1807 - val_accuracy: 0.9525\n",
            "Epoch 393/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0885 - accuracy: 0.9805 - val_loss: 0.1782 - val_accuracy: 0.9525\n",
            "Epoch 394/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0907 - accuracy: 0.9793 - val_loss: 0.1917 - val_accuracy: 0.9525\n",
            "Epoch 395/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0883 - accuracy: 0.9805 - val_loss: 0.1840 - val_accuracy: 0.9525\n",
            "Epoch 396/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0880 - accuracy: 0.9805 - val_loss: 0.1894 - val_accuracy: 0.9525\n",
            "Epoch 397/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1028 - accuracy: 0.9762 - val_loss: 0.1927 - val_accuracy: 0.9525\n",
            "Epoch 398/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0960 - accuracy: 0.9784 - val_loss: 0.1930 - val_accuracy: 0.9525\n",
            "Epoch 399/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0927 - accuracy: 0.9783 - val_loss: 0.1932 - val_accuracy: 0.9525\n",
            "Epoch 400/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1059 - accuracy: 0.9752 - val_loss: 0.1896 - val_accuracy: 0.9525\n",
            "Epoch 401/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0868 - accuracy: 0.9799 - val_loss: 0.1835 - val_accuracy: 0.9525\n",
            "Epoch 402/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0796 - accuracy: 0.9821 - val_loss: 0.1871 - val_accuracy: 0.9525\n",
            "Epoch 403/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0929 - accuracy: 0.9799 - val_loss: 0.1844 - val_accuracy: 0.9525\n",
            "Epoch 404/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0900 - accuracy: 0.9799 - val_loss: 0.2010 - val_accuracy: 0.9525\n",
            "Epoch 405/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0921 - accuracy: 0.9799 - val_loss: 0.1772 - val_accuracy: 0.9525\n",
            "Epoch 406/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0891 - accuracy: 0.9795 - val_loss: 0.1857 - val_accuracy: 0.9525\n",
            "Epoch 407/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0822 - accuracy: 0.9808 - val_loss: 0.1875 - val_accuracy: 0.9525\n",
            "Epoch 408/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0999 - accuracy: 0.9779 - val_loss: 0.1884 - val_accuracy: 0.9525\n",
            "Epoch 409/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0876 - accuracy: 0.9807 - val_loss: 0.1831 - val_accuracy: 0.9525\n",
            "Epoch 410/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0869 - accuracy: 0.9802 - val_loss: 0.1820 - val_accuracy: 0.9525\n",
            "Epoch 411/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0967 - accuracy: 0.9781 - val_loss: 0.1936 - val_accuracy: 0.9525\n",
            "Epoch 412/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0913 - accuracy: 0.9793 - val_loss: 0.2072 - val_accuracy: 0.9525\n",
            "Epoch 413/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0900 - accuracy: 0.9800 - val_loss: 0.1958 - val_accuracy: 0.9525\n",
            "Epoch 414/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0952 - accuracy: 0.9786 - val_loss: 0.1992 - val_accuracy: 0.9525\n",
            "Epoch 415/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0962 - accuracy: 0.9785 - val_loss: 0.1889 - val_accuracy: 0.9525\n",
            "Epoch 416/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0991 - accuracy: 0.9773 - val_loss: 0.2060 - val_accuracy: 0.9525\n",
            "Epoch 417/500\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0981 - accuracy: 0.9768 - val_loss: 0.1771 - val_accuracy: 0.9525\n",
            "Epoch 418/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1087 - accuracy: 0.9750 - val_loss: 0.1832 - val_accuracy: 0.9525\n",
            "Epoch 419/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0865 - accuracy: 0.9805 - val_loss: 0.1851 - val_accuracy: 0.9525\n",
            "Epoch 420/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0952 - accuracy: 0.9782 - val_loss: 0.1832 - val_accuracy: 0.9525\n",
            "Epoch 421/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0953 - accuracy: 0.9771 - val_loss: 0.2009 - val_accuracy: 0.9525\n",
            "Epoch 422/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0986 - accuracy: 0.9774 - val_loss: 0.1788 - val_accuracy: 0.9525\n",
            "Epoch 423/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0903 - accuracy: 0.9798 - val_loss: 0.2003 - val_accuracy: 0.9525\n",
            "Epoch 424/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0889 - accuracy: 0.9799 - val_loss: 0.2119 - val_accuracy: 0.9525\n",
            "Epoch 425/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1066 - accuracy: 0.9765 - val_loss: 0.1940 - val_accuracy: 0.9525\n",
            "Epoch 426/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0914 - accuracy: 0.9790 - val_loss: 0.1690 - val_accuracy: 0.9525\n",
            "Epoch 427/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0940 - accuracy: 0.9790 - val_loss: 0.2002 - val_accuracy: 0.9525\n",
            "Epoch 428/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0829 - accuracy: 0.9812 - val_loss: 0.1785 - val_accuracy: 0.9525\n",
            "Epoch 429/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0928 - accuracy: 0.9784 - val_loss: 0.1789 - val_accuracy: 0.9525\n",
            "Epoch 430/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0836 - accuracy: 0.9818 - val_loss: 0.1782 - val_accuracy: 0.9525\n",
            "Epoch 431/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1053 - accuracy: 0.9761 - val_loss: 0.2017 - val_accuracy: 0.9525\n",
            "Epoch 432/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0985 - accuracy: 0.9768 - val_loss: 0.2065 - val_accuracy: 0.9525\n",
            "Epoch 433/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0871 - accuracy: 0.9803 - val_loss: 0.1763 - val_accuracy: 0.9525\n",
            "Epoch 434/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0864 - accuracy: 0.9805 - val_loss: 0.1853 - val_accuracy: 0.9525\n",
            "Epoch 435/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0950 - accuracy: 0.9777 - val_loss: 0.1867 - val_accuracy: 0.9525\n",
            "Epoch 436/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0883 - accuracy: 0.9803 - val_loss: 0.1882 - val_accuracy: 0.9525\n",
            "Epoch 437/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0816 - accuracy: 0.9821 - val_loss: 0.1725 - val_accuracy: 0.9525\n",
            "Epoch 438/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0979 - accuracy: 0.9775 - val_loss: 0.1903 - val_accuracy: 0.9525\n",
            "Epoch 439/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0835 - accuracy: 0.9814 - val_loss: 0.1926 - val_accuracy: 0.9525\n",
            "Epoch 440/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0904 - accuracy: 0.9788 - val_loss: 0.1924 - val_accuracy: 0.9525\n",
            "Epoch 441/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1062 - accuracy: 0.9752 - val_loss: 0.1904 - val_accuracy: 0.9525\n",
            "Epoch 442/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0915 - accuracy: 0.9788 - val_loss: 0.1809 - val_accuracy: 0.9525\n",
            "Epoch 443/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0966 - accuracy: 0.9782 - val_loss: 0.1866 - val_accuracy: 0.9525\n",
            "Epoch 444/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0828 - accuracy: 0.9815 - val_loss: 0.1809 - val_accuracy: 0.9525\n",
            "Epoch 445/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1078 - accuracy: 0.9760 - val_loss: 0.2038 - val_accuracy: 0.9525\n",
            "Epoch 446/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0943 - accuracy: 0.9776 - val_loss: 0.1864 - val_accuracy: 0.9525\n",
            "Epoch 447/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0911 - accuracy: 0.9783 - val_loss: 0.1817 - val_accuracy: 0.9525\n",
            "Epoch 448/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0913 - accuracy: 0.9786 - val_loss: 0.1821 - val_accuracy: 0.9525\n",
            "Epoch 449/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0833 - accuracy: 0.9811 - val_loss: 0.1846 - val_accuracy: 0.9525\n",
            "Epoch 450/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1007 - accuracy: 0.9771 - val_loss: 0.1825 - val_accuracy: 0.9525\n",
            "Epoch 451/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1048 - accuracy: 0.9757 - val_loss: 0.1965 - val_accuracy: 0.9525\n",
            "Epoch 452/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1010 - accuracy: 0.9760 - val_loss: 0.1829 - val_accuracy: 0.9525\n",
            "Epoch 453/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0950 - accuracy: 0.9777 - val_loss: 0.1928 - val_accuracy: 0.9525\n",
            "Epoch 454/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0885 - accuracy: 0.9804 - val_loss: 0.1818 - val_accuracy: 0.9525\n",
            "Epoch 455/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1058 - accuracy: 0.9752 - val_loss: 0.1958 - val_accuracy: 0.9525\n",
            "Epoch 456/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0934 - accuracy: 0.9788 - val_loss: 0.1909 - val_accuracy: 0.9525\n",
            "Epoch 457/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1107 - accuracy: 0.9745 - val_loss: 0.1886 - val_accuracy: 0.9525\n",
            "Epoch 458/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0951 - accuracy: 0.9787 - val_loss: 0.2015 - val_accuracy: 0.9525\n",
            "Epoch 459/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0916 - accuracy: 0.9797 - val_loss: 0.1959 - val_accuracy: 0.9525\n",
            "Epoch 460/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0986 - accuracy: 0.9775 - val_loss: 0.1806 - val_accuracy: 0.9525\n",
            "Epoch 461/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0946 - accuracy: 0.9791 - val_loss: 0.1892 - val_accuracy: 0.9525\n",
            "Epoch 462/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0887 - accuracy: 0.9795 - val_loss: 0.1869 - val_accuracy: 0.9525\n",
            "Epoch 463/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0871 - accuracy: 0.9811 - val_loss: 0.1845 - val_accuracy: 0.9525\n",
            "Epoch 464/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0817 - accuracy: 0.9816 - val_loss: 0.1857 - val_accuracy: 0.9525\n",
            "Epoch 465/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0905 - accuracy: 0.9794 - val_loss: 0.1976 - val_accuracy: 0.9525\n",
            "Epoch 466/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0905 - accuracy: 0.9796 - val_loss: 0.1843 - val_accuracy: 0.9525\n",
            "Epoch 467/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0870 - accuracy: 0.9812 - val_loss: 0.1744 - val_accuracy: 0.9525\n",
            "Epoch 468/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1001 - accuracy: 0.9773 - val_loss: 0.1982 - val_accuracy: 0.9525\n",
            "Epoch 469/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0936 - accuracy: 0.9794 - val_loss: 0.1811 - val_accuracy: 0.9525\n",
            "Epoch 470/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0955 - accuracy: 0.9780 - val_loss: 0.1863 - val_accuracy: 0.9525\n",
            "Epoch 471/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0980 - accuracy: 0.9772 - val_loss: 0.1860 - val_accuracy: 0.9525\n",
            "Epoch 472/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0989 - accuracy: 0.9765 - val_loss: 0.1942 - val_accuracy: 0.9525\n",
            "Epoch 473/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0857 - accuracy: 0.9806 - val_loss: 0.1914 - val_accuracy: 0.9525\n",
            "Epoch 474/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0930 - accuracy: 0.9803 - val_loss: 0.1823 - val_accuracy: 0.9525\n",
            "Epoch 475/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0906 - accuracy: 0.9800 - val_loss: 0.1792 - val_accuracy: 0.9525\n",
            "Epoch 476/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0951 - accuracy: 0.9782 - val_loss: 0.1920 - val_accuracy: 0.9525\n",
            "Epoch 477/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0902 - accuracy: 0.9785 - val_loss: 0.1933 - val_accuracy: 0.9525\n",
            "Epoch 478/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0923 - accuracy: 0.9781 - val_loss: 0.1861 - val_accuracy: 0.9525\n",
            "Epoch 479/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0941 - accuracy: 0.9779 - val_loss: 0.1774 - val_accuracy: 0.9525\n",
            "Epoch 480/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0946 - accuracy: 0.9798 - val_loss: 0.1879 - val_accuracy: 0.9525\n",
            "Epoch 481/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0903 - accuracy: 0.9804 - val_loss: 0.1798 - val_accuracy: 0.9525\n",
            "Epoch 482/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0897 - accuracy: 0.9799 - val_loss: 0.2006 - val_accuracy: 0.9525\n",
            "Epoch 483/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0961 - accuracy: 0.9788 - val_loss: 0.1787 - val_accuracy: 0.9525\n",
            "Epoch 484/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0805 - accuracy: 0.9822 - val_loss: 0.1701 - val_accuracy: 0.9525\n",
            "Epoch 485/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0866 - accuracy: 0.9814 - val_loss: 0.1778 - val_accuracy: 0.9525\n",
            "Epoch 486/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0919 - accuracy: 0.9786 - val_loss: 0.1933 - val_accuracy: 0.9525\n",
            "Epoch 487/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0878 - accuracy: 0.9804 - val_loss: 0.1858 - val_accuracy: 0.9525\n",
            "Epoch 488/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0865 - accuracy: 0.9790 - val_loss: 0.1834 - val_accuracy: 0.9525\n",
            "Epoch 489/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0936 - accuracy: 0.9795 - val_loss: 0.1874 - val_accuracy: 0.9525\n",
            "Epoch 490/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0874 - accuracy: 0.9806 - val_loss: 0.1770 - val_accuracy: 0.9525\n",
            "Epoch 491/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0912 - accuracy: 0.9797 - val_loss: 0.1819 - val_accuracy: 0.9525\n",
            "Epoch 492/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0958 - accuracy: 0.9791 - val_loss: 0.1928 - val_accuracy: 0.9525\n",
            "Epoch 493/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0942 - accuracy: 0.9785 - val_loss: 0.2114 - val_accuracy: 0.9525\n",
            "Epoch 494/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0886 - accuracy: 0.9802 - val_loss: 0.1852 - val_accuracy: 0.9525\n",
            "Epoch 495/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.1023 - accuracy: 0.9783 - val_loss: 0.1872 - val_accuracy: 0.9525\n",
            "Epoch 496/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0880 - accuracy: 0.9797 - val_loss: 0.1859 - val_accuracy: 0.9525\n",
            "Epoch 497/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0852 - accuracy: 0.9816 - val_loss: 0.1898 - val_accuracy: 0.9525\n",
            "Epoch 498/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0909 - accuracy: 0.9800 - val_loss: 0.1934 - val_accuracy: 0.9525\n",
            "Epoch 499/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0935 - accuracy: 0.9785 - val_loss: 0.1870 - val_accuracy: 0.9525\n",
            "Epoch 500/500\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0828 - accuracy: 0.9814 - val_loss: 0.1973 - val_accuracy: 0.9525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fPwBO4q8Z8d"
      },
      "source": [
        "**Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IU6SuV_Wzfek",
        "outputId": "35ced094-eb97-4ba7-ce1b-046ef98a4d8c"
      },
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "034RDmeN-Wl0",
        "outputId": "a5fed682-151d-457e-bab3-00073e6c3564"
      },
      "source": [
        "model_lstm.evaluate(test_x, test_y)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65/65 [==============================] - 1s 2ms/step - loss: 0.2325 - accuracy: 0.9488\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2325439602136612, 0.9488304257392883]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    }
  ]
}